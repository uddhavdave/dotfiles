{"id":"819436d5-92b1-45ea-b600-36f100f40df4","zed":"context","version":"0.4.0","text":"\n\n\n<task_description>\n\n# Code Change Workflow\n\nYour task is to guide the user through code changes using a series of steps. Each step should describe a high-level change, which can consist of multiple edits to distinct locations in the codebase.\n\n## Output Example\n\nProvide output as XML, with the following format:\n\n<step>\nUpdate the Person struct to store an age\n\n```rust\nstruct Person {\n    // existing fields...\n    age: u8,\n    height: f32,\n    // existing fields...\n}\n\nimpl Person {\n    fn age(&self) -> u8 {\n        self.age\n    }\n}\n```\n\n<edit>\n<path>src/person.rs</path>\n<operation>insert_before</operation>\n<search>height: f32,</search>\n<description>Add the age field</description>\n</edit>\n\n<edit>\n<path>src/person.rs</path>\n<operation>insert_after</operation>\n<search>impl Person {</search>\n<description>Add the age getter</description>\n</edit>\n</step>\n\n## Output Format\n\nFirst, each `<step>` must contain a written description of the change that should be made. The description should begin with a high-level overview, and can contain markdown code blocks as well. The description should be self-contained and actionable.\n\nAfter the description, each `<step>` must contain one or more `<edit>` tags, each of which refer to a specific range in a source file. Each `<edit>` tag must contain the following child tags:\n\n### `<path>` (required)\n\nThis tag contains the path to the file that will be changed. It can be an existing path, or a path that should be created.\n\n### `<search>` (optional)\n\nThis tag contains a search string to locate in the source file, e.g. `pub fn baz() {`. If not provided, the new content will be inserted at the top of the file. Make sure to produce a string that exists in the source file and that isn't ambiguous. When there's ambiguity, add more lines to the search to eliminate it.\n\n### `<description>` (required)\n\nThis tag contains a single-line description of the edit that should be made at the given location.\n\n### `<operation>` (required)\n\nThis tag indicates what type of change should be made, relative to the given location. It can be one of the following:\n- `update`: Rewrites the specified string entirely based on the given description.\n- `create`: Creates a new file with the given path based on the provided description.\n- `insert_before`: Inserts new text based on the given description before the specified search string.\n- `insert_after`: Inserts new text based on the given description after the specified search string.\n- `delete`: Deletes the specified string from the containing file.\n\n<guidelines>\n- There's no need to describe *what* to do, just *where* to do it.\n- Only reference locations that actually exist (unless you're creating a file).\n- If creating a file, assume any subsequent updates are included at the time of creation.\n- Don't create and then update a file. Always create new files in one hot.\n- Prefer multiple edits to smaller regions, as opposed to one big edit to a larger region.\n- Don't produce edits that intersect each other. In that case, merge them into a bigger edit.\n- Never nest an edit with another edit. Never include CDATA. All edits are leaf nodes.\n- Descriptions are required for all edits except delete.\n- When generating multiple edits, ensure the descriptions are specific to each individual operation.\n- Avoid referring to the search string in the description. Focus on the change to be made, not the location where it's made. That's implicit with the `search` string you provide.\n- Don't generate multiple edits at the same location. Instead, combine them together in a single edit with a succinct combined description.\n- Always ensure imports are added if you're referencing symbols that are not in scope.\n</guidelines>\n\nHere are some concrete examples.\n\n<example>\n<message role=\"user\">\n\n```rs src/shapes.rs\npub mod rectangle;\npub mod circle;\n```\n\n```rs src/shapes/rectangle.rs\npub struct Rectangle {\n    width: f64,\n    height: f64,\n}\n\nimpl Rectangle {\n    pub fn new(width: f64, height: f64) -> Self {\n        Rectangle { width, height }\n    }\n}\n```\n\n```rs src/shapes/circle.rs\npub struct Circle {\n    radius: f64,\n}\n\nimpl Circle {\n    pub fn new(radius: f64) -> Self {\n        Circle { radius }\n    }\n}\n```\n\nUpdate all shapes to store their origin as an (x, y) tuple and implement Display.\n</message>\n\n<message role=\"assistant\">\nWe'll need to update both the rectangle and circle modules.\n\n<step>\nAdd origin fields to both shape types.\n\n```rust\nstruct Rectangle {\n    // existing fields ...\n    origin: (f64, f64),\n}\n```\n\n```rust\nstruct Circle {\n    // existing fields ...\n    origin: (f64, f64),\n}\n```\n\n<edit>\n<path>src/shapes/rectangle.rs</path>\n<operation>insert_before</operation>\n<search>\n    width: f64,\n    height: f64,\n</search>\n<description>Add the origin field to Rectangle</description>\n</edit>\n\n<edit>\n<path>src/shapes/circle.rs</path>\n<operation>insert_before</operation>\n<search>\n    radius: f64,\n</search>\n<description>Add the origin field to Circle</description>\n</edit>\n\n<step>\nUpdate both shape's constructors to take an origin.\n\n<edit>\n<path>src/shapes/rectangle.rs</path>\n<operation>update</operation>\n<search>\n    fn new(width: f64, height: f64) -> Self {\n        Rectangle { width, height }\n    }\n</search>\n<description>Update the Rectangle new function to take an origin</description>\n</edit>\n\n<edit>\n<path>src/shapes/circle.rs</path>\n<operation>update</operation>\n<search>\n    fn new(radius: f64) -> Self {\n        Circle { radius }\n    }\n</search>\n<description>Update the Circle new function to take an origin</description>\n</edit>\n</step>\n\n<step>\nImplement Display for both shapes\n\n<edit>\n<path>src/shapes/rectangle.rs</path>\n<operation>insert_before</operation>\n<search>\nstruct Rectangle {\n</search>\n<description>Add an import for the `std::fmt` module</description>\n</edit>\n\n<edit>\n<path>src/shapes/rectangle.rs</path>\n<operation>insert_after</operation>\n<search>\n        Rectangle { width, height }\n    }\n}\n</search>\n<description>Add a Display implementation for Rectangle</description>\n</edit>\n\n<edit>\n<path>src/shapes/circle.rs</path>\n<operation>insert_before</operation>\n<search>\nstruct Circle {\n</search>\n<description>Add an import for the `std::fmt` module</description>\n</edit>\n\n<edit>\n<path>src/shapes/circle.rs</path>\n<operation>insert_after</operation>\n<search>\n        Circle { radius }\n    }\n}\n</search>\n<description>Add a Display implementation for Circle</description>\n</edit>\n</step>\n</message>\n</example>\n\n<example number=2>\n<message role=\"user\">\n\n```rs src/user.rs\nstruct User {\n    pub name: String,\n    age: u32,\n    email: String,\n}\n\nimpl User {\n    fn new(name: String, age: u32, email: String) -> Self {\n        User { name, age, email }\n    }\n\n    pub fn print_info(&self) {\n        todo!()\n    }\n}\n```\n\nLet's print all the user information and delete the email field.\n</message>\n\n<message role=\"assistant\">\n<step>\nUpdate the 'print_info' method to print user information\n\n```rust\nimpl User {\n    // ... other methods ...\n\n    pub fn print_info(&self) {\n        println!(\"Name: {name}, Age: {age}\", name = self.name, age = self.age);\n    }\n}\n```\n\n<edit>\n<path>src/user.rs</path>\n<operation>update</operation>\n<search>\n    pub fn print_info(&self) {\n        todo!()\n    }\n</search>\n<description>Print all the user information</description>\n</edit>\n</step>\n\n<step>\nRemove the 'email' field from the User struct\n\n<edit>\n<path>src/user.rs</path>\n<operation>delete</operation>\n<search>\nemail: String,\n</search>\n</edit>\n\n<edit>\n<path>src/user.rs</path>\n<operation>update</operation>\n<symbol>\nfn new(name: String, age: u32, email: String) -> Self {\n    User { name, age, email }\n}\n</symbol>\n<description>Remove email parameter from new method</description>\n</edit>\n</step>\n</message>\n</example>\n\nYou should think step by step. When possible, produce smaller, coherent logical steps as opposed to one big step that combines lots of heterogeneous edits.\n\n</task_description>\n\nmake me a sequence diagram showcasing the search flow of quickwit in detail with all the phase searches\nTo create a sequence diagram showcasing the search flow of Quickwit in detail, we need to break down the process into distinct phases. Quickwit is a search engine designed for large-scale, real-time search applications. The search flow typically involves several key components and phases, including query parsing, search execution, and result aggregation.\n\nHere's a detailed sequence diagram for the search flow of Quickwit:\n\n```xml\n<sequence_diagram>\n<actors>\n<actor>Client</actor>\n<actor>Quickwit</actor>\n<actor>QueryParser</actor>\n<actor>SearchExecutor</actor>\n<actor>Index</actor>\n<actor>Aggregator</actor>\n</actors>\n\n<steps>\n<step>\n<description>Client sends a search query to Quickwit</description>\n<from>Client</from>\n<to>Quickwit</to>\n</step>\n\n<step>\n<description>Quickwit forwards the query to the QueryParser</description>\n<from>Quickwit</from>\n<to>QueryParser</to>\n</step>\n\n<step>\n<description>QueryParser parses the query and returns a parsed query object</description>\n<from>QueryParser</from>\n<to>Quickwit</to>\n</step>\n\n<step>\n<description>Quickwit sends the parsed query to the SearchExecutor</description>\n<from>Quickwit</from>\n<to>SearchExecutor</to>\n</step>\n\n<step>\n<description>SearchExecutor distributes the query to relevant Indexes</description>\n<from>SearchExecutor</from>\n<to>Index</to>\n</step>\n\n<step>\n<description>Indexes perform the search and return partial results to the SearchExecutor</description>\n<from>Index</from>\n<to>SearchExecutor</to>\n</step>\n\n<step>\n<description>SearchExecutor sends partial results to the Aggregator</description>\n<from>SearchExecutor</from>\n<to>Aggregator</to>\n</step>\n\n<step>\n<description>Aggregator combines partial results into a final result set</description>\n<from>Aggregator</from>\n<to>Quickwit</to>\n</step>\n\n<step>\n<description>Quickwit returns the final result set to the Client</description>\n<from>Quickwit</from>\n<to>Client</to>\n</step>\n</steps>\n</sequence_diagram>\n```\n\nThis sequence diagram outlines the detailed search flow of Quickwit, including all the phases from query parsing to result aggregation. Each step is described with the involved actors and the direction of communication.\nasync fn search_partial_hits_phase_with_scroll(\nexplain me this function \nTo explain the function `async fn search_partial_hits_phase_with_scroll`, we need to break down its purpose, the context in which it operates, and the key components involved. This function is likely part of a larger search system, possibly within a search engine like Quickwit, and it deals with searching and retrieving partial hits using a scroll mechanism.\n```rs quickwit/quickwit/quickwit-search/src/root.rs\n// Copyright (C) 2024 Quickwit, Inc.\n//\n// Quickwit is offered under the AGPL v3.0 and as commercial software.\n// For commercial licensing, contact us at hello@quickwit.io.\n//\n// AGPL:\n// This program is free software: you can redistribute it and/or modify\n// it under the terms of the GNU Affero General Public License as\n// published by the Free Software Foundation, either version 3 of the\n// License, or (at your option) any later version.\n//\n// This program is distributed in the hope that it will be useful,\n// but WITHOUT ANY WARRANTY; without even the implied warranty of\n// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n// GNU Affero General Public License for more details.\n//\n// You should have received a copy of the GNU Affero General Public License\n// along with this program. If not, see <http://www.gnu.org/licenses/>.\n\nuse std::collections::{HashMap, HashSet};\nuse std::sync::OnceLock;\nuse std::time::Duration;\n\nuse anyhow::Context;\nuse futures::future::try_join_all;\nuse itertools::Itertools;\nuse quickwit_common::pretty::PrettySample;\nuse quickwit_common::shared_consts;\nuse quickwit_common::uri::Uri;\nuse quickwit_config::build_doc_mapper;\nuse quickwit_doc_mapper::tag_pruning::extract_tags_from_query;\nuse quickwit_doc_mapper::DYNAMIC_FIELD_NAME;\nuse quickwit_metastore::{IndexMetadata, ListIndexesMetadataResponseExt, SplitMetadata};\nuse quickwit_proto::metastore::{\n    ListIndexesMetadataRequest, MetastoreService, MetastoreServiceClient,\n};\nuse quickwit_proto::search::{\n    FetchDocsRequest, FetchDocsResponse, Hit, LeafHit, LeafRequestRef, LeafSearchRequest,\n    LeafSearchResponse, PartialHit, SearchPlanResponse, SearchRequest, SearchResponse,\n    SnippetRequest, SortDatetimeFormat, SortField, SortValue, SplitIdAndFooterOffsets,\n};\nuse quickwit_proto::types::{IndexUid, SplitId};\nuse quickwit_query::query_ast::{\n    BoolQuery, QueryAst, QueryAstVisitor, RangeQuery, TermQuery, TermSetQuery,\n};\nuse serde::{Deserialize, Serialize};\nuse tantivy::aggregation::agg_result::AggregationResults;\nuse tantivy::aggregation::intermediate_agg_result::IntermediateAggregationResults;\nuse tantivy::collector::Collector;\nuse tantivy::schema::{FieldEntry, FieldType, Schema};\nuse tantivy::TantivyError;\nuse tracing::{debug, error, info, info_span, instrument};\n\nuse crate::cluster_client::ClusterClient;\nuse crate::collector::{make_merge_collector, QuickwitAggregations};\nuse crate::find_trace_ids_collector::Span;\nuse crate::scroll_context::{ScrollContext, ScrollKeyAndStartOffset};\nuse crate::search_job_placer::{group_by, group_jobs_by_index_id, Job};\nuse crate::search_response_rest::StorageRequestCount;\nuse crate::service::SearcherContext;\nuse crate::{\n    extract_split_and_footer_offsets, list_relevant_splits, SearchError, SearchJobPlacer,\n    SearchPlanResponseRest, SearchServiceClient,\n};\n\n/// Maximum accepted scroll TTL.\nfn max_scroll_ttl() -> Duration {\n    static MAX_SCROLL_TTL_LOCK: OnceLock<Duration> = OnceLock::new();\n    *MAX_SCROLL_TTL_LOCK.get_or_init(|| {\n        let split_deletion_grace_period = shared_consts::split_deletion_grace_period();\n        assert!(\n            split_deletion_grace_period >= shared_consts::MINIMUM_DELETION_GRACE_PERIOD,\n            \"The split deletion grace period is too short ({split_deletion_grace_period:?}). This \\\n             should not happen.\"\n        );\n        // We remove an extra margin of 2minutes from the split deletion grace period.\n        split_deletion_grace_period - Duration::from_secs(60 * 2)\n    })\n}\n\nconst SORT_DOC_FIELD_NAMES: &[&str] = &[\"_shard_doc\", \"_doc\"];\n\n/// SearchJob to be assigned to search clients by the [`SearchJobPlacer`].\n#[derive(Debug, Clone, PartialEq)]\npub struct SearchJob {\n    /// The index UID.\n    pub index_uid: IndexUid,\n    cost: usize,\n    /// The split ID and footer offsets of the split.\n    pub offsets: SplitIdAndFooterOffsets,\n}\n\nimpl SearchJob {\n    #[cfg(test)]\n    pub fn for_test(split_id: &str, cost: usize) -> SearchJob {\n        use std::str::FromStr;\n        SearchJob {\n            index_uid: IndexUid::from_str(\"test-index:00000000000000000000000000\").unwrap(),\n            cost,\n            offsets: SplitIdAndFooterOffsets {\n                split_id: split_id.to_string(),\n                ..Default::default()\n            },\n        }\n    }\n}\n\nimpl From<SearchJob> for SplitIdAndFooterOffsets {\n    fn from(search_job: SearchJob) -> Self {\n        search_job.offsets\n    }\n}\n\nimpl<'a> From<&'a SplitMetadata> for SearchJob {\n    fn from(split_metadata: &'a SplitMetadata) -> Self {\n        SearchJob {\n            index_uid: split_metadata.index_uid.clone(),\n            cost: compute_split_cost(split_metadata),\n            offsets: extract_split_and_footer_offsets(split_metadata),\n        }\n    }\n}\n\nimpl Job for SearchJob {\n    fn split_id(&self) -> &str {\n        &self.offsets.split_id\n    }\n\n    fn cost(&self) -> usize {\n        self.cost\n    }\n}\n\npub struct FetchDocsJob {\n    index_uid: IndexUid,\n    offsets: SplitIdAndFooterOffsets,\n    pub partial_hits: Vec<PartialHit>,\n}\n\nimpl Job for FetchDocsJob {\n    fn split_id(&self) -> &str {\n        &self.offsets.split_id\n    }\n\n    fn cost(&self) -> usize {\n        self.partial_hits.len()\n    }\n}\n\nimpl From<FetchDocsJob> for SplitIdAndFooterOffsets {\n    fn from(fetch_docs_job: FetchDocsJob) -> SplitIdAndFooterOffsets {\n        fetch_docs_job.offsets\n    }\n}\n\n/// Index metas needed for executing a leaf search request.\n#[derive(Serialize, Deserialize, Clone, Debug)]\npub struct IndexMetasForLeafSearch {\n    /// Index URI.\n    pub index_uri: Uri,\n    /// Doc mapper json string.\n    pub doc_mapper_str: String,\n}\n\npub(crate) type IndexesMetasForLeafSearch = HashMap<IndexUid, IndexMetasForLeafSearch>;\n\n#[derive(Debug)]\nstruct RequestMetadata {\n    timestamp_field_opt: Option<String>,\n    query_ast_resolved: QueryAst,\n    indexes_meta_for_leaf_search: IndexesMetasForLeafSearch,\n    sort_fields_is_datetime: HashMap<String, bool>,\n}\n\n/// Validates request against each index's doc mapper and ensures that:\n/// - timestamp fields (if any) are equal across indexes.\n/// - resolved query ASTs are the same across indexes.\n/// - if a sort field is of type datetime, it must be a datetime field on all indexes. This\n///   constraint come from the need to support datetime formatting on sort values.\n/// Returns the timestamp field, the resolved query AST and the indexes metadatas\n/// needed for leaf search requests.\n/// Note: the requirements on timestamp fields and resolved query ASTs can be lifted\n/// but it adds complexity that does not seem needed right now.\nfn validate_request_and_build_metadata(\n    indexes_metadata: &[IndexMetadata],\n    search_request: &SearchRequest,\n) -> crate::Result<RequestMetadata> {\n    validate_sort_by_fields_and_search_after(\n        &search_request.sort_fields,\n        &search_request.search_after,\n    )?;\n    let query_ast: QueryAst = serde_json::from_str(&search_request.query_ast)\n        .map_err(|err| SearchError::InvalidQuery(err.to_string()))?;\n    let mut indexes_meta_for_leaf_search: HashMap<IndexUid, IndexMetasForLeafSearch> =\n        HashMap::new();\n    let mut query_ast_resolved_opt: Option<QueryAst> = None;\n    let mut timestamp_field_opt: Option<String> = None;\n    let mut sort_fields_is_datetime: HashMap<String, bool> = HashMap::new();\n\n    for index_metadata in indexes_metadata {\n        let doc_mapper = build_doc_mapper(\n            &index_metadata.index_config.doc_mapping,\n            &index_metadata.index_config.search_settings,\n        )\n        .map_err(|err| {\n            SearchError::Internal(format!(\"failed to build doc mapper. cause: {err}\"))\n        })?;\n        let query_ast_resolved_for_index = query_ast\n            .clone()\n            .parse_user_query(doc_mapper.default_search_fields())\n            // We convert the error to return a 400 to the user (and not a 500).\n            .map_err(|err| SearchError::InvalidQuery(err.to_string()))?;\n\n        // Validate uniqueness of resolved query AST.\n        if let Some(query_ast_resolved) = &query_ast_resolved_opt {\n            if query_ast_resolved != &query_ast_resolved_for_index {\n                return Err(SearchError::InvalidQuery(\n                    \"resolved query ASTs must be the same across indexes. resolving queries with \\\n                     different default fields are different between indexes is not supported\"\n                        .to_string(),\n                ));\n            }\n        } else {\n            query_ast_resolved_opt = Some(query_ast_resolved_for_index.clone());\n        }\n\n        // Validate uniqueness of timestamp field if any.\n        if let Some(timestamp_field_for_index) = doc_mapper.timestamp_field_name() {\n            match timestamp_field_opt {\n                Some(timestamp_field) if timestamp_field != timestamp_field_for_index => {\n                    return Err(SearchError::InvalidQuery(\n                        \"the timestamp field (if present) must be the same for all indexes\"\n                            .to_string(),\n                    ));\n                }\n                None => {\n                    timestamp_field_opt = Some(timestamp_field_for_index.to_string());\n                }\n                _ => {}\n            }\n        }\n\n        // Validate request against the current index schema.\n        let schema = doc_mapper.schema();\n        validate_request(&schema, &doc_mapper.timestamp_field_name(), search_request)?;\n\n        validate_sort_field_types(\n            &schema,\n            &search_request.sort_fields,\n            &mut sort_fields_is_datetime,\n        )?;\n\n        // Validates the query by effectively building it against the current schema.\n        doc_mapper.query(doc_mapper.schema(), &query_ast_resolved_for_index, true)?;\n\n        let index_metadata_for_leaf_search = IndexMetasForLeafSearch {\n            index_uri: index_metadata.index_uri().clone(),\n            doc_mapper_str: serde_json::to_string(&doc_mapper).map_err(|err| {\n                SearchError::Internal(format!(\"failed to serialize doc mapper. cause: {err}\"))\n            })?,\n        };\n        indexes_meta_for_leaf_search.insert(\n            index_metadata.index_uid.clone(),\n            index_metadata_for_leaf_search,\n        );\n    }\n\n    let query_ast_resolved = query_ast_resolved_opt.ok_or_else(|| {\n        SearchError::Internal(\n            \"resolved query AST must be present. this should never happen\".to_string(),\n        )\n    })?;\n\n    Ok(RequestMetadata {\n        timestamp_field_opt,\n        query_ast_resolved,\n        indexes_meta_for_leaf_search,\n        sort_fields_is_datetime,\n    })\n}\n\n/// Validate sort field types.\nfn validate_sort_field_types(\n    schema: &Schema,\n    sort_fields: &[SortField],\n    sort_field_is_datetime: &mut HashMap<String, bool>,\n) -> crate::Result<()> {\n    for sort_field in sort_fields.iter() {\n        if let Some(sort_field_entry) = get_sort_by_field_entry(&sort_field.field_name, schema)? {\n            validate_sort_by_field_type(\n                sort_field_entry,\n                sort_field.sort_datetime_format.is_some(),\n            )?;\n            // If sort field type is a date, ensure it's true for all indexes.\n            if let Some(is_datetime) = sort_field_is_datetime.get(&sort_field.field_name) {\n                if *is_datetime != sort_field_entry.field_type().is_date() {\n                    return Err(SearchError::InvalidQuery(format!(\n                        \"sort datetime field `{}` must be of type datetime on all indexes\",\n                        sort_field_entry.name(),\n                    )));\n                }\n            } else {\n                sort_field_is_datetime.insert(\n                    sort_field.field_name.to_string(),\n                    sort_field_entry.field_type().is_date(),\n                );\n            }\n        } else {\n            sort_field_is_datetime.insert(sort_field.field_name.to_string(), false);\n        }\n    }\n    Ok(())\n}\n\nfn validate_requested_snippet_fields(\n    schema: &Schema,\n    snippet_fields: &[String],\n) -> anyhow::Result<()> {\n    for field_name in snippet_fields {\n        let field_entry = schema\n            .get_field(field_name)\n            .map(|field| schema.get_field_entry(field))?;\n        match field_entry.field_type() {\n            FieldType::Str(text_options) => {\n                if !text_options.is_stored() {\n                    return Err(anyhow::anyhow!(\n                        \"the snippet field `{}` must be stored\",\n                        field_name\n                    ));\n                }\n            }\n            other => {\n                return Err(anyhow::anyhow!(\n                    \"the snippet field `{}` must be of type `Str`, got `{}`\",\n                    field_name,\n                    other.value_type().name()\n                ))\n            }\n        }\n    }\n    Ok(())\n}\n\nfn simplify_search_request_for_scroll_api(req: &SearchRequest) -> crate::Result<SearchRequest> {\n    if req.search_after.is_some() {\n        return Err(SearchError::InvalidArgument(\n            \"search_after cannot be used in a scroll context\".to_string(),\n        ));\n    }\n\n    // We do not mutate\n    Ok(SearchRequest {\n        index_id_patterns: req.index_id_patterns.clone(),\n        query_ast: req.query_ast.clone(),\n        start_timestamp: req.start_timestamp,\n        end_timestamp: req.end_timestamp,\n        max_hits: req.max_hits,\n        start_offset: req.start_offset,\n        sort_fields: req.sort_fields.clone(),\n        // We remove all aggregation request.\n        // The aggregation will not be computed for each scroll request.\n        aggregation_request: None,\n        // We remove the snippet fields. This feature is not supported for scroll requests.\n        snippet_fields: Vec::new(),\n        // We remove the scroll ttl parameter. It is irrelevant to process later request\n        scroll_ttl_secs: None,\n        search_after: None,\n        // request is simplified after initial query, and we cache the hit count, so we don't need\n        // to recompute it afterward.\n        count_hits: quickwit_proto::search::CountHits::Underestimate as i32,\n    })\n}\n\n/// Validates sort fields and search after values.\n/// - validate sort fields length.\n/// - search after values must be set for all sort fields.\nfn validate_sort_by_fields_and_search_after(\n    sort_fields: &[SortField],\n    search_after: &Option<PartialHit>,\n) -> crate::Result<()> {\n    if sort_fields.is_empty() {\n        return Ok(());\n    }\n    if sort_fields.len() > 2 {\n        return Err(SearchError::InvalidArgument(format!(\n            \"sort by field must be up to 2 fields, got {}\",\n            sort_fields.len()\n        )));\n    }\n    let Some(search_after_partial_hit) = search_after.as_ref() else {\n        return Ok(());\n    };\n\n    let sort_fields_without_doc_count = sort_fields\n        .iter()\n        .filter(|sort_field| !SORT_DOC_FIELD_NAMES.contains(&sort_field.field_name.as_str()))\n        .count();\n    let has_doc_sort_field = sort_fields_without_doc_count != sort_fields.len();\n    if has_doc_sort_field && search_after_partial_hit.split_id.is_empty() {\n        return Err(SearchError::InvalidArgument(\n            \"search_after with a sort field `_doc` must define a split ID, segment ID and doc ID \\\n             values\"\n                .to_string(),\n        ));\n    }\n\n    let mut search_after_sort_value_count = 0;\n    // TODO: we could validate if the search after sort value types of consistent with the sort\n    // field types.\n    if let Some(sort_by_value) = search_after_partial_hit.sort_value.as_ref() {\n        sort_by_value.sort_value.context(\"sort value must be set\")?;\n        search_after_sort_value_count += 1;\n    }\n    if let Some(sort_by_value_2) = search_after_partial_hit.sort_value2.as_ref() {\n        sort_by_value_2\n            .sort_value\n            .context(\"sort value must be set\")?;\n        search_after_sort_value_count += 1;\n    }\n    if search_after_sort_value_count != sort_fields_without_doc_count {\n        return Err(SearchError::InvalidArgument(format!(\n            \"`search_after` must have the same number of sort values as sort by fields {:?}\",\n            sort_fields\n                .iter()\n                .map(|sort_field| &sort_field.field_name)\n                .collect_vec()\n        )));\n    }\n    Ok(())\n}\n\nfn get_sort_by_field_entry<'a>(\n    field_name: &str,\n    schema: &'a Schema,\n) -> crate::Result<Option<&'a FieldEntry>> {\n    if \"_score\" == field_name || SORT_DOC_FIELD_NAMES.contains(&field_name) {\n        return Ok(None);\n    }\n    let dynamic_field_opt = schema.get_field(DYNAMIC_FIELD_NAME).ok();\n    let (sort_by_field, _json_path) = schema\n        .find_field_with_default(field_name, dynamic_field_opt)\n        .ok_or_else(|| {\n            SearchError::InvalidArgument(format!(\"unknown field used in `sort by`: {field_name}\"))\n        })?;\n    let sort_by_field_entry = schema.get_field_entry(sort_by_field);\n    Ok(Some(sort_by_field_entry))\n}\n\n/// Validates sort field type.\nfn validate_sort_by_field_type(\n    sort_by_field_entry: &FieldEntry,\n    has_timestamp_format: bool,\n) -> crate::Result<()> {\n    let field_name = sort_by_field_entry.name();\n    if matches!(sort_by_field_entry.field_type(), FieldType::Str(_)) {\n        return Err(SearchError::InvalidArgument(format!(\n            \"sort by field on type text is currently not supported `{field_name}`\"\n        )));\n    }\n    if !sort_by_field_entry.is_fast() {\n        return Err(SearchError::InvalidArgument(format!(\n            \"sort by field must be a fast field, please add the fast property to your field \\\n             `{field_name}`\",\n        )));\n    }\n    if has_timestamp_format && !sort_by_field_entry.field_type().is_date() {\n        return Err(SearchError::InvalidArgument(format!(\n            \"sort by field with a timestamp format must be a datetime field and the field \\\n             `{field_name}` is not\",\n        )));\n    }\n    Ok(())\n}\n\nfn validate_request(\n    schema: &Schema,\n    timestamp_field_name: &Option<&str>,\n    search_request: &SearchRequest,\n) -> crate::Result<()> {\n    if timestamp_field_name.is_none()\n        && (search_request.start_timestamp.is_some() || search_request.end_timestamp.is_some())\n    {\n        return Err(SearchError::InvalidQuery(format!(\n            \"the timestamp field is not set in index: {:?} definition but start-timestamp or \\\n             end-timestamp are set in the query\",\n            search_request.index_id_patterns\n        )));\n    }\n\n    validate_requested_snippet_fields(schema, &search_request.snippet_fields)?;\n\n    if let Some(agg) = search_request.aggregation_request.as_ref() {\n        let _aggs: QuickwitAggregations = serde_json::from_str(agg).map_err(|_err| {\n            let err = serde_json::from_str::<tantivy::aggregation::agg_req::Aggregations>(agg)\n                .unwrap_err();\n            SearchError::InvalidAggregationRequest(err.to_string())\n        })?;\n    };\n\n    if search_request.start_offset > 10_000 {\n        return Err(SearchError::InvalidArgument(format!(\n            \"max value for start_offset is 10_000, but got {}\",\n            search_request.start_offset\n        )));\n    }\n\n    if search_request.max_hits > 10_000 {\n        return Err(SearchError::InvalidArgument(format!(\n            \"max value for max_hits is 10_000, but got {}\",\n            search_request.max_hits\n        )));\n    }\n\n    Ok(())\n}\n\nfn get_scroll_ttl_duration(search_request: &SearchRequest) -> crate::Result<Option<Duration>> {\n    let Some(scroll_ttl_secs) = search_request.scroll_ttl_secs else {\n        return Ok(None);\n    };\n    let scroll_ttl: Duration = Duration::from_secs(scroll_ttl_secs as u64);\n    let max_scroll_ttl = max_scroll_ttl();\n    if scroll_ttl > max_scroll_ttl {\n        return Err(SearchError::InvalidArgument(format!(\n            \"Quickwit only supports scroll TTL period up to {} secs\",\n            max_scroll_ttl.as_secs()\n        )));\n    }\n    Ok(Some(scroll_ttl))\n}\n\n#[instrument(level = \"debug\", skip_all)]\nasync fn search_partial_hits_phase_with_scroll(\n    searcher_context: &SearcherContext,\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    mut search_request: SearchRequest,\n    split_metadatas: &[SplitMetadata],\n    cluster_client: &ClusterClient,\n) -> crate::Result<(LeafSearchResponse, Option<ScrollKeyAndStartOffset>)> {\n    let scroll_ttl_opt = get_scroll_ttl_duration(&search_request)?;\n\n    if let Some(scroll_ttl) = scroll_ttl_opt {\n        let max_hits = search_request.max_hits;\n        // This is a scroll request.\n        //\n        // We increase max hits to add populate the scroll cache.\n        search_request.max_hits = search_request\n            .max_hits\n            .max(shared_consts::SCROLL_BATCH_LEN as u64);\n        search_request.scroll_ttl_secs = None;\n        let mut leaf_search_resp = search_partial_hits_phase(\n            searcher_context,\n            indexes_metas_for_leaf_search,\n            &search_request,\n            split_metadatas,\n            cluster_client,\n        )\n        .await?;\n        let cached_partial_hits = leaf_search_resp.partial_hits.clone();\n        leaf_search_resp.partial_hits.truncate(max_hits as usize);\n        let last_hit = leaf_search_resp\n            .partial_hits\n            .last()\n            .cloned()\n            .unwrap_or_default();\n\n        let scroll_context_search_request =\n            simplify_search_request_for_scroll_api(&search_request)?;\n        let mut scroll_ctx = ScrollContext {\n            indexes_metas_for_leaf_search: indexes_metas_for_leaf_search.clone(),\n            split_metadatas: split_metadatas.to_vec(),\n            search_request: scroll_context_search_request,\n            total_num_hits: leaf_search_resp.num_hits,\n            max_hits_per_page: max_hits,\n            cached_partial_hits_start_offset: search_request.start_offset,\n            cached_partial_hits,\n        };\n        let scroll_key_and_start_offset: ScrollKeyAndStartOffset =\n            ScrollKeyAndStartOffset::new_with_start_offset(\n                scroll_ctx.search_request.start_offset,\n                max_hits as u32,\n                last_hit.clone(),\n            )\n            .next_page(leaf_search_resp.partial_hits.len() as u64, last_hit);\n\n        scroll_ctx.clear_cache_if_unneeded();\n        let payload: Vec<u8> = scroll_ctx.serialize();\n        let scroll_key = scroll_key_and_start_offset.scroll_key();\n        cluster_client\n            .put_kv(&scroll_key, &payload, scroll_ttl)\n            .await;\n        Ok((leaf_search_resp, Some(scroll_key_and_start_offset)))\n    } else {\n        let leaf_search_resp = search_partial_hits_phase(\n            searcher_context,\n            indexes_metas_for_leaf_search,\n            &search_request,\n            split_metadatas,\n            cluster_client,\n        )\n        .await?;\n        Ok((leaf_search_resp, None))\n    }\n}\n\n/// Check if the request is a count request without any filters, so we can just return the split\n/// metadata count.\n///\n/// This is done by exclusion, so we will need to keep it up to date if fields are added.\npub fn is_metadata_count_request(request: &SearchRequest) -> bool {\n    let query_ast: QueryAst = serde_json::from_str(&request.query_ast).unwrap();\n    is_metadata_count_request_with_ast(&query_ast, request)\n}\n\n/// Check if the request is a count request without any filters, so we can just return the split\n/// metadata count.\n///\n/// This is done by exclusion, so we will need to keep it up to date if fields are added.\n///\n/// The passed query_ast should match the serialized on in request.\npub fn is_metadata_count_request_with_ast(query_ast: &QueryAst, request: &SearchRequest) -> bool {\n    if query_ast != &QueryAst::MatchAll {\n        return false;\n    }\n    if request.max_hits != 0 {\n        return false;\n    }\n\n    // If the start and end timestamp encompass the whole split, it is still a count query.\n    // We remove this currently on the leaf level, but not yet on the root level.\n    // There's a small advantage when we would do this on the root level, since we have the\n    // counts available on the split. On the leaf it is currently required to open the split\n    // to get the count.\n    if request.start_timestamp.is_some() || request.end_timestamp.is_some() {\n        return false;\n    }\n    if request.aggregation_request.is_some() || !request.snippet_fields.is_empty() {\n        return false;\n    }\n    true\n}\n\n/// Get a leaf search response that returns the num_docs of the split\npub fn get_count_from_metadata(split_metadatas: &[SplitMetadata]) -> Vec<LeafSearchResponse> {\n    split_metadatas\n        .iter()\n        .map(|metadata| LeafSearchResponse {\n            num_hits: metadata.num_docs as u64,\n            partial_hits: Vec::new(),\n            failed_splits: Vec::new(),\n            num_attempted_splits: 1,\n            intermediate_aggregation_result: None,\n        })\n        .collect()\n}\n\n#[instrument(level = \"debug\", skip_all)]\npub(crate) async fn search_partial_hits_phase(\n    searcher_context: &SearcherContext,\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    search_request: &SearchRequest,\n    split_metadatas: &[SplitMetadata],\n    cluster_client: &ClusterClient,\n) -> crate::Result<LeafSearchResponse> {\n    let leaf_search_responses: Vec<LeafSearchResponse> =\n        if is_metadata_count_request(search_request) {\n            get_count_from_metadata(split_metadatas)\n        } else {\n            let jobs: Vec<SearchJob> = split_metadatas.iter().map(SearchJob::from).collect();\n            let assigned_leaf_search_jobs = cluster_client\n                .search_job_placer\n                .assign_jobs(jobs, &HashSet::default())\n                .await?;\n            let mut leaf_request_tasks = Vec::new();\n            for (client, client_jobs) in assigned_leaf_search_jobs {\n                let leaf_request = jobs_to_leaf_request(\n                    search_request,\n                    indexes_metas_for_leaf_search,\n                    client_jobs,\n                )?;\n                leaf_request_tasks.push(cluster_client.leaf_search(leaf_request, client.clone()));\n            }\n            try_join_all(leaf_request_tasks).await?\n        };\n\n    // Creates a collector which merges responses into one\n    let merge_collector =\n        make_merge_collector(search_request, &searcher_context.get_aggregation_limits())?;\n\n    // Merging is a cpu-bound task.\n    // It should be executed by Tokio's blocking threads.\n\n    // Wrap into result for merge_fruits\n    let leaf_search_responses: Vec<tantivy::Result<LeafSearchResponse>> =\n        leaf_search_responses.into_iter().map(Ok).collect_vec();\n    let span = info_span!(\"merge_fruits\");\n    let leaf_search_response = crate::search_thread_pool()\n        .run_cpu_intensive(move || {\n            let _span_guard = span.enter();\n            merge_collector.merge_fruits(leaf_search_responses)\n        })\n        .await\n        .context(\"failed to merge leaf search responses\")?\n        .map_err(|error: TantivyError| crate::SearchError::Internal(error.to_string()))?;\n    debug!(\n        num_hits = leaf_search_response.num_hits,\n        failed_splits = ?leaf_search_response.failed_splits,\n        num_attempted_splits = leaf_search_response.num_attempted_splits,\n        has_intermediate_aggregation_result = leaf_search_response.intermediate_aggregation_result.is_some(),\n        \"Merged leaf search response.\"\n    );\n    if !leaf_search_response.failed_splits.is_empty() {\n        error!(failed_splits = ?leaf_search_response.failed_splits, \"leaf search response contains at least one failed split\");\n        let errors: String = leaf_search_response.failed_splits.iter().join(\", \");\n        return Err(SearchError::Internal(errors));\n    }\n    Ok(leaf_search_response)\n}\n\npub(crate) fn get_snippet_request(search_request: &SearchRequest) -> Option<SnippetRequest> {\n    if search_request.snippet_fields.is_empty() {\n        return None;\n    }\n    Some(SnippetRequest {\n        snippet_fields: search_request.snippet_fields.clone(),\n        query_ast_resolved: search_request.query_ast.clone(),\n    })\n}\n\n#[instrument(skip_all, fields(partial_hits_num=partial_hits.len()))]\npub(crate) async fn fetch_docs_phase(\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    partial_hits: &[PartialHit],\n    split_metadatas: &[SplitMetadata],\n    search_request: &SearchRequest,\n    cluster_client: &ClusterClient,\n) -> crate::Result<Vec<Hit>> {\n    let snippet_request: Option<SnippetRequest> = get_snippet_request(search_request);\n    let hit_order: HashMap<(String, u32, u32), usize> = partial_hits\n        .iter()\n        .enumerate()\n        .map(|(position, partial_hit)| {\n            let key = (\n                partial_hit.split_id.clone(),\n                partial_hit.segment_ord,\n                partial_hit.doc_id,\n            );\n            (key, position)\n        })\n        .collect();\n\n    let assigned_fetch_docs_jobs = assign_client_fetch_docs_jobs(\n        partial_hits,\n        split_metadatas,\n        &cluster_client.search_job_placer,\n    )\n    .await?;\n\n    let mut fetch_docs_tasks = Vec::new();\n    for (client, client_jobs) in assigned_fetch_docs_jobs {\n        let fetch_jobs_requests = jobs_to_fetch_docs_requests(\n            snippet_request.clone(),\n            indexes_metas_for_leaf_search,\n            client_jobs,\n        )?;\n        for fetch_docs_request in fetch_jobs_requests {\n            fetch_docs_tasks.push(cluster_client.fetch_docs(fetch_docs_request, client.clone()));\n        }\n    }\n    let fetch_docs_responses: Vec<FetchDocsResponse> = try_join_all(fetch_docs_tasks).await?;\n\n    // Merge the fetched docs.\n    let leaf_hits = fetch_docs_responses\n        .into_iter()\n        .flat_map(|response| response.hits.into_iter());\n\n    // Build map of Split ID > index ID to add the index ID to the hits.\n    // Used for ES compatibility.\n    let split_id_to_index_id_map: HashMap<&SplitId, &str> = split_metadatas\n        .iter()\n        .map(|split_metadata| {\n            (\n                &split_metadata.split_id,\n                split_metadata.index_uid.index_id.as_str(),\n            )\n        })\n        .collect();\n    let mut sort_field_iter = search_request.sort_fields.iter();\n    let sort_field_1_datetime_format_opt: Option<SortDatetimeFormat> =\n        get_sort_field_datetime_format(sort_field_iter.next())?;\n    let sort_field_2_datetime_format_opt: Option<SortDatetimeFormat> =\n        get_sort_field_datetime_format(sort_field_iter.next())?;\n    let mut hits_with_position: Vec<(usize, Hit)> = leaf_hits\n        .map(|leaf_hit| {\n            build_hit_with_position(\n                leaf_hit,\n                &split_id_to_index_id_map,\n                &hit_order,\n                &sort_field_1_datetime_format_opt,\n                &sort_field_2_datetime_format_opt,\n            )\n        })\n        .try_collect()?;\n\n    hits_with_position.sort_by_key(|(position, _)| *position);\n    let hits: Vec<Hit> = hits_with_position\n        .into_iter()\n        .map(|(_position, hit)| hit)\n        .collect();\n\n    Ok(hits)\n}\n\nfn build_hit_with_position(\n    mut leaf_hit: LeafHit,\n    split_id_to_index_id_map: &HashMap<&SplitId, &str>,\n    hit_order: &HashMap<(String, u32, u32), usize>,\n    sort_field_1_datetime_format_opt: &Option<SortDatetimeFormat>,\n    sort_field_2_datetime_format_opt: &Option<SortDatetimeFormat>,\n) -> crate::Result<(usize, Hit)> {\n    let partial_hit_ref = leaf_hit\n        .partial_hit\n        .as_mut()\n        .expect(\"partial hit must be present\");\n    let key = (\n        partial_hit_ref.split_id.clone(),\n        partial_hit_ref.segment_ord,\n        partial_hit_ref.doc_id,\n    );\n    let sort_value_opt = partial_hit_ref\n        .sort_value\n        .as_mut()\n        .and_then(|sort_field| sort_field.sort_value.as_mut());\n    if let Some(sort_by_value) = sort_value_opt {\n        if let Some(output_datetime_format) = &sort_field_1_datetime_format_opt {\n            convert_sort_datetime_value(sort_by_value, *output_datetime_format)?;\n        }\n    }\n    let sort_value_2_opt = partial_hit_ref\n        .sort_value2\n        .as_mut()\n        .and_then(|sort_field| sort_field.sort_value.as_mut());\n    if let Some(sort_by_value) = sort_value_2_opt {\n        if let Some(output_datetime_format) = &sort_field_2_datetime_format_opt {\n            convert_sort_datetime_value(sort_by_value, *output_datetime_format)?;\n        }\n    }\n    let position = *hit_order.get(&key).expect(\"hit order must be present\");\n    let index_id = split_id_to_index_id_map\n        .get(&partial_hit_ref.split_id)\n        .map(|split_id| split_id.to_string())\n        .unwrap_or_default();\n\n    Result::<(usize, Hit), SearchError>::Ok((\n        position,\n        Hit {\n            json: leaf_hit.leaf_json,\n            partial_hit: leaf_hit.partial_hit,\n            snippet: leaf_hit.leaf_snippet_json,\n            index_id,\n        },\n    ))\n}\n\nfn get_sort_field_datetime_format(\n    sort_field: Option<&SortField>,\n) -> crate::Result<Option<SortDatetimeFormat>> {\n    if let Some(sort_field) = sort_field {\n        if let Some(sort_field_datetime_format_int) = &sort_field.sort_datetime_format {\n            let sort_field_datetime_format =\n                SortDatetimeFormat::from_i32(*sort_field_datetime_format_int)\n                    .context(\"invalid sort datetime format\")?;\n            return Ok(Some(sort_field_datetime_format));\n        }\n    }\n    Ok(None)\n}\n\n/// Performs a distributed search.\n/// 1. Sends leaf request over gRPC to multiple leaf nodes.\n/// 2. Merges the search results.\n/// 3. Sends fetch docs requests to multiple leaf nodes.\n/// 4. Builds the response with docs and returns.\n#[instrument(skip_all, fields(num_splits=%split_metadatas.len()))]\nasync fn root_search_aux(\n    searcher_context: &SearcherContext,\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    search_request: SearchRequest,\n    split_metadatas: Vec<SplitMetadata>,\n    cluster_client: &ClusterClient,\n) -> crate::Result<SearchResponse> {\n    debug!(split_metadatas = ?PrettySample::new(&split_metadatas, 5));\n    let (first_phase_result, scroll_key_and_start_offset_opt): (\n        LeafSearchResponse,\n        Option<ScrollKeyAndStartOffset>,\n    ) = search_partial_hits_phase_with_scroll(\n        searcher_context,\n        indexes_metas_for_leaf_search,\n        search_request.clone(),\n        &split_metadatas[..],\n        cluster_client,\n    )\n    .await?;\n\n    let hits = fetch_docs_phase(\n        indexes_metas_for_leaf_search,\n        &first_phase_result.partial_hits,\n        &split_metadatas[..],\n        &search_request,\n        cluster_client,\n    )\n    .await?;\n\n    let mut aggregation_result_json_opt = finalize_aggregation_if_any(\n        &search_request,\n        first_phase_result.intermediate_aggregation_result,\n        searcher_context,\n    )?;\n    // In case there is no index, we don't want the response to contain any aggregation structure\n    if indexes_metas_for_leaf_search.is_empty() {\n        aggregation_result_json_opt = None;\n    }\n\n    Ok(SearchResponse {\n        aggregation: aggregation_result_json_opt,\n        num_hits: first_phase_result.num_hits,\n        hits,\n        elapsed_time_micros: 0u64,\n        errors: Vec::new(),\n        scroll_id: scroll_key_and_start_offset_opt\n            .as_ref()\n            .map(ToString::to_string),\n    })\n}\n\nfn finalize_aggregation(\n    intermediate_aggregation_result_bytes_opt: Option<Vec<u8>>,\n    aggregations: QuickwitAggregations,\n    searcher_context: &SearcherContext,\n) -> crate::Result<Option<String>> {\n    let merge_aggregation_result = match aggregations {\n        QuickwitAggregations::FindTraceIdsAggregation(_) => {\n            let Some(intermediate_aggregation_result_bytes) =\n                intermediate_aggregation_result_bytes_opt\n            else {\n                return Ok(None);\n            };\n            // The merge collector has already merged the intermediate results.\n            let aggs: Vec<Span> = postcard::from_bytes(&intermediate_aggregation_result_bytes)?;\n            serde_json::to_string(&aggs)?\n        }\n        QuickwitAggregations::TantivyAggregations(aggregations) => {\n            let intermediate_aggregation_results =\n                if let Some(intermediate_aggregation_result_bytes) =\n                    intermediate_aggregation_result_bytes_opt\n                {\n                    let intermediate_aggregation_results: IntermediateAggregationResults =\n                        postcard::from_bytes(&intermediate_aggregation_result_bytes)?;\n                    intermediate_aggregation_results\n                } else {\n                    // Default, to return correct structure\n                    Default::default()\n                };\n            let final_aggregation_results: AggregationResults = intermediate_aggregation_results\n                .into_final_result(aggregations, &searcher_context.get_aggregation_limits())?;\n            serde_json::to_string(&final_aggregation_results)?\n        }\n    };\n    Ok(Some(merge_aggregation_result))\n}\n\nfn finalize_aggregation_if_any(\n    search_request: &SearchRequest,\n    intermediate_aggregation_result_bytes_opt: Option<Vec<u8>>,\n    searcher_context: &SearcherContext,\n) -> crate::Result<Option<String>> {\n    let Some(aggregations_json) = search_request.aggregation_request.as_ref() else {\n        return Ok(None);\n    };\n    let aggregations: QuickwitAggregations = serde_json::from_str(aggregations_json)?;\n    let aggregation_result_json = finalize_aggregation(\n        intermediate_aggregation_result_bytes_opt,\n        aggregations,\n        searcher_context,\n    )?;\n    Ok(aggregation_result_json)\n}\n\n/// Checks that all of the index researched as found.\n///\n/// An index pattern (= containing a wildcard) not matching is not an error.\n/// A specific index id however must be found.\n///\n/// We put this check here and not in the metastore to make sure the logic is independent\n/// of the metastore implementation, and some different use cases could require different\n/// behaviors. This specification was principally motivated by #4042.\npub fn check_all_index_metadata_found(\n    index_metadatas: &[IndexMetadata],\n    index_id_patterns: &[String],\n) -> crate::Result<()> {\n    let mut index_ids: HashSet<&str> = index_id_patterns\n        .iter()\n        .map(|index_ptn| index_ptn.as_str())\n        .filter(|index_ptn| !index_ptn.contains('*') && !index_ptn.starts_with('-'))\n        .collect();\n\n    if index_ids.is_empty() {\n        // All of the patterns are wildcard patterns.\n        return Ok(());\n    }\n\n    for index_metadata in index_metadatas {\n        index_ids.remove(index_metadata.index_uid.index_id.as_str());\n    }\n\n    if !index_ids.is_empty() {\n        let missing_index_ids = index_ids\n            .into_iter()\n            .map(|missing_index_id| missing_index_id.to_string())\n            .collect();\n        return Err(SearchError::IndexesNotFound {\n            index_ids: missing_index_ids,\n        });\n    }\n\n    Ok(())\n}\n\n/// This function takes in the index metadatas and lists the relevant splits for the search request.\nasync fn refine_and_list_matches(\n    metastore: &mut MetastoreServiceClient,\n    search_request: &mut SearchRequest,\n    indexes_metadata: Vec<IndexMetadata>,\n    query_ast_resolved: QueryAst,\n    sort_fields_is_datetime: HashMap<String, bool>,\n    timestamp_field_opt: Option<String>,\n) -> crate::Result<Vec<SplitMetadata>> {\n    let index_uids = indexes_metadata\n        .iter()\n        .map(|index_metadata| index_metadata.index_uid.clone())\n        .collect_vec();\n    search_request.query_ast = serde_json::to_string(&query_ast_resolved)?;\n\n    // convert search_after datetime values from input datetime format to nanos.\n    convert_search_after_datetime_values(search_request, &sort_fields_is_datetime)?;\n\n    // update_search_after_datetime_in_nanos(&mut search_request)?;\n    if let Some(timestamp_field) = &timestamp_field_opt {\n        refine_start_end_timestamp_from_ast(\n            &query_ast_resolved,\n            timestamp_field,\n            &mut search_request.start_timestamp,\n            &mut search_request.end_timestamp,\n        );\n    }\n    let tag_filter_ast = extract_tags_from_query(query_ast_resolved);\n\n    // TODO if search after is set, we sort by timestamp and we don't want to count all results,\n    // we can refine more here. Same if we sort by _shard_doc\n    let split_metadatas: Vec<SplitMetadata> = list_relevant_splits(\n        index_uids,\n        search_request.start_timestamp,\n        search_request.end_timestamp,\n        tag_filter_ast,\n        metastore,\n    )\n    .await?;\n    Ok(split_metadatas)\n}\n\n/// Performs a distributed search.\n/// 1. Sends leaf request over gRPC to multiple leaf nodes.\n/// 2. Merges the search results.\n/// 3. Sends fetch docs requests to multiple leaf nodes.\n/// 4. Builds the response with docs and returns.\n#[instrument(skip_all)]\npub async fn root_search(\n    // contains split footer cache\n    searcher_context: &SearcherContext,\n    // search request will contains timestamps and tags to prune splits\n    mut search_request: SearchRequest,\n    // metastore client\n    mut metastore: MetastoreServiceClient,\n    // cluster client to communicate between nodes\n    cluster_client: &ClusterClient,\n) -> crate::Result<SearchResponse> {\n    info!(searcher_context = ?searcher_context, search_request = ?search_request);\n    let start_instant = tokio::time::Instant::now();\n    let list_indexes_metadatas_request = ListIndexesMetadataRequest {\n        index_id_patterns: search_request.index_id_patterns.clone(),\n    };\n    let indexes_metadata: Vec<IndexMetadata> = metastore\n        // codegen will generate the correct method call\n        // this will fetch the index metadata from the metastore\n        .list_indexes_metadata(list_indexes_metadatas_request)\n        .await?\n        .deserialize_indexes_metadata()\n        .await?;\n\n    check_all_index_metadata_found(&indexes_metadata[..], &search_request.index_id_patterns[..])?;\n\n    if indexes_metadata.is_empty() {\n        // We go through root_search_aux instead of directly\n        // returning an empty response to make sure we generate\n        // a (pretty useless) scroll id if requested.\n        let mut search_response = root_search_aux(\n            searcher_context,\n            &HashMap::default(),\n            search_request,\n            Vec::new(),\n            cluster_client,\n        )\n        .await?;\n        search_response.elapsed_time_micros = start_instant.elapsed().as_micros() as u64;\n        return Ok(search_response);\n    }\n\n    let request_metadata = validate_request_and_build_metadata(&indexes_metadata, &search_request)?;\n    let split_metadatas = refine_and_list_matches(\n        &mut metastore,\n        &mut search_request,\n        indexes_metadata,\n        request_metadata.query_ast_resolved,\n        request_metadata.sort_fields_is_datetime,\n        request_metadata.timestamp_field_opt,\n    )\n    .await?;\n\n    let mut search_response = root_search_aux(\n        searcher_context,\n        &request_metadata.indexes_meta_for_leaf_search,\n        search_request,\n        split_metadatas,\n        cluster_client,\n    )\n    .await?;\n\n    search_response.elapsed_time_micros = start_instant.elapsed().as_micros() as u64;\n    Ok(search_response)\n}\n\n/// Returns details on how a query would be executed\npub async fn search_plan(\n    mut search_request: SearchRequest,\n    mut metastore: MetastoreServiceClient,\n) -> crate::Result<SearchPlanResponse> {\n    let list_indexes_metadatas_request = ListIndexesMetadataRequest {\n        index_id_patterns: search_request.index_id_patterns.clone(),\n    };\n    let indexes_metadata: Vec<IndexMetadata> = metastore\n        .list_indexes_metadata(list_indexes_metadatas_request)\n        .await?\n        .deserialize_indexes_metadata()\n        .await?;\n\n    check_all_index_metadata_found(&indexes_metadata[..], &search_request.index_id_patterns[..])?;\n    if indexes_metadata.is_empty() {\n        return Ok(SearchPlanResponse {\n            result: serde_json::to_string(&SearchPlanResponseRest {\n                quickwit_ast: QueryAst::MatchAll,\n                tantivy_ast: String::new(),\n                searched_splits: Vec::new(),\n                storage_requests: StorageRequestCount::default(),\n            })?,\n        });\n    }\n    let doc_mapper = build_doc_mapper(\n        &indexes_metadata[0].index_config.doc_mapping,\n        &indexes_metadata[0].index_config.search_settings,\n    )\n    .map_err(|err| SearchError::Internal(format!(\"failed to build doc mapper. cause: {err}\")))?;\n\n    let request_metadata = validate_request_and_build_metadata(&indexes_metadata, &search_request)?;\n    let split_metadatas = refine_and_list_matches(\n        &mut metastore,\n        &mut search_request,\n        indexes_metadata,\n        request_metadata.query_ast_resolved.clone(),\n        request_metadata.sort_fields_is_datetime,\n        request_metadata.timestamp_field_opt,\n    )\n    .await?;\n\n    let (query, mut warmup_info) = doc_mapper.query(\n        doc_mapper.schema(),\n        &request_metadata.query_ast_resolved,\n        true,\n    )?;\n    let merge_collector = make_merge_collector(&search_request, &Default::default())?;\n    warmup_info.merge(merge_collector.warmup_info());\n    warmup_info.simplify();\n\n    let split_ids = split_metadatas\n        .into_iter()\n        .map(|split| format!(\"{}/{}\", split.index_uid.index_id, split.split_id))\n        .collect();\n    // this is an upper bound, we'd need access to a hotdir for more precise results\n    let fieldnorm_query_count = if warmup_info.field_norms {\n        doc_mapper\n            .schema()\n            .fields()\n            .filter(|(_, entry)| entry.has_fieldnorms())\n            .count()\n    } else {\n        0\n    };\n    let sstable_query_count = warmup_info.term_dict_fields.len()\n        + warmup_info\n            .terms_grouped_by_field\n            .values()\n            .map(|terms: &HashMap<tantivy::Term, bool>| terms.len())\n            .sum::<usize>()\n        + warmup_info\n            .term_ranges_grouped_by_field\n            .values()\n            .map(|terms: &HashMap<_, bool>| terms.len())\n            .sum::<usize>();\n    let position_query_count = warmup_info\n        .terms_grouped_by_field\n        .values()\n        .map(|terms: &HashMap<tantivy::Term, bool>| {\n            terms\n                .values()\n                .filter(|load_position| **load_position)\n                .count()\n        })\n        .sum::<usize>()\n        + warmup_info\n            .term_ranges_grouped_by_field\n            .values()\n            .map(|terms: &HashMap<_, bool>| {\n                terms\n                    .values()\n                    .filter(|load_position| **load_position)\n                    .count()\n            })\n            .sum::<usize>();\n    Ok(SearchPlanResponse {\n        result: serde_json::to_string(&SearchPlanResponseRest {\n            quickwit_ast: request_metadata.query_ast_resolved,\n            tantivy_ast: format!(\"{query:#?}\"),\n            searched_splits: split_ids,\n            storage_requests: StorageRequestCount {\n                footer: 1,\n                fastfield: warmup_info.fast_field_names.len(),\n                fieldnorm: fieldnorm_query_count,\n                sstable: sstable_query_count,\n                posting: sstable_query_count,\n                position: position_query_count,\n            },\n        })?,\n    })\n}\n\n/// Converts search after with datetime format to nanoseconds (representation in tantivy).\n/// If the sort field is a datetime field and no datetime format is set, the default format is\n/// milliseconds.\n/// `sort_fields_are_datetime_opt` must be of the same length as `search_request.sort_fields`.\nfn convert_search_after_datetime_values(\n    search_request: &mut SearchRequest,\n    sort_fields_is_datetime: &HashMap<String, bool>,\n) -> crate::Result<()> {\n    for sort_field in search_request.sort_fields.iter_mut() {\n        if *sort_fields_is_datetime\n            .get(&sort_field.field_name)\n            .unwrap_or(&false)\n            && sort_field.sort_datetime_format.is_none()\n        {\n            sort_field.sort_datetime_format = Some(SortDatetimeFormat::UnixTimestampMillis as i32);\n        }\n    }\n    if let Some(partial_hit) = search_request.search_after.as_mut() {\n        let search_after_values = [\n            partial_hit.sort_value.as_mut(),\n            partial_hit.sort_value2.as_mut(),\n        ];\n        for (sort_field, search_after_value_opt) in\n            search_request.sort_fields.iter().zip(search_after_values)\n        {\n            let Some(search_after_sort_by_value) = search_after_value_opt else {\n                continue;\n            };\n            let Some(search_after_sort_value) = search_after_sort_by_value.sort_value.as_mut()\n            else {\n                continue;\n            };\n            let Some(datetime_format_int) = sort_field.sort_datetime_format else {\n                continue;\n            };\n            let input_datetime_format = SortDatetimeFormat::from_i32(datetime_format_int)\n                .context(\"invalid sort datetime format\")?;\n            convert_sort_datetime_value_into_nanos(search_after_sort_value, input_datetime_format)?;\n        }\n    }\n    Ok(())\n}\n\n/// Convert sort values from input datetime format into nanoseconds.\n/// The conversion is done only for U64 and I64 sort values, an error is returned for other types.\nfn convert_sort_datetime_value_into_nanos(\n    sort_value: &mut SortValue,\n    input_format: SortDatetimeFormat,\n) -> crate::Result<()> {\n    match sort_value {\n        SortValue::U64(value) => match input_format {\n            SortDatetimeFormat::UnixTimestampMillis => {\n                *value = value.checked_mul(1_000_000).ok_or_else(|| {\n                    SearchError::Internal(format!(\n                        \"sort value defined in milliseconds is too large and cannot be converted \\\n                         into nanoseconds: {}\",\n                        value\n                    ))\n                })?;\n            }\n            SortDatetimeFormat::UnixTimestampNanos => {\n                // Nothing to do as the internal format is nanos.\n            }\n        },\n        SortValue::I64(value) => match input_format {\n            SortDatetimeFormat::UnixTimestampMillis => {\n                *value = value.checked_mul(1_000_000).ok_or_else(|| {\n                    SearchError::Internal(format!(\n                        \"sort value defined in milliseconds is too large and cannot be converted \\\n                         into nanoseconds: {}\",\n                        value\n                    ))\n                })?;\n            }\n            SortDatetimeFormat::UnixTimestampNanos => {\n                // Nothing to do as the internal format is nanos.\n            }\n        },\n        _ => {\n            return Err(SearchError::Internal(format!(\n                \"datetime conversion are only support for u64 and i64 sort values, not `{:?}`\",\n                sort_value\n            )));\n        }\n    }\n    Ok(())\n}\n\n/// Convert sort values from nanoseconds to the requested output format.\n/// The conversion is done only for U64 and I64 sort values, an error is returned for other types.\nfn convert_sort_datetime_value(\n    sort_value: &mut SortValue,\n    output_format: SortDatetimeFormat,\n) -> crate::Result<()> {\n    match sort_value {\n        SortValue::U64(value) => match output_format {\n            SortDatetimeFormat::UnixTimestampMillis => {\n                *value /= 1_000_000;\n            }\n            SortDatetimeFormat::UnixTimestampNanos => {\n                // Nothing todo as the internal format is in nanos.\n            }\n        },\n        SortValue::I64(value) => match output_format {\n            SortDatetimeFormat::UnixTimestampMillis => {\n                *value /= 1_000_000;\n            }\n            SortDatetimeFormat::UnixTimestampNanos => {\n                // Nothing todo as the internal format is in nanos.\n            }\n        },\n        _ => {\n            return Err(SearchError::Internal(format!(\n                \"datetime conversion are only support for u64 and i64 sort values, not `{:?}`\",\n                sort_value\n            )));\n        }\n    }\n    Ok(())\n}\n\npub(crate) fn refine_start_end_timestamp_from_ast(\n    query_ast: &QueryAst,\n    timestamp_field: &str,\n    start_timestamp: &mut Option<i64>,\n    end_timestamp: &mut Option<i64>,\n) {\n    let mut timestamp_range_extractor = ExtractTimestampRange {\n        timestamp_field,\n        start_timestamp: *start_timestamp,\n        end_timestamp: *end_timestamp,\n    };\n    timestamp_range_extractor\n        .visit(query_ast)\n        .expect(\"can't fail unwrapping Infallible\");\n    *start_timestamp = timestamp_range_extractor.start_timestamp;\n    *end_timestamp = timestamp_range_extractor.end_timestamp;\n}\n\n/// Boundaries identified as being implied by the QueryAst.\n///\n/// `start_timestamp` is to be interpreted as Inclusive (or Unbounded)\n/// `end_timestamp` is to be interpreted as Exclusive (or Unbounded)\n/// In other word, this is a `[start_timestamp..end_timestamp)` interval.\nstruct ExtractTimestampRange<'a> {\n    timestamp_field: &'a str,\n    start_timestamp: Option<i64>,\n    end_timestamp: Option<i64>,\n}\n\nimpl<'a> ExtractTimestampRange<'a> {\n    fn update_start_timestamp(\n        &mut self,\n        lower_bound: &quickwit_query::JsonLiteral,\n        included: bool,\n    ) {\n        use quickwit_query::InterpretUserInput;\n        let Some(lower_bound) = tantivy::DateTime::interpret_json(lower_bound) else {\n            return;\n        };\n        let mut lower_bound = lower_bound.into_timestamp_secs();\n        if !included {\n            // TODO saturating isn't exactly right, we should replace the RangeQuery with\n            // a match_none, but the visitor doesn't allow mutation.\n            lower_bound = lower_bound.saturating_add(1);\n        }\n        self.start_timestamp = Some(\n            self.start_timestamp\n                .map_or(lower_bound, |current| current.max(lower_bound)),\n        );\n    }\n\n    fn update_end_timestamp(&mut self, upper_bound: &quickwit_query::JsonLiteral, included: bool) {\n        use quickwit_query::InterpretUserInput;\n        let Some(upper_bound_timestamp) = tantivy::DateTime::interpret_json(upper_bound) else {\n            return;\n        };\n        let mut upper_bound = upper_bound_timestamp.into_timestamp_secs();\n        let round_up = (upper_bound_timestamp.into_timestamp_nanos() % 1_000_000_000) != 0;\n        if included || round_up {\n            // TODO saturating isn't exactly right, we should replace the RangeQuery with\n            // a match_none, but the visitor doesn't allow mutation.\n            upper_bound = upper_bound.saturating_add(1);\n        }\n        self.end_timestamp = Some(\n            self.end_timestamp\n                .map_or(upper_bound, |current| current.min(upper_bound)),\n        );\n    }\n}\n\nimpl<'a, 'b> QueryAstVisitor<'b> for ExtractTimestampRange<'a> {\n    type Err = std::convert::Infallible;\n\n    fn visit_bool(&mut self, bool_query: &'b BoolQuery) -> Result<(), Self::Err> {\n        // we only want to visit sub-queries which are strict (positive) requirements\n        for ast in bool_query.must.iter().chain(bool_query.filter.iter()) {\n            self.visit(ast)?;\n        }\n        Ok(())\n    }\n\n    fn visit_range(&mut self, range_query: &'b RangeQuery) -> Result<(), Self::Err> {\n        use std::ops::Bound;\n\n        if range_query.field == self.timestamp_field {\n            match &range_query.lower_bound {\n                Bound::Included(lower_bound) => self.update_start_timestamp(lower_bound, true),\n                Bound::Excluded(lower_bound) => self.update_start_timestamp(lower_bound, false),\n                Bound::Unbounded => (),\n            }\n            match &range_query.upper_bound {\n                Bound::Included(upper_bound) => self.update_end_timestamp(upper_bound, true),\n                Bound::Excluded(upper_bound) => self.update_end_timestamp(upper_bound, false),\n                Bound::Unbounded => (),\n            }\n        }\n        Ok(())\n    }\n\n    // if we visit a term, limit the range to DATE..=DATE\n    fn visit_term(&mut self, term_query: &'b TermQuery) -> Result<(), Self::Err> {\n        if term_query.field == self.timestamp_field {\n            // TODO when fixing #3323, this may need to be modified to support numbers too\n            let json_term = quickwit_query::JsonLiteral::String(term_query.value.clone());\n            self.update_start_timestamp(&json_term, true);\n            self.update_end_timestamp(&json_term, true);\n        }\n        Ok(())\n    }\n\n    // if we visit a termset, limit the range to LOWEST..=HIGHEST\n    fn visit_term_set(&mut self, term_query: &'b TermSetQuery) -> Result<(), Self::Err> {\n        if let Some(term_set) = term_query.terms_per_field.get(self.timestamp_field) {\n            // rfc3339 is lexicographically ordered if YEAR <= 9999, so we can use string\n            // ordering to get the start and end quickly.\n            if let Some(first) = term_set.first() {\n                let json_term = quickwit_query::JsonLiteral::String(first.clone());\n                self.update_start_timestamp(&json_term, true);\n            }\n            if let Some(last) = term_set.last() {\n                let json_term = quickwit_query::JsonLiteral::String(last.clone());\n                self.update_end_timestamp(&json_term, true);\n            }\n        }\n        Ok(())\n    }\n}\n\nasync fn assign_client_fetch_docs_jobs(\n    partial_hits: &[PartialHit],\n    split_metadatas: &[SplitMetadata],\n    client_pool: &SearchJobPlacer,\n) -> crate::Result<impl Iterator<Item = (SearchServiceClient, Vec<FetchDocsJob>)>> {\n    let index_uids_and_split_offsets_map: HashMap<String, (IndexUid, SplitIdAndFooterOffsets)> =\n        split_metadatas\n            .iter()\n            .map(|metadata| {\n                (\n                    metadata.split_id().to_string(),\n                    (\n                        metadata.index_uid.clone(),\n                        extract_split_and_footer_offsets(metadata),\n                    ),\n                )\n            })\n            .collect();\n\n    // Group the partial hits per split\n    let mut partial_hits_map: HashMap<String, Vec<PartialHit>> = HashMap::new();\n    for partial_hit in partial_hits.iter() {\n        partial_hits_map\n            .entry(partial_hit.split_id.clone())\n            .or_default()\n            .push(partial_hit.clone());\n    }\n\n    let mut fetch_docs_req_jobs: Vec<FetchDocsJob> = Vec::new();\n    for (split_id, partial_hits) in partial_hits_map {\n        let (index_uid, offsets) = index_uids_and_split_offsets_map\n            .get(&split_id)\n            .ok_or_else(|| {\n                crate::SearchError::Internal(format!(\n                    \"received partial hit from an unknown split {split_id}\"\n                ))\n            })?\n            .clone();\n        let fetch_docs_job = FetchDocsJob {\n            index_uid: index_uid.clone(),\n            offsets,\n            partial_hits,\n        };\n        fetch_docs_req_jobs.push(fetch_docs_job);\n    }\n\n    let assigned_jobs = client_pool\n        .assign_jobs(fetch_docs_req_jobs, &HashSet::new())\n        .await?;\n\n    Ok(assigned_jobs)\n}\n\n// Measure the cost associated to searching in a given split metadata.\nfn compute_split_cost(split_metadata: &SplitMetadata) -> usize {\n    // TODO this formula could be tuned a lot more. The general idea is that there is a fixed\n    // cost to searching a split, plus a somewhat-linear cost depending on the size of the split\n    5 + split_metadata.num_docs / 100_000\n}\n\n/// Builds a LeafSearchRequest to one node, from a list of [`SearchJob`].\npub fn jobs_to_leaf_request(\n    request: &SearchRequest,\n    search_indexes_metadatas: &IndexesMetasForLeafSearch,\n    jobs: Vec<SearchJob>,\n) -> crate::Result<LeafSearchRequest> {\n    let mut search_request_for_leaf = request.clone();\n    search_request_for_leaf.start_offset = 0;\n    search_request_for_leaf.max_hits += request.start_offset;\n\n    let mut leaf_search_request = LeafSearchRequest {\n        search_request: Some(search_request_for_leaf),\n        leaf_requests: Vec::new(),\n        doc_mappers: Vec::new(),\n        index_uris: Vec::new(),\n    };\n\n    let mut added_doc_mappers: HashMap<&str, u32> = HashMap::new();\n    // Group jobs by index uid, as the split offsets are relative to the index.\n    group_jobs_by_index_id(jobs, |job_group| {\n        let index_uid = &job_group[0].index_uid;\n        let search_index_meta = search_indexes_metadatas.get(index_uid).ok_or_else(|| {\n            SearchError::Internal(format!(\n                \"received job for an unknown index {index_uid}. it should never happen\"\n            ))\n        })?;\n        let doc_mapper_ord = *added_doc_mappers\n            .entry(&search_index_meta.doc_mapper_str)\n            .or_insert_with(|| {\n                let ord = leaf_search_request.doc_mappers.len();\n                leaf_search_request\n                    .doc_mappers\n                    .push(search_index_meta.doc_mapper_str.to_string());\n                ord as u32\n            });\n        let index_uri_ord = leaf_search_request.index_uris.len() as u32;\n        leaf_search_request\n            .index_uris\n            .push(search_index_meta.index_uri.to_string());\n\n        let leaf_search_request_ref = LeafRequestRef {\n            split_offsets: job_group.into_iter().map(|job| job.offsets).collect(),\n            doc_mapper_ord,\n            index_uri_ord,\n        };\n        leaf_search_request\n            .leaf_requests\n            .push(leaf_search_request_ref);\n        Ok(())\n    })?;\n    Ok(leaf_search_request)\n}\n\n/// Builds a list of [`FetchDocsRequest`], one per index, from a list of [`FetchDocsJob`].\npub fn jobs_to_fetch_docs_requests(\n    snippet_request_opt: Option<SnippetRequest>,\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    jobs: Vec<FetchDocsJob>,\n) -> crate::Result<Vec<FetchDocsRequest>> {\n    let mut fetch_docs_requests = Vec::new();\n    // Group jobs by index uid.\n    group_by(\n        jobs,\n        |job| &job.index_uid,\n        |fetch_docs_jobs| {\n            let index_uid = &fetch_docs_jobs[0].index_uid;\n\n            let index_meta = indexes_metas_for_leaf_search\n                .get(index_uid)\n                .ok_or_else(|| {\n                    SearchError::Internal(format!(\n                        \"received search job for an unknown index {index_uid}\"\n                    ))\n                })?;\n            let partial_hits: Vec<PartialHit> = fetch_docs_jobs\n                .iter()\n                .flat_map(|fetch_doc_job| fetch_doc_job.partial_hits.iter().cloned())\n                .collect();\n            let split_offsets: Vec<SplitIdAndFooterOffsets> = fetch_docs_jobs\n                .into_iter()\n                .map(|fetch_doc_job| fetch_doc_job.into())\n                .collect();\n            let fetch_docs_req = FetchDocsRequest {\n                partial_hits,\n                split_offsets,\n                index_uri: index_meta.index_uri.to_string(),\n                snippet_request: snippet_request_opt.clone(),\n                doc_mapper: index_meta.doc_mapper_str.clone(),\n            };\n            fetch_docs_requests.push(fetch_docs_req);\n\n            Ok(())\n        },\n    )?;\n    Ok(fetch_docs_requests)\n}\n\n#[cfg(test)]\nmod tests {\n    use std::ops::Range;\n    use std::str::FromStr;\n    use std::sync::{Arc, RwLock};\n\n    use quickwit_common::shared_consts::SCROLL_BATCH_LEN;\n    use quickwit_common::ServiceStream;\n    use quickwit_config::{DocMapping, IndexConfig, IndexingSettings, SearchSettings};\n    use quickwit_indexing::MockSplitBuilder;\n    use quickwit_metastore::{IndexMetadata, ListSplitsRequestExt, ListSplitsResponseExt};\n    use quickwit_proto::metastore::{\n        ListIndexesMetadataResponse, ListSplitsResponse, MockMetastoreService,\n    };\n    use quickwit_proto::search::{\n        ScrollRequest, SortByValue, SortOrder, SortValue, SplitSearchError,\n    };\n    use quickwit_query::query_ast::{qast_helper, qast_json_helper, query_ast_from_user_text};\n    use tantivy::schema::{FAST, STORED, TEXT};\n\n    use super::*;\n    use crate::{searcher_pool_for_test, MockSearchService};\n\n    #[track_caller]\n    fn check_snippet_fields_validation(snippet_fields: &[String]) -> anyhow::Result<()> {\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_text_field(\"title\", TEXT);\n        schema_builder.add_text_field(\"desc\", TEXT | STORED);\n        schema_builder.add_ip_addr_field(\"ip\", FAST | STORED);\n        let schema = schema_builder.build();\n        validate_requested_snippet_fields(&schema, snippet_fields)\n    }\n\n    #[test]\n    fn test_validate_requested_snippet_fields() {\n        check_snippet_fields_validation(&[\"desc\".to_string()]).unwrap();\n        let field_not_stored_err =\n            check_snippet_fields_validation(&[\"title\".to_string()]).unwrap_err();\n        assert_eq!(\n            field_not_stored_err.to_string(),\n            \"the snippet field `title` must be stored\"\n        );\n        let field_doesnotexist_err =\n            check_snippet_fields_validation(&[\"doesnotexist\".to_string()]).unwrap_err();\n        assert_eq!(\n            field_doesnotexist_err.to_string(),\n            \"The field does not exist: 'doesnotexist'\"\n        );\n        let field_is_not_text_err =\n            check_snippet_fields_validation(&[\"ip\".to_string()]).unwrap_err();\n        assert_eq!(\n            field_is_not_text_err.to_string(),\n            \"the snippet field `ip` must be of type `Str`, got `IpAddr`\"\n        );\n    }\n\n    #[test]\n    fn test_get_sort_by_field_entry() {\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_text_field(\"title\", TEXT);\n        schema_builder.add_text_field(\"desc\", TEXT | STORED);\n        schema_builder.add_u64_field(\"timestamp\", FAST | STORED);\n        let schema = schema_builder.build();\n        get_sort_by_field_entry(\"timestamp\", &schema)\n            .unwrap()\n            .unwrap();\n        let sort_by_field_entry_err = get_sort_by_field_entry(\"doesnotexist\", &schema).unwrap_err();\n        assert_eq!(\n            sort_by_field_entry_err.to_string(),\n            \"Invalid argument: unknown field used in `sort by`: doesnotexist\"\n        );\n        for sort_field_name in &[\"_doc\", \"_score\", \"_shard_doc\"] {\n            assert!(get_sort_by_field_entry(sort_field_name, &schema)\n                .unwrap()\n                .is_none());\n        }\n    }\n\n    fn index_metadata_for_multi_indexes_test(index_id: &str, index_uri: &str) -> IndexMetadata {\n        let index_uri = Uri::from_str(index_uri).unwrap();\n        let doc_mapping_json = r#\"{\n            \"mode\": \"lenient\",\n            \"field_mappings\": [\n                {\n                    \"name\": \"timestamp\",\n                    \"type\": \"datetime\",\n                    \"fast\": true\n                },\n                {\n                    \"name\": \"body\",\n                    \"type\": \"text\",\n                    \"stored\": true\n                }\n            ],\n            \"timestamp_field\": \"timestamp\",\n            \"store_source\": true\n        }\"#;\n        let doc_mapping = serde_json::from_str(doc_mapping_json).unwrap();\n        let indexing_settings = IndexingSettings::default();\n        let search_settings = SearchSettings {\n            default_search_fields: vec![\"body\".to_string()],\n        };\n        IndexMetadata::new(IndexConfig {\n            index_id: index_id.to_string(),\n            index_uri,\n            doc_mapping,\n            indexing_settings,\n            search_settings,\n            retention_policy_opt: Default::default(),\n        })\n    }\n\n    #[test]\n    fn test_validate_request_and_build_metadatas_ok() {\n        let request_query_ast = qast_helper(\"body:test\", &[]);\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: serde_json::to_string(&request_query_ast).unwrap(),\n            max_hits: 10,\n            start_offset: 10,\n            sort_fields: vec![\n                SortField {\n                    field_name: \"timestamp\".to_string(),\n                    sort_order: SortOrder::Desc as i32,\n                    sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n                },\n                SortField {\n                    field_name: \"_doc\".to_string(),\n                    sort_order: SortOrder::Asc as i32,\n                    sort_datetime_format: None,\n                },\n            ],\n            ..Default::default()\n        };\n        let index_metadata = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_metadata_with_other_config =\n            index_metadata_for_multi_indexes_test(\"test-index-2\", \"ram:///test-index-2\");\n        let mut index_metadata_no_timestamp =\n            IndexMetadata::for_test(\"test-index-3\", \"ram:///test-index-3\");\n        index_metadata_no_timestamp\n            .index_config\n            .doc_mapping\n            .timestamp_field = None;\n        let request_metadata = validate_request_and_build_metadata(\n            &[\n                index_metadata,\n                index_metadata_with_other_config,\n                index_metadata_no_timestamp,\n            ],\n            &search_request,\n        )\n        .unwrap();\n        assert_eq!(\n            request_metadata.timestamp_field_opt,\n            Some(\"timestamp\".to_string())\n        );\n        assert_eq!(request_metadata.query_ast_resolved, request_query_ast);\n        assert_eq!(request_metadata.indexes_meta_for_leaf_search.len(), 3);\n        assert_eq!(request_metadata.sort_fields_is_datetime.len(), 2);\n        assert_eq!(\n            request_metadata.sort_fields_is_datetime.get(\"timestamp\"),\n            Some(&true)\n        );\n        assert_eq!(\n            request_metadata.sort_fields_is_datetime.get(\"_doc\"),\n            Some(&false)\n        );\n    }\n\n    #[test]\n    fn test_validate_request_and_build_metadatas_fail_with_different_timestamps() {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            start_offset: 10,\n            ..Default::default()\n        };\n        let index_metadata_1 = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let mut index_metadata_2 = IndexMetadata::for_test(\"test-index-2\", \"ram:///test-index-2\");\n        let doc_mapping_json_2 = r#\"{\n            \"mode\": \"lenient\",\n            \"field_mappings\": [\n                {\n                    \"name\": \"timestamp-2\",\n                    \"type\": \"datetime\",\n                    \"fast\": true\n                },\n                {\n                    \"name\": \"body\",\n                    \"type\": \"text\"\n                }\n            ],\n            \"timestamp_field\": \"timestamp-2\",\n            \"store_source\": true\n        }\"#;\n        let doc_mapping_2: DocMapping = serde_json::from_str(doc_mapping_json_2).unwrap();\n        index_metadata_2.index_config.doc_mapping = doc_mapping_2;\n        index_metadata_2\n            .index_config\n            .search_settings\n            .default_search_fields = Vec::new();\n        let timestamp_field_different = validate_request_and_build_metadata(\n            &[index_metadata_1, index_metadata_2],\n            &search_request,\n        )\n        .unwrap_err();\n        assert_eq!(\n            timestamp_field_different.to_string(),\n            \"the timestamp field (if present) must be the same for all indexes\"\n        );\n    }\n\n    #[test]\n    fn test_validate_request_and_build_metadatas_fail_with_different_resolved_qast() {\n        let qast = query_ast_from_user_text(\"test\", None);\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: serde_json::to_string(&qast).unwrap(),\n            max_hits: 10,\n            start_offset: 10,\n            ..Default::default()\n        };\n        let index_metadata_1 = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let mut index_metadata_2 = IndexMetadata::for_test(\"test-index-2\", \"ram:///test-index-2\");\n        index_metadata_2\n            .index_config\n            .search_settings\n            .default_search_fields = vec![\"owner\".to_string()];\n        let timestamp_field_different = validate_request_and_build_metadata(\n            &[index_metadata_1, index_metadata_2],\n            &search_request,\n        )\n        .unwrap_err();\n        assert_eq!(\n            timestamp_field_different.to_string(),\n            \"resolved query ASTs must be the same across indexes. resolving queries with \\\n             different default fields are different between indexes is not supported\"\n        );\n    }\n\n    fn index_metadata_for_multi_indexes_test_with_incompatible_sort_type(\n        index_id: &str,\n        index_uri: &str,\n    ) -> IndexMetadata {\n        let index_uri = Uri::from_str(index_uri).unwrap();\n        let doc_mapping_json = r#\"{\n            \"mode\": \"lenient\",\n            \"field_mappings\": [\n                {\n                    \"name\": \"timestamp\",\n                    \"type\": \"datetime\",\n                    \"fast\": true\n                },\n                {\n                    \"name\": \"body\",\n                    \"type\": \"text\",\n                    \"stored\": true\n                },\n                {\n                    \"name\": \"response_date\",\n                    \"type\": \"i64\",\n                    \"stored\": true,\n                    \"fast\": true\n                }\n            ],\n            \"timestamp_field\": \"timestamp\",\n            \"store_source\": true\n        }\"#;\n        let doc_mapping = serde_json::from_str(doc_mapping_json).unwrap();\n        let indexing_settings = IndexingSettings::default();\n        let search_settings = SearchSettings {\n            default_search_fields: vec![\"body\".to_string()],\n        };\n        IndexMetadata::new(IndexConfig {\n            index_id: index_id.to_string(),\n            index_uri,\n            doc_mapping,\n            indexing_settings,\n            search_settings,\n            retention_policy_opt: Default::default(),\n        })\n    }\n\n    #[test]\n    fn test_validate_request_and_build_metadatas_fail_with_incompatible_sort_field_types() {\n        let request_query_ast = qast_helper(\"body:test\", &[]);\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: serde_json::to_string(&request_query_ast).unwrap(),\n            max_hits: 10,\n            start_offset: 10,\n            sort_fields: vec![SortField {\n                field_name: \"response_date\".to_string(),\n                sort_order: SortOrder::Desc as i32,\n                sort_datetime_format: None,\n            }],\n            ..Default::default()\n        };\n        let index_metadata = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_metadata_with_other_config =\n            index_metadata_for_multi_indexes_test_with_incompatible_sort_type(\n                \"test-index-2\",\n                \"ram:///test-index-2\",\n            );\n        let search_error = validate_request_and_build_metadata(\n            &[index_metadata, index_metadata_with_other_config],\n            &search_request,\n        )\n        .unwrap_err();\n        assert_eq!(\n            search_error.to_string(),\n            \"sort datetime field `response_date` must be of type datetime on all indexes\"\n        );\n    }\n\n    #[test]\n    fn test_convert_sort_datetime_value() {\n        let mut sort_value = SortValue::U64(1617000000000000000);\n        convert_sort_datetime_value(&mut sort_value, SortDatetimeFormat::UnixTimestampMillis)\n            .unwrap();\n        assert_eq!(sort_value, SortValue::U64(1617000000000));\n        let mut sort_value = SortValue::I64(1617000000000000000);\n        convert_sort_datetime_value(&mut sort_value, SortDatetimeFormat::UnixTimestampMillis)\n            .unwrap();\n        assert_eq!(sort_value, SortValue::I64(1617000000000));\n\n        // conversion with float values should fail.\n        let mut sort_value = SortValue::F64(1617000000000000000.0);\n        let error =\n            convert_sort_datetime_value(&mut sort_value, SortDatetimeFormat::UnixTimestampMillis)\n                .unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"internal error: `datetime conversion are only support for u64 and i64 sort values, \\\n             not `F64(1.617e18)``\"\n        );\n    }\n\n    #[test]\n    fn test_convert_sort_datetime_value_into_nanos() {\n        let mut sort_value = SortValue::U64(1617000000000);\n        convert_sort_datetime_value_into_nanos(\n            &mut sort_value,\n            SortDatetimeFormat::UnixTimestampMillis,\n        )\n        .unwrap();\n        assert_eq!(sort_value, SortValue::U64(1617000000000000000));\n        let mut sort_value = SortValue::I64(1617000000000);\n        convert_sort_datetime_value_into_nanos(\n            &mut sort_value,\n            SortDatetimeFormat::UnixTimestampMillis,\n        )\n        .unwrap();\n        assert_eq!(sort_value, SortValue::I64(1617000000000000000));\n\n        // conversion with a too large millisecond value should fail.\n        let mut sort_value = SortValue::I64(1617000000000000);\n        let error = convert_sort_datetime_value_into_nanos(\n            &mut sort_value,\n            SortDatetimeFormat::UnixTimestampMillis,\n        )\n        .unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"internal error: `sort value defined in milliseconds is too large and cannot be \\\n             converted into nanoseconds: 1617000000000000`\"\n        );\n        // conversion with float values should fail.\n        let mut sort_value = SortValue::F64(1617000000000000.0);\n        let error = convert_sort_datetime_value_into_nanos(\n            &mut sort_value,\n            SortDatetimeFormat::UnixTimestampMillis,\n        )\n        .unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"internal error: `datetime conversion are only support for u64 and i64 sort values, \\\n             not `F64(1617000000000000.0)``\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_field_types_with_doc_and_shard_doc() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"_doc\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n            SortField {\n                field_name: \"_shard_doc\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_date_field(\"timestamp\", FAST);\n        schema_builder.add_u64_field(\"id\", FAST);\n        let schema = schema_builder.build();\n        let mut sort_field_are_datetime = HashMap::new();\n        validate_sort_field_types(&schema, &sort_fields, &mut sort_field_are_datetime).unwrap();\n        assert_eq!(sort_field_are_datetime.get(\"_doc\"), Some(&false));\n        assert_eq!(sort_field_are_datetime.get(\"_shard_doc\"), Some(&false));\n    }\n\n    #[test]\n    fn test_validate_sort_field_types_valid() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_date_field(\"timestamp\", FAST);\n        schema_builder.add_u64_field(\"id\", FAST);\n        let schema = schema_builder.build();\n        let mut sort_field_are_datetime = HashMap::new();\n        validate_sort_field_types(&schema, &sort_fields, &mut sort_field_are_datetime).unwrap();\n        assert_eq!(sort_field_are_datetime.get(\"timestamp\"), Some(&true));\n        assert_eq!(sort_field_are_datetime.get(\"id\"), Some(&false));\n    }\n\n    #[test]\n    fn test_validate_sort_field_types_with_inconsistent_datetime_type() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_date_field(\"timestamp\", FAST);\n        schema_builder.add_u64_field(\"id\", FAST);\n        let schema = schema_builder.build();\n        {\n            let mut sort_field_are_datetime = HashMap::new();\n            sort_field_are_datetime.insert(\"timestamp\".to_string(), false);\n            sort_field_are_datetime.insert(\"id\".to_string(), false);\n            let error =\n                validate_sort_field_types(&schema, &sort_fields, &mut sort_field_are_datetime)\n                    .unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"sort datetime field `timestamp` must be of type datetime on all indexes\"\n            );\n        }\n        {\n            let mut sort_field_are_datetime = HashMap::new();\n            sort_field_are_datetime.insert(\"id\".to_string(), true);\n            let error =\n                validate_sort_field_types(&schema, &sort_fields, &mut sort_field_are_datetime)\n                    .unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"sort datetime field `id` must be of type datetime on all indexes\"\n            );\n        }\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_with_datetime_format_ok() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        validate_sort_by_fields_and_search_after(&sort_fields, &None).unwrap();\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_ok() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: Some(SortByValue {\n                sort_value: Some(SortValue::U64(2)),\n            }),\n            split_id: \"\".to_string(),\n            segment_ord: 0,\n            doc_id: 0,\n        };\n        validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap();\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_ok_with_doc_sort_field() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"_doc\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: None,\n            split_id: \"split1\".to_string(),\n            segment_ord: 1,\n            doc_id: 1,\n        };\n        validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap();\n    }\n\n    #[test]\n    fn test_validate_sort_by_field_type() {\n        let mut schema_builder = Schema::builder();\n        let timestamp_field = schema_builder.add_date_field(\"timestamp\", FAST);\n        let id_field = schema_builder.add_u64_field(\"id\", FAST);\n        let no_fast_field = schema_builder.add_u64_field(\"no_fast\", STORED);\n        let text_field = schema_builder.add_text_field(\"text\", STORED);\n        let schema = schema_builder.build();\n        {\n            let sort_by_field_entry = schema.get_field_entry(timestamp_field);\n            validate_sort_by_field_type(sort_by_field_entry, false).unwrap();\n            validate_sort_by_field_type(sort_by_field_entry, true).unwrap();\n        }\n        {\n            let sort_by_field_entry = schema.get_field_entry(id_field);\n            validate_sort_by_field_type(sort_by_field_entry, false).unwrap();\n            let error = validate_sort_by_field_type(sort_by_field_entry, true).unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"Invalid argument: sort by field with a timestamp format must be a datetime field \\\n                 and the field `id` is not\"\n            );\n        }\n        {\n            let sort_by_field_entry = schema.get_field_entry(no_fast_field);\n            let error = validate_sort_by_field_type(sort_by_field_entry, true).unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"Invalid argument: sort by field must be a fast field, please add the fast \\\n                 property to your field `no_fast`\"\n            );\n        }\n        {\n            let sort_by_field_entry = schema.get_field_entry(text_field);\n            let error = validate_sort_by_field_type(sort_by_field_entry, true).unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"Invalid argument: sort by field on type text is currently not supported `text`\"\n            );\n        }\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_invalid_1() {\n        // 2 sort fields + search after with only one sort value is invalid.\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: None,\n            split_id: \"split1\".to_string(),\n            segment_ord: 1,\n            doc_id: 1,\n        };\n        let error =\n            validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: `search_after` must have the same number of sort values as sort by \\\n             fields [\\\"timestamp\\\", \\\"id\\\"]\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_invalid_with_missing_split_id() {\n        // 2 sort fields + search after with only one sort value is invalid.\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"_doc\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: None,\n            split_id: \"\".to_string(),\n            segment_ord: 1,\n            doc_id: 1,\n        };\n        let error =\n            validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: search_after with a sort field `_doc` must define a split ID, \\\n             segment ID and doc ID values\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_valid_1() {\n        // 2 sort fields + search after with only one sort value is invalid.\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: None,\n            split_id: \"split1\".to_string(),\n            segment_ord: 1,\n            doc_id: 1,\n        };\n        let error =\n            validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: `search_after` must have the same number of sort values as sort by \\\n             fields [\\\"timestamp\\\", \\\"id\\\"]\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_by_field_type_invalid() {\n        // sort non-datetime field with a datetime format is invalid.\n        let mut schema_builder = Schema::builder();\n        let field = schema_builder.add_u64_field(\"timestamp\", FAST);\n        let schema = schema_builder.build();\n        let field_entry = schema.get_field_entry(field);\n        let error = validate_sort_by_field_type(field_entry, true).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: sort by field with a timestamp format must be a datetime field and \\\n             the field `timestamp` is not\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_invalid_3() {\n        // 3 sort fields is not possible.\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n        ];\n        let error = validate_sort_by_fields_and_search_after(&sort_fields, &None).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: sort by field must be up to 2 fields, got 3\"\n        );\n    }\n\n    fn mock_partial_hit(\n        split_id: &str,\n        sort_value: u64,\n        doc_id: u32,\n    ) -> quickwit_proto::search::PartialHit {\n        quickwit_proto::search::PartialHit {\n            sort_value: Some(SortValue::U64(sort_value).into()),\n            sort_value2: None,\n            split_id: split_id.to_string(),\n            segment_ord: 1,\n            doc_id,\n        }\n    }\n\n    fn mock_partial_hit_opt_sort_value(\n        split_id: &str,\n        sort_value: Option<u64>,\n        doc_id: u32,\n    ) -> quickwit_proto::search::PartialHit {\n        quickwit_proto::search::PartialHit {\n            sort_value: sort_value.map(|sort_value| SortValue::U64(sort_value).into()),\n            sort_value2: None,\n            split_id: split_id.to_string(),\n            segment_ord: 1,\n            doc_id,\n        }\n    }\n\n    fn get_doc_for_fetch_req(\n        fetch_docs_req: quickwit_proto::search::FetchDocsRequest,\n    ) -> Vec<quickwit_proto::search::LeafHit> {\n        fetch_docs_req\n            .partial_hits\n            .into_iter()\n            .map(|req| quickwit_proto::search::LeafHit {\n                leaf_json: serde_json::to_string_pretty(&serde_json::json!({\n                    \"title\": [req.doc_id.to_string()],\n                    \"body\": [\"test 1\"],\n                    \"url\": [\"http://127.0.0.1/1\"]\n                }))\n                .expect(\"Json serialization should not fail\"),\n                partial_hit: Some(req),\n                leaf_snippet_json: None,\n            })\n            .collect()\n    }\n\n    #[tokio::test]\n    async fn test_root_search_offset_out_of_bounds_1085() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            start_offset: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_indexes_metadata_request| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 3,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split1\", 3, 1),\n                        mock_partial_hit(\"split1\", 2, 2),\n                        mock_partial_hit(\"split1\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split2\", 3, 1),\n                        mock_partial_hit(\"split2\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 5);\n        assert_eq!(search_response.hits.len(), 0);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_single_split() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_list_splits_request| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service = MockSearchService::new();\n        mock_search_service.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 3,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split1\", 3, 1),\n                        mock_partial_hit(\"split1\", 2, 2),\n                        mock_partial_hit(\"split1\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n\n        let searcher_context = SearcherContext::for_test();\n        let search_response = root_search(\n            &searcher_context,\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split1\", 3, 1),\n                        mock_partial_hit(\"split1\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 1,\n                    partial_hits: vec![mock_partial_hit(\"split2\", 2, 2)],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_with_failure() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 2,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                if leaf_search_req.leaf_requests[0].split_offsets.len() == 2 {\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: 2,\n                        partial_hits: vec![\n                            mock_partial_hit(\"split1\", 3, 1),\n                            mock_partial_hit(\"split1\", 1, 3),\n                        ],\n                        failed_splits: vec![SplitSearchError {\n                            error: \"some error\".to_string(),\n                            split_id: \"split2\".to_string(),\n                            retryable_error: true,\n                        }],\n                        num_attempted_splits: 2,\n                        ..Default::default()\n                    })\n                } else {\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: 1,\n                        partial_hits: vec![mock_partial_hit(\"split2\", 2, 2)],\n                        failed_splits: Vec::new(),\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                }\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service_1)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 2);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_sort_heteregeneous_field_ascending(\n    ) -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            sort_fields: vec![SortField {\n                field_name: \"response_date\".to_string(),\n                sort_order: SortOrder::Asc.into(),\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampNanos as i32),\n            }],\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::U64(2u64).into()),\n                            sort_value2: None,\n                            split_id: \"split1\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 0,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: None,\n                            sort_value2: None,\n                            split_id: \"split1\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 1,\n                        },\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 3,\n                    partial_hits: vec![\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::I64(-1i64).into()),\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 1,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::I64(1i64).into()),\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 0,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: None,\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 2,\n                        },\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request.clone(),\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await?;\n\n        assert_eq!(search_response.num_hits, 5);\n        assert_eq!(search_response.hits.len(), 5);\n        assert_eq!(\n            search_response.hits[0].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 1,\n                sort_value: Some(SortValue::I64(-1i64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[1].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 0,\n                sort_value: Some(SortValue::I64(1i64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[2].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split1\".to_string(),\n                segment_ord: 0,\n                doc_id: 0,\n                sort_value: Some(SortValue::U64(2u64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[3].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split1\".to_string(),\n                segment_ord: 0,\n                doc_id: 1,\n                sort_value: None,\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[4].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 2,\n                sort_value: None,\n                sort_value2: None,\n            }\n        );\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_sort_heteregeneous_field_descending(\n    ) -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            sort_fields: vec![SortField {\n                field_name: \"response_date\".to_string(),\n                sort_order: SortOrder::Desc.into(),\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampNanos as i32),\n            }],\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::U64(2u64).into()),\n                            sort_value2: None,\n                            split_id: \"split1\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 0,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: None,\n                            sort_value2: None,\n                            split_id: \"split1\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 1,\n                        },\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 3,\n                    partial_hits: vec![\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::I64(1i64).into()),\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 0,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::I64(-1i64).into()),\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 1,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: None,\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 2,\n                        },\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request.clone(),\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await?;\n\n        assert_eq!(search_response.num_hits, 5);\n        assert_eq!(search_response.hits.len(), 5);\n        assert_eq!(\n            search_response.hits[0].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split1\".to_string(),\n                segment_ord: 0,\n                doc_id: 0,\n                sort_value: Some(SortValue::U64(2u64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[1].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 0,\n                sort_value: Some(SortValue::I64(1i64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[2].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 1,\n                sort_value: Some(SortValue::I64(-1i64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[3].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 2,\n                sort_value: None,\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[4].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split1\".to_string(),\n                segment_ord: 0,\n                doc_id: 1,\n                sort_value: None,\n                sort_value2: None,\n            }\n        );\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_retry_on_other_node() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1\n            .expect_leaf_search()\n            .times(2)\n            .returning(\n                |leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                    let split_ids: Vec<&str> = leaf_search_req.leaf_requests[0]\n                        .split_offsets\n                        .iter()\n                        .map(|metadata| metadata.split_id.as_str())\n                        .collect();\n                    if split_ids == [\"split1\"] {\n                        Ok(quickwit_proto::search::LeafSearchResponse {\n                            num_hits: 2,\n                            partial_hits: vec![\n                                mock_partial_hit(\"split1\", 3, 1),\n                                mock_partial_hit(\"split1\", 1, 3),\n                            ],\n                            failed_splits: Vec::new(),\n                            num_attempted_splits: 1,\n                            ..Default::default()\n                        })\n                    } else if split_ids == [\"split2\"] {\n                        // RETRY REQUEST!\n                        Ok(quickwit_proto::search::LeafSearchResponse {\n                            num_hits: 1,\n                            partial_hits: vec![mock_partial_hit(\"split2\", 2, 2)],\n                            failed_splits: Vec::new(),\n                            num_attempted_splits: 1,\n                            ..Default::default()\n                        })\n                    } else {\n                        panic!(\"unexpected request in test {split_ids:?}\");\n                    }\n                },\n            );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2\n            .expect_leaf_search()\n            .times(1)\n            .returning(\n                |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        // requests from split 2 arrive here - simulate failure\n                        num_hits: 0,\n                        partial_hits: Vec::new(),\n                        failed_splits: vec![SplitSearchError {\n                            error: \"mock_error\".to_string(),\n                            split_id: \"split2\".to_string(),\n                            retryable_error: true,\n                        }],\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                },\n            );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_retry_on_all_nodes() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_indexes_metadata_request| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1\n            .expect_leaf_search()\n            .withf(|leaf_search_req| {\n                leaf_search_req.leaf_requests[0].split_offsets[0].split_id == \"split2\"\n            })\n            .return_once(|_| {\n                // requests from split 2 arrive here - simulate failure.\n                // a retry will be made on the second service.\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 0,\n                    partial_hits: Vec::new(),\n                    failed_splits: vec![SplitSearchError {\n                        error: \"mock_error\".to_string(),\n                        split_id: \"split2\".to_string(),\n                        retryable_error: true,\n                    }],\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            });\n        mock_search_service_1\n            .expect_leaf_search()\n            .withf(|leaf_search_req| {\n                leaf_search_req.leaf_requests[0].split_offsets[0].split_id == \"split1\"\n            })\n            .return_once(|_| {\n                // RETRY REQUEST from split1\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split1\", 3, 1),\n                        mock_partial_hit(\"split1\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            });\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2\n            .expect_leaf_search()\n            .withf(|leaf_search_req| {\n                leaf_search_req.leaf_requests[0].split_offsets[0].split_id == \"split2\"\n            })\n            .return_once(|_| {\n                // retry for split 2 arrive here, simulate success.\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 1,\n                    partial_hits: vec![mock_partial_hit(\"split2\", 2, 2)],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            });\n        mock_search_service_2\n            .expect_leaf_search()\n            .withf(|leaf_search_req| {\n                leaf_search_req.leaf_requests[0].split_offsets[0].split_id == \"split1\"\n            })\n            .return_once(|_| {\n                // requests from split 1 arrive here - simulate failure, then success.\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    // requests from split 2 arrive here - simulate failure\n                    num_hits: 0,\n                    partial_hits: Vec::new(),\n                    failed_splits: vec![SplitSearchError {\n                        error: \"mock_error\".to_string(),\n                        split_id: \"split1\".to_string(),\n                        retryable_error: true,\n                    }],\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            });\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_single_split_retry_single_node() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_list_splits_request| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut first_call = true;\n        let mut mock_search_service = MockSearchService::new();\n        mock_search_service.expect_leaf_search().times(2).returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                // requests from split 2 arrive here - simulate failure, then success\n                if first_call {\n                    first_call = false;\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: 0,\n                        partial_hits: Vec::new(),\n                        failed_splits: vec![SplitSearchError {\n                            error: \"mock_error\".to_string(),\n                            split_id: \"split1\".to_string(),\n                            retryable_error: true,\n                        }],\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                } else {\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: 1,\n                        partial_hits: vec![mock_partial_hit(\"split1\", 2, 2)],\n                        failed_splits: Vec::new(),\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                }\n            },\n        );\n        mock_search_service.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 1);\n        assert_eq!(search_response.hits.len(), 1);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_single_split_retry_single_node_fails() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n\n        let mut mock_search_service = MockSearchService::new();\n        mock_search_service.expect_leaf_search().times(2).returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 0,\n                    partial_hits: Vec::new(),\n                    failed_splits: vec![SplitSearchError {\n                        error: \"mock_error\".to_string(),\n                        split_id: \"split1\".to_string(),\n                        retryable_error: true,\n                    }],\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service.expect_fetch_docs().returning(\n            |_fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Err(SearchError::Internal(\"mockerr docs\".to_string()))\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await;\n        assert!(search_response.is_err());\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_one_splits_two_nodes_but_one_is_failing_for_split(\n    ) -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        // Service1 - broken node.\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                // retry requests from split 1 arrive here\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 1,\n                    partial_hits: vec![mock_partial_hit(\"split1\", 2, 2)],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        // Service2 - working node.\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 0,\n                    partial_hits: Vec::new(),\n                    failed_splits: vec![SplitSearchError {\n                        error: \"mock_error\".to_string(),\n                        split_id: \"split1\".to_string(),\n                        retryable_error: true,\n                    }],\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |_fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Err(SearchError::Internal(\"mockerr docs\".to_string()))\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 1);\n        assert_eq!(search_response.hits.len(), 1);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_one_splits_two_nodes_but_one_is_failing_completely(\n    ) -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n\n        // Service1 - working node.\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 1,\n                    partial_hits: vec![mock_partial_hit(\"split1\", 2, 2)],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        // Service2 - broken node.\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Err(SearchError::Internal(\"mockerr search\".to_string()))\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |_fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Err(SearchError::Internal(\"mockerr docs\".to_string()))\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 1);\n        assert_eq!(search_response.hits.len(), 1);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_invalid_queries() -> anyhow::Result<()> {\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", MockSearchService::new())]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let searcher_context = SearcherContext::for_test();\n        let metastore = MetastoreServiceClient::from_mock(mock_metastore);\n\n        assert!(root_search(\n            &searcher_context,\n            quickwit_proto::search::SearchRequest {\n                index_id_patterns: vec![\"test-index\".to_string()],\n                query_ast: qast_json_helper(\"invalid_field:\\\"test\\\"\", &[\"body\"]),\n                max_hits: 10,\n                ..Default::default()\n            },\n            metastore.clone(),\n            &cluster_client,\n        )\n        .await\n        .is_err());\n\n        assert!(root_search(\n            &searcher_context,\n            quickwit_proto::search::SearchRequest {\n                index_id_patterns: vec![\"test-index\".to_string()],\n                query_ast: qast_json_helper(\"test\", &[\"invalid_field\"]),\n                max_hits: 10,\n                ..Default::default()\n            },\n            metastore,\n            &cluster_client,\n        )\n        .await\n        .is_err());\n\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_invalid_aggregation() -> anyhow::Result<()> {\n        let agg_req = r#\"\n            {\n                \"expensive_colors\": {\n                    \"termss\": {\n                        \"field\": \"color\",\n                        \"order\": {\n                            \"price_stats.max\": \"desc\"\n                        }\n                    },\n                    \"aggs\": {\n                        \"price_stats\" : {\n                            \"stats\": {\n                                \"field\": \"price\"\n                            }\n                        }\n                    }\n                }\n            }\"#;\n\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            aggregation_request: Some(agg_req.to_string()),\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", MockSearchService::new())]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await;\n        assert!(search_response.is_err());\n        assert!(search_response\n            .unwrap_err()\n            .to_string()\n            .starts_with(\"invalid aggregation request: unknown variant `termss`, expected one of\"));\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_invalid_request() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            start_offset: 20_000,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", MockSearchService::new())]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let metastore = MetastoreServiceClient::from_mock(mock_metastore);\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            metastore.clone(),\n            &cluster_client,\n        )\n        .await;\n        assert!(search_response.is_err());\n        assert_eq!(\n            search_response.unwrap_err().to_string(),\n            \"Invalid argument: max value for start_offset is 10_000, but got 20000\",\n        );\n\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 20_000,\n            ..Default::default()\n        };\n\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            metastore,\n            &cluster_client,\n        )\n        .await;\n        assert!(search_response.is_err());\n        assert_eq!(\n            search_response.unwrap_err().to_string(),\n            \"Invalid argument: max value for max_hits is 10_000, but got 20000\",\n        );\n\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_search_plan_multiple_splits() -> anyhow::Result<()> {\n        use quickwit_query::query_ast::{FullTextMode, FullTextParams, FullTextQuery};\n        use quickwit_query::MatchAllOrNone;\n\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test-query\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let search_response = search_plan(\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n        )\n        .await\n        .unwrap();\n        let response: SearchPlanResponseRest =\n            serde_json::from_str(&search_response.result).unwrap();\n        assert_eq!(\n            response,\n            SearchPlanResponseRest {\n                quickwit_ast: QueryAst::FullText(FullTextQuery {\n                    field: \"body\".to_string(),\n                    text: \"test-query\".to_string(),\n                    params: FullTextParams {\n                        tokenizer: None,\n                        mode: FullTextMode::PhraseFallbackToIntersection,\n                        zero_terms_query: MatchAllOrNone::MatchNone,\n                    },\n                    lenient: false,\n                },),\n                tantivy_ast: r#\"BooleanQuery {\n    subqueries: [\n        (\n            Must,\n            TermQuery(Term(field=3, type=Str, \"test\")),\n        ),\n        (\n            Must,\n            TermQuery(Term(field=3, type=Str, \"query\")),\n        ),\n    ],\n    minimum_number_should_match: 0,\n}\"#\n                .to_string(),\n                searched_splits: vec![\n                    \"test-index/split1\".to_string(),\n                    \"test-index/split2\".to_string()\n                ],\n                storage_requests: StorageRequestCount {\n                    footer: 1,\n                    fastfield: 0,\n                    fieldnorm: 0,\n                    sstable: 2,\n                    posting: 2,\n                    position: 0,\n                },\n            }\n        );\n        Ok(())\n    }\n\n    #[test]\n    fn test_extract_timestamp_range_from_ast() {\n        use std::ops::Bound;\n\n        use quickwit_query::JsonLiteral;\n\n        let timestamp_field = \"timestamp\";\n\n        let simple_range = quickwit_query::query_ast::RangeQuery {\n            field: timestamp_field.to_string(),\n            lower_bound: Bound::Included(JsonLiteral::String(\"2021-04-13T22:45:41Z\".to_owned())),\n            upper_bound: Bound::Excluded(JsonLiteral::String(\"2021-05-06T06:51:19Z\".to_owned())),\n        }\n        .into();\n\n        // direct range\n        let mut timestamp_range_extractor = ExtractTimestampRange {\n            timestamp_field,\n            start_timestamp: None,\n            end_timestamp: None,\n        };\n        timestamp_range_extractor.visit(&simple_range).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353941));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283879));\n\n        // range inside a must bool query\n        let bool_query_must = quickwit_query::query_ast::BoolQuery {\n            must: vec![simple_range.clone()],\n            ..Default::default()\n        };\n        timestamp_range_extractor.start_timestamp = None;\n        timestamp_range_extractor.end_timestamp = None;\n        timestamp_range_extractor\n            .visit(&bool_query_must.into())\n            .unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353941));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283879));\n\n        // range inside a should bool query\n        let bool_query_should = quickwit_query::query_ast::BoolQuery {\n            should: vec![simple_range.clone()],\n            ..Default::default()\n        };\n        timestamp_range_extractor.start_timestamp = Some(123);\n        timestamp_range_extractor.end_timestamp = None;\n        timestamp_range_extractor\n            .visit(&bool_query_should.into())\n            .unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(123));\n        assert_eq!(timestamp_range_extractor.end_timestamp, None);\n\n        // start bound was already more restrictive\n        timestamp_range_extractor.start_timestamp = Some(1618601297);\n        timestamp_range_extractor.end_timestamp = Some(i64::MAX);\n        timestamp_range_extractor.visit(&simple_range).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618601297));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283879));\n\n        // end bound was already more restrictive\n        timestamp_range_extractor.start_timestamp = Some(1);\n        timestamp_range_extractor.end_timestamp = Some(1618601297);\n        timestamp_range_extractor.visit(&simple_range).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353941));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1618601297));\n\n        // bounds are (start..end] instead of [start..end)\n        let unusual_bounds = quickwit_query::query_ast::RangeQuery {\n            field: timestamp_field.to_string(),\n            lower_bound: Bound::Excluded(JsonLiteral::String(\"2021-04-13T22:45:41Z\".to_owned())),\n            upper_bound: Bound::Included(JsonLiteral::String(\"2021-05-06T06:51:19Z\".to_owned())),\n        }\n        .into();\n        timestamp_range_extractor.start_timestamp = None;\n        timestamp_range_extractor.end_timestamp = None;\n        timestamp_range_extractor.visit(&unusual_bounds).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353942));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283880));\n\n        let wrong_field = quickwit_query::query_ast::RangeQuery {\n            field: \"other_field\".to_string(),\n            lower_bound: Bound::Included(JsonLiteral::String(\"2021-04-13T22:45:41Z\".to_owned())),\n            upper_bound: Bound::Excluded(JsonLiteral::String(\"2021-05-06T06:51:19Z\".to_owned())),\n        }\n        .into();\n        timestamp_range_extractor.start_timestamp = None;\n        timestamp_range_extractor.end_timestamp = None;\n        timestamp_range_extractor.visit(&wrong_field).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, None);\n        assert_eq!(timestamp_range_extractor.end_timestamp, None);\n\n        let high_precision = quickwit_query::query_ast::RangeQuery {\n            field: timestamp_field.to_string(),\n            lower_bound: Bound::Included(JsonLiteral::String(\n                \"2021-04-13T22:45:41.001Z\".to_owned(),\n            )),\n            upper_bound: Bound::Excluded(JsonLiteral::String(\n                \"2021-05-06T06:51:19.001Z\".to_owned(),\n            )),\n        }\n        .into();\n\n        // the upper bound should be rounded up as to includes documents from X.000 to X.001\n        let mut timestamp_range_extractor = ExtractTimestampRange {\n            timestamp_field,\n            start_timestamp: None,\n            end_timestamp: None,\n        };\n        timestamp_range_extractor.visit(&high_precision).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353941));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283880));\n    }\n\n    fn create_search_resp(\n        index_uri: &str,\n        hit_range: Range<usize>,\n        search_after: Option<PartialHit>,\n    ) -> LeafSearchResponse {\n        let (num_total_hits, split_id) = match index_uri {\n            \"ram:///test-index-1\" => (TOTAL_NUM_HITS_INDEX_1, \"split1\"),\n            \"ram:///test-index-2\" => (TOTAL_NUM_HITS_INDEX_2, \"split2\"),\n            _ => panic!(\"unexpected index uri\"),\n        };\n\n        let doc_ids = (0..num_total_hits)\n            .rev()\n            .filter(|elem| {\n                if let Some(search_after) = &search_after {\n                    if split_id == search_after.split_id {\n                        *elem < (search_after.doc_id as usize)\n                    } else {\n                        split_id < search_after.split_id.as_str()\n                    }\n                } else {\n                    true\n                }\n            })\n            .skip(hit_range.start)\n            .take(hit_range.end - hit_range.start);\n        quickwit_proto::search::LeafSearchResponse {\n            num_hits: num_total_hits as u64,\n            partial_hits: doc_ids\n                .map(|doc_id| mock_partial_hit_opt_sort_value(split_id, None, doc_id as u32))\n                .collect(),\n            num_attempted_splits: 1,\n            ..Default::default()\n        }\n    }\n\n    const TOTAL_NUM_HITS_INDEX_1: usize = 2_005;\n    const TOTAL_NUM_HITS_INDEX_2: usize = 10;\n    const MAX_HITS_PER_PAGE: usize = 93;\n    const MAX_HITS_PER_PAGE_LARGE: usize = 1_005;\n\n    #[tokio::test]\n    async fn test_root_search_with_scroll() {\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_uid = index_metadata.index_uid.clone();\n        let index_metadata_2 = IndexMetadata::for_test(\"test-index-2\", \"ram:///test-index-2\");\n        let index_uid_2 = index_metadata_2.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                let indexes_metadata = vec![index_metadata.clone(), index_metadata_2.clone()];\n                Ok(ListIndexesMetadataResponse::for_test(indexes_metadata))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid_2)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        // We add two mock_search_service to simulate a multi node environment, where the requests\n        // are forwarded two node.\n        let mut mock_search_service1 = MockSearchService::new();\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_none());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n\n        let mut mock_search_service2 = MockSearchService::new();\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_none());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n\n        let kv: Arc<RwLock<HashMap<Vec<u8>, Vec<u8>>>> = Default::default();\n        let kv_clone = kv.clone();\n        mock_search_service1\n            .expect_put_kv()\n            .returning(move |put_kv_req| {\n                kv_clone\n                    .write()\n                    .unwrap()\n                    .insert(put_kv_req.key, put_kv_req.payload);\n            });\n        mock_search_service1\n            .expect_get_kv()\n            .returning(move |get_kv_req| kv.read().unwrap().get(&get_kv_req.key).cloned());\n\n        let kv: Arc<RwLock<HashMap<Vec<u8>, Vec<u8>>>> = Default::default();\n        let kv_clone = kv.clone();\n        mock_search_service2\n            .expect_put_kv()\n            .returning(move |put_kv_req| {\n                kv_clone\n                    .write()\n                    .unwrap()\n                    .insert(put_kv_req.key, put_kv_req.payload);\n            });\n        mock_search_service2\n            .expect_get_kv()\n            .returning(move |get_kv_req| kv.read().unwrap().get(&get_kv_req.key).cloned());\n\n        mock_search_service1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                assert!(fetch_docs_req.partial_hits.len() <= MAX_HITS_PER_PAGE);\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n\n        mock_search_service2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                assert!(fetch_docs_req.partial_hits.len() <= MAX_HITS_PER_PAGE);\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service1),\n            (\"127.0.0.1:1002\", mock_search_service2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let searcher_context = SearcherContext::for_test();\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n\n        let mut count_seen_hits = 0;\n\n        let mut scroll_id: String = {\n            let search_request = quickwit_proto::search::SearchRequest {\n                index_id_patterns: vec![\"test-index-*\".to_string()],\n                query_ast: qast_json_helper(\"test\", &[\"body\"]),\n                max_hits: MAX_HITS_PER_PAGE as u64,\n                scroll_ttl_secs: Some(60),\n                ..Default::default()\n            };\n            let search_response = root_search(\n                &searcher_context,\n                search_request,\n                MetastoreServiceClient::from_mock(mock_metastore),\n                &cluster_client,\n            )\n            .await\n            .unwrap();\n            assert_eq!(\n                search_response.num_hits,\n                (TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2) as u64\n            );\n            assert_eq!(search_response.hits.len(), MAX_HITS_PER_PAGE);\n            let expected = (0..TOTAL_NUM_HITS_INDEX_2)\n                .rev()\n                .zip(std::iter::repeat(\"split2\"))\n                .chain(\n                    (0..TOTAL_NUM_HITS_INDEX_1)\n                        .rev()\n                        .zip(std::iter::repeat(\"split1\")),\n                );\n            for (hit, (doc_id, split)) in search_response.hits.iter().zip(expected) {\n                assert_eq!(\n                    hit.partial_hit.as_ref().unwrap(),\n                    &mock_partial_hit_opt_sort_value(split, None, doc_id as u32)\n                );\n            }\n            count_seen_hits += search_response.hits.len();\n            search_response.scroll_id.unwrap()\n        };\n        for page in 1.. {\n            let scroll_req = ScrollRequest {\n                scroll_id,\n                scroll_ttl_secs: Some(60),\n            };\n            let scroll_resp =\n                crate::service::scroll(scroll_req, &cluster_client, &searcher_context)\n                    .await\n                    .unwrap();\n            assert_eq!(\n                scroll_resp.num_hits,\n                (TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2) as u64\n            );\n            let expected = (0..TOTAL_NUM_HITS_INDEX_2)\n                .rev()\n                .zip(std::iter::repeat(\"split2\"))\n                .chain(\n                    (0..TOTAL_NUM_HITS_INDEX_1)\n                        .rev()\n                        .zip(std::iter::repeat(\"split1\")),\n                )\n                .skip(page * MAX_HITS_PER_PAGE);\n            for (hit, (doc_id, split)) in scroll_resp.hits.iter().zip(expected) {\n                assert_eq!(\n                    hit.partial_hit.as_ref().unwrap(),\n                    &mock_partial_hit_opt_sort_value(split, None, doc_id as u32)\n                );\n            }\n            scroll_id = scroll_resp.scroll_id.unwrap();\n            count_seen_hits += scroll_resp.hits.len();\n            if scroll_resp.hits.is_empty() {\n                break;\n            }\n        }\n\n        assert_eq!(\n            count_seen_hits,\n            TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2\n        );\n    }\n\n    #[tokio::test]\n    async fn test_root_search_with_scroll_large_page() {\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_uid = index_metadata.index_uid.clone();\n        let index_metadata_2 = IndexMetadata::for_test(\"test-index-2\", \"ram:///test-index-2\");\n        let index_uid_2 = index_metadata_2.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                let indexes_metadata = vec![index_metadata.clone(), index_metadata_2.clone()];\n                Ok(ListIndexesMetadataResponse::for_test(indexes_metadata))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid_2)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        // We add two mock_search_service to simulate a multi node environment, where the requests\n        // are forwarded two nodes.\n        let mut mock_search_service1 = MockSearchService::new();\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_none());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        let kv: Arc<RwLock<HashMap<Vec<u8>, Vec<u8>>>> = Default::default();\n        let kv_clone = kv.clone();\n        mock_search_service1\n            .expect_put_kv()\n            .returning(move |put_kv_req| {\n                kv_clone\n                    .write()\n                    .unwrap()\n                    .insert(put_kv_req.key, put_kv_req.payload);\n            });\n        mock_search_service1\n            .expect_get_kv()\n            .returning(move |get_kv_req| kv.read().unwrap().get(&get_kv_req.key).cloned());\n        mock_search_service1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                assert!(fetch_docs_req.partial_hits.len() <= MAX_HITS_PER_PAGE_LARGE);\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n\n        let mut mock_search_service2 = MockSearchService::new();\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_none());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        let kv: Arc<RwLock<HashMap<Vec<u8>, Vec<u8>>>> = Default::default();\n        let kv_clone = kv.clone();\n        mock_search_service2\n            .expect_put_kv()\n            .returning(move |put_kv_req| {\n                kv_clone\n                    .write()\n                    .unwrap()\n                    .insert(put_kv_req.key, put_kv_req.payload);\n            });\n        mock_search_service2\n            .expect_get_kv()\n            .returning(move |get_kv_req| kv.read().unwrap().get(&get_kv_req.key).cloned());\n        mock_search_service2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                assert!(fetch_docs_req.partial_hits.len() <= MAX_HITS_PER_PAGE_LARGE);\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service1),\n            (\"127.0.0.1:1002\", mock_search_service2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let searcher_context = SearcherContext::for_test();\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n\n        let mut count_seen_hits = 0;\n\n        let mut scroll_id: String = {\n            let search_request = quickwit_proto::search::SearchRequest {\n                index_id_patterns: vec![\"test-index-*\".to_string()],\n                query_ast: qast_json_helper(\"test\", &[\"body\"]),\n                max_hits: MAX_HITS_PER_PAGE_LARGE as u64,\n                scroll_ttl_secs: Some(60),\n                ..Default::default()\n            };\n            let search_response = root_search(\n                &searcher_context,\n                search_request,\n                MetastoreServiceClient::from_mock(mock_metastore),\n                &cluster_client,\n            )\n            .await\n            .unwrap();\n            assert_eq!(\n                search_response.num_hits,\n                (TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2) as u64\n            );\n            assert_eq!(search_response.hits.len(), MAX_HITS_PER_PAGE_LARGE);\n            let expected = (0..TOTAL_NUM_HITS_INDEX_2)\n                .rev()\n                .zip(std::iter::repeat(\"split2\"))\n                .chain(\n                    (0..TOTAL_NUM_HITS_INDEX_1)\n                        .rev()\n                        .zip(std::iter::repeat(\"split1\")),\n                );\n            for (hit, (doc_id, split)) in search_response.hits.iter().zip(expected) {\n                assert_eq!(\n                    hit.partial_hit.as_ref().unwrap(),\n                    &mock_partial_hit_opt_sort_value(split, None, doc_id as u32)\n                );\n            }\n            count_seen_hits += search_response.hits.len();\n            search_response.scroll_id.unwrap()\n        };\n        for page in 1.. {\n            let scroll_req = ScrollRequest {\n                scroll_id,\n                scroll_ttl_secs: Some(60),\n            };\n            let scroll_resp =\n                crate::service::scroll(scroll_req, &cluster_client, &searcher_context)\n                    .await\n                    .unwrap();\n            assert_eq!(\n                scroll_resp.num_hits,\n                (TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2) as u64\n            );\n            let expected = (0..TOTAL_NUM_HITS_INDEX_2)\n                .rev()\n                .zip(std::iter::repeat(\"split2\"))\n                .chain(\n                    (0..TOTAL_NUM_HITS_INDEX_1)\n                        .rev()\n                        .zip(std::iter::repeat(\"split1\")),\n                )\n                .skip(page * MAX_HITS_PER_PAGE_LARGE);\n            for (hit, (doc_id, split)) in scroll_resp.hits.iter().zip(expected) {\n                assert_eq!(\n                    hit.partial_hit.as_ref().unwrap(),\n                    &mock_partial_hit_opt_sort_value(split, None, doc_id as u32)\n                );\n            }\n            scroll_id = scroll_resp.scroll_id.unwrap();\n            count_seen_hits += scroll_resp.hits.len();\n            if scroll_resp.hits.is_empty() {\n                break;\n            }\n        }\n\n        assert_eq!(\n            count_seen_hits,\n            TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2\n        );\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multi_indices() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index-*\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata_1 = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_uid_1 = index_metadata_1.index_uid.clone();\n        let index_metadata_2 =\n            index_metadata_for_multi_indexes_test(\"test-index-2\", \"ram:///test-index-2\");\n        let index_uid_2 = index_metadata_2.index_uid.clone();\n        let index_metadata_3 =\n            index_metadata_for_multi_indexes_test(\"test-index-3\", \"ram:///test-index-3\");\n        let index_uid_3 = index_metadata_3.index_uid.clone();\n        mock_metastore.expect_list_indexes_metadata().return_once(\n            move |list_indexes_metadata_request: ListIndexesMetadataRequest| {\n                let index_id_patterns = list_indexes_metadata_request.index_id_patterns;\n                assert_eq!(&index_id_patterns, &[\"test-index-*\".to_string()]);\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata_1,\n                    index_metadata_2,\n                    index_metadata_3,\n                ]))\n            },\n        );\n        mock_metastore\n            .expect_list_splits()\n            .return_once(move |list_splits_request| {\n                let list_splits_query =\n                    list_splits_request.deserialize_list_splits_query().unwrap();\n                assert!(\n                    list_splits_query.index_uids\n                        == vec![\n                            index_uid_1.clone(),\n                            index_uid_2.clone(),\n                            index_uid_3.clone()\n                        ]\n                );\n                let splits = vec![\n                    MockSplitBuilder::new(\"index-1-split-1\")\n                        .with_index_uid(&index_uid_1)\n                        .build(),\n                    MockSplitBuilder::new(\"index-1-split-2\")\n                        .with_index_uid(&index_uid_1)\n                        .build(),\n                    MockSplitBuilder::new(\"index-2-split-1\")\n                        .with_index_uid(&index_uid_2)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1\n            .expect_leaf_search()\n            .times(1)\n            .withf(|leaf_search_req| {\n                (&leaf_search_req.index_uris[0] == \"ram:///test-index-1\"\n                    && leaf_search_req.leaf_requests[0].split_offsets.len() == 2)\n                    || (leaf_search_req.index_uris[0] == \"ram:///test-index-2\"\n                        && leaf_search_req.leaf_requests[0].split_offsets[0].split_id\n                            == \"index-2-split-1\")\n            })\n            .returning(\n                |leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                    let mut partial_hits = leaf_search_req.leaf_requests[0]\n                        .split_offsets\n                        .iter()\n                        .map(|split_offset| mock_partial_hit(&split_offset.split_id, 3, 1))\n                        .collect_vec();\n                    let partial_hits2 = leaf_search_req.leaf_requests[1]\n                        .split_offsets\n                        .iter()\n                        .map(|split_offset| mock_partial_hit(&split_offset.split_id, 3, 1))\n                        .collect_vec();\n                    partial_hits.extend_from_slice(&partial_hits2);\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: leaf_search_req.leaf_requests[0].split_offsets.len() as u64\n                            + leaf_search_req.leaf_requests[1].split_offsets.len() as u64,\n                        partial_hits,\n                        failed_splits: Vec::new(),\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                },\n            );\n        mock_search_service_1\n            .expect_fetch_docs()\n            .times(2)\n            .withf(|fetch_docs_req: &FetchDocsRequest| {\n                (fetch_docs_req.index_uri == \"ram:///test-index-1\"\n                    && fetch_docs_req.partial_hits.len() == 2)\n                    || (fetch_docs_req.index_uri == \"ram:///test-index-2\"\n                        && fetch_docs_req.partial_hits[0].split_id == \"index-2-split-1\")\n            })\n            .returning(|fetch_docs_req| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            });\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service_1)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        assert_eq!(\n            search_response\n                .hits\n                .iter()\n                .map(|hit| &hit.index_id)\n                .collect_vec(),\n            vec![\"test-index-1\", \"test-index-1\", \"test-index-2\"]\n        );\n        Ok(())\n    }\n}\n```\nasync fn search_partial_hits_phase_with_scroll(\nexplain me this fun \n\n### Purpose\nThe function `search_partial_hits_phase_with_scroll` is designed to perform a search operation that retrieves partial hits (i.e., subsets of the total search results) in a paginated manner using a scroll mechanism. This is useful for handling large result sets that cannot be fetched in a single request due to memory or performance constraints.\n\n### Context\nIn search engines, a scroll mechanism allows clients to retrieve large sets of search results in chunks (or pages) rather than all at once. This is particularly useful for deep pagination and for efficiently handling large datasets.\n\n### Key Components\n1. **Async Function**: The function is asynchronous, meaning it can perform non-blocking I/O operations and can be awaited.\n2. **Partial Hits**: Refers to subsets of the total search results.\n3. **Scroll Mechanism**: A method to paginate through search results.\n\n### Function Breakdown\nLet's break down the function step-by-step. Note that the actual implementation details will depend on the specific codebase and libraries used.\n\n```rust\nasync fn search_partial_hits_phase_with_scroll(\n    query: Query, // The search query\n    index: Index, // The index to search against\n    scroll_id: Option<String>, // Optional scroll identifier for pagination\n    page_size: usize, // Number of results per page\n) -> Result<PartialHits, SearchError> {\n    // Step 1: Initialize the scroll context if not provided\n    let scroll_context = match scroll_id {\n        Some(id) => ScrollContext::from_id(id),\n        None => ScrollContext::new(),\n    };\n\n    // Step 2: Execute the search query with the scroll context\n    let search_results = index.search_with_scroll(query, scroll_context, page_size).await?;\n\n    // Step 3: Process the search results to extract partial hits\n    let partial_hits = process_search_results(search_results);\n\n    // Step 4: Return the partial hits along with the updated scroll context\n    Ok(partial_hits)\n}\n```\n\n### Detailed Explanation\n1. **Function Signature**:\n   - `async fn`: Indicates that the function is asynchronous.\n   - `search_partial_hits_phase_with_scroll`: The name of the function.\n   - Parameters:\n     - `query: Query`: The search query to be executed.\n     - `index: Index`: The index against which the search is performed.\n     - `scroll_id: Option<String>`: An optional scroll identifier for pagination.\n     - `page_size: usize`: The number of results to retrieve per page.\n   - Return Type: `Result<PartialHits, SearchError>`: The function returns a `Result` containing either `PartialHits` or a `SearchError`.\n\n2. **Step 1: Initialize the Scroll Context**:\n   - The function checks if a `scroll_id` is provided.\n   - If a `scroll_id` is provided, it initializes the `ScrollContext` using the existing `scroll_id`.\n   - If no `scroll_id` is provided, it creates a new `ScrollContext`.\n\n3. **Step 2: Execute the Search Query**:\n   - The function executes the search query using the `index` and the `scroll_context`.\n   - The `page_size` parameter determines the number of results to retrieve in this request.\n   - The search operation is awaited, meaning the function will pause until the search results are available.\n\n4. **Step 3: Process the Search Results**:\n   - The function processes the search results to extract partial hits.\n   - This step may involve filtering, sorting, or transforming the raw search results into a more usable format.\n\n5. **Step 4: Return the Partial Hits**:\n   - The function returns the partial hits along with the updated scroll context.\n   - The `Ok(partial_hits)` indicates a successful operation, while any errors encountered would be returned as `SearchError`.\n\n### Conclusion\nThe `search_partial_hits_phase_with_scroll` function is designed to handle paginated search results using a scroll mechanism. It initializes the scroll context, executes the search query, processes the results, and returns the partial hits. This approach is efficient for handling large datasets and deep pagination in search applications.\n\n\n```rs quickwit/quickwit/quickwit-search/src/root.rs\n// Copyright (C) 2024 Quickwit, Inc.\n//\n// Quickwit is offered under the AGPL v3.0 and as commercial software.\n// For commercial licensing, contact us at hello@quickwit.io.\n//\n// AGPL:\n// This program is free software: you can redistribute it and/or modify\n// it under the terms of the GNU Affero General Public License as\n// published by the Free Software Foundation, either version 3 of the\n// License, or (at your option) any later version.\n//\n// This program is distributed in the hope that it will be useful,\n// but WITHOUT ANY WARRANTY; without even the implied warranty of\n// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n// GNU Affero General Public License for more details.\n//\n// You should have received a copy of the GNU Affero General Public License\n// along with this program. If not, see <http://www.gnu.org/licenses/>.\n\nuse std::collections::{HashMap, HashSet};\nuse std::sync::OnceLock;\nuse std::time::Duration;\n\nuse anyhow::Context;\nuse futures::future::try_join_all;\nuse itertools::Itertools;\nuse quickwit_common::pretty::PrettySample;\nuse quickwit_common::shared_consts;\nuse quickwit_common::uri::Uri;\nuse quickwit_config::build_doc_mapper;\nuse quickwit_doc_mapper::tag_pruning::extract_tags_from_query;\nuse quickwit_doc_mapper::DYNAMIC_FIELD_NAME;\nuse quickwit_metastore::{IndexMetadata, ListIndexesMetadataResponseExt, SplitMetadata};\nuse quickwit_proto::metastore::{\n    ListIndexesMetadataRequest, MetastoreService, MetastoreServiceClient,\n};\nuse quickwit_proto::search::{\n    FetchDocsRequest, FetchDocsResponse, Hit, LeafHit, LeafRequestRef, LeafSearchRequest,\n    LeafSearchResponse, PartialHit, SearchPlanResponse, SearchRequest, SearchResponse,\n    SnippetRequest, SortDatetimeFormat, SortField, SortValue, SplitIdAndFooterOffsets,\n};\nuse quickwit_proto::types::{IndexUid, SplitId};\nuse quickwit_query::query_ast::{\n    BoolQuery, QueryAst, QueryAstVisitor, RangeQuery, TermQuery, TermSetQuery,\n};\nuse serde::{Deserialize, Serialize};\nuse tantivy::aggregation::agg_result::AggregationResults;\nuse tantivy::aggregation::intermediate_agg_result::IntermediateAggregationResults;\nuse tantivy::collector::Collector;\nuse tantivy::schema::{FieldEntry, FieldType, Schema};\nuse tantivy::TantivyError;\nuse tracing::{debug, error, info, info_span, instrument};\n\nuse crate::cluster_client::ClusterClient;\nuse crate::collector::{make_merge_collector, QuickwitAggregations};\nuse crate::find_trace_ids_collector::Span;\nuse crate::scroll_context::{ScrollContext, ScrollKeyAndStartOffset};\nuse crate::search_job_placer::{group_by, group_jobs_by_index_id, Job};\nuse crate::search_response_rest::StorageRequestCount;\nuse crate::service::SearcherContext;\nuse crate::{\n    extract_split_and_footer_offsets, list_relevant_splits, SearchError, SearchJobPlacer,\n    SearchPlanResponseRest, SearchServiceClient,\n};\n\n/// Maximum accepted scroll TTL.\nfn max_scroll_ttl() -> Duration {\n    static MAX_SCROLL_TTL_LOCK: OnceLock<Duration> = OnceLock::new();\n    *MAX_SCROLL_TTL_LOCK.get_or_init(|| {\n        let split_deletion_grace_period = shared_consts::split_deletion_grace_period();\n        assert!(\n            split_deletion_grace_period >= shared_consts::MINIMUM_DELETION_GRACE_PERIOD,\n            \"The split deletion grace period is too short ({split_deletion_grace_period:?}). This \\\n             should not happen.\"\n        );\n        // We remove an extra margin of 2minutes from the split deletion grace period.\n        split_deletion_grace_period - Duration::from_secs(60 * 2)\n    })\n}\n\nconst SORT_DOC_FIELD_NAMES: &[&str] = &[\"_shard_doc\", \"_doc\"];\n\n/// SearchJob to be assigned to search clients by the [`SearchJobPlacer`].\n#[derive(Debug, Clone, PartialEq)]\npub struct SearchJob {\n    /// The index UID.\n    pub index_uid: IndexUid,\n    cost: usize,\n    /// The split ID and footer offsets of the split.\n    pub offsets: SplitIdAndFooterOffsets,\n}\n\nimpl SearchJob {\n    #[cfg(test)]\n    pub fn for_test(split_id: &str, cost: usize) -> SearchJob {\n        use std::str::FromStr;\n        SearchJob {\n            index_uid: IndexUid::from_str(\"test-index:00000000000000000000000000\").unwrap(),\n            cost,\n            offsets: SplitIdAndFooterOffsets {\n                split_id: split_id.to_string(),\n                ..Default::default()\n            },\n        }\n    }\n}\n\nimpl From<SearchJob> for SplitIdAndFooterOffsets {\n    fn from(search_job: SearchJob) -> Self {\n        search_job.offsets\n    }\n}\n\nimpl<'a> From<&'a SplitMetadata> for SearchJob {\n    fn from(split_metadata: &'a SplitMetadata) -> Self {\n        SearchJob {\n            index_uid: split_metadata.index_uid.clone(),\n            cost: compute_split_cost(split_metadata),\n            offsets: extract_split_and_footer_offsets(split_metadata),\n        }\n    }\n}\n\nimpl Job for SearchJob {\n    fn split_id(&self) -> &str {\n        &self.offsets.split_id\n    }\n\n    fn cost(&self) -> usize {\n        self.cost\n    }\n}\n\npub struct FetchDocsJob {\n    index_uid: IndexUid,\n    offsets: SplitIdAndFooterOffsets,\n    pub partial_hits: Vec<PartialHit>,\n}\n\nimpl Job for FetchDocsJob {\n    fn split_id(&self) -> &str {\n        &self.offsets.split_id\n    }\n\n    fn cost(&self) -> usize {\n        self.partial_hits.len()\n    }\n}\n\nimpl From<FetchDocsJob> for SplitIdAndFooterOffsets {\n    fn from(fetch_docs_job: FetchDocsJob) -> SplitIdAndFooterOffsets {\n        fetch_docs_job.offsets\n    }\n}\n\n/// Index metas needed for executing a leaf search request.\n#[derive(Serialize, Deserialize, Clone, Debug)]\npub struct IndexMetasForLeafSearch {\n    /// Index URI.\n    pub index_uri: Uri,\n    /// Doc mapper json string.\n    pub doc_mapper_str: String,\n}\n\npub(crate) type IndexesMetasForLeafSearch = HashMap<IndexUid, IndexMetasForLeafSearch>;\n\n#[derive(Debug)]\nstruct RequestMetadata {\n    timestamp_field_opt: Option<String>,\n    query_ast_resolved: QueryAst,\n    indexes_meta_for_leaf_search: IndexesMetasForLeafSearch,\n    sort_fields_is_datetime: HashMap<String, bool>,\n}\n\n/// Validates request against each index's doc mapper and ensures that:\n/// - timestamp fields (if any) are equal across indexes.\n/// - resolved query ASTs are the same across indexes.\n/// - if a sort field is of type datetime, it must be a datetime field on all indexes. This\n///   constraint come from the need to support datetime formatting on sort values.\n/// Returns the timestamp field, the resolved query AST and the indexes metadatas\n/// needed for leaf search requests.\n/// Note: the requirements on timestamp fields and resolved query ASTs can be lifted\n/// but it adds complexity that does not seem needed right now.\nfn validate_request_and_build_metadata(\n    indexes_metadata: &[IndexMetadata],\n    search_request: &SearchRequest,\n) -> crate::Result<RequestMetadata> {\n    validate_sort_by_fields_and_search_after(\n        &search_request.sort_fields,\n        &search_request.search_after,\n    )?;\n    let query_ast: QueryAst = serde_json::from_str(&search_request.query_ast)\n        .map_err(|err| SearchError::InvalidQuery(err.to_string()))?;\n    let mut indexes_meta_for_leaf_search: HashMap<IndexUid, IndexMetasForLeafSearch> =\n        HashMap::new();\n    let mut query_ast_resolved_opt: Option<QueryAst> = None;\n    let mut timestamp_field_opt: Option<String> = None;\n    let mut sort_fields_is_datetime: HashMap<String, bool> = HashMap::new();\n\n    for index_metadata in indexes_metadata {\n        let doc_mapper = build_doc_mapper(\n            &index_metadata.index_config.doc_mapping,\n            &index_metadata.index_config.search_settings,\n        )\n        .map_err(|err| {\n            SearchError::Internal(format!(\"failed to build doc mapper. cause: {err}\"))\n        })?;\n        let query_ast_resolved_for_index = query_ast\n            .clone()\n            .parse_user_query(doc_mapper.default_search_fields())\n            // We convert the error to return a 400 to the user (and not a 500).\n            .map_err(|err| SearchError::InvalidQuery(err.to_string()))?;\n\n        // Validate uniqueness of resolved query AST.\n        if let Some(query_ast_resolved) = &query_ast_resolved_opt {\n            if query_ast_resolved != &query_ast_resolved_for_index {\n                return Err(SearchError::InvalidQuery(\n                    \"resolved query ASTs must be the same across indexes. resolving queries with \\\n                     different default fields are different between indexes is not supported\"\n                        .to_string(),\n                ));\n            }\n        } else {\n            query_ast_resolved_opt = Some(query_ast_resolved_for_index.clone());\n        }\n\n        // Validate uniqueness of timestamp field if any.\n        if let Some(timestamp_field_for_index) = doc_mapper.timestamp_field_name() {\n            match timestamp_field_opt {\n                Some(timestamp_field) if timestamp_field != timestamp_field_for_index => {\n                    return Err(SearchError::InvalidQuery(\n                        \"the timestamp field (if present) must be the same for all indexes\"\n                            .to_string(),\n                    ));\n                }\n                None => {\n                    timestamp_field_opt = Some(timestamp_field_for_index.to_string());\n                }\n                _ => {}\n            }\n        }\n\n        // Validate request against the current index schema.\n        let schema = doc_mapper.schema();\n        validate_request(&schema, &doc_mapper.timestamp_field_name(), search_request)?;\n\n        validate_sort_field_types(\n            &schema,\n            &search_request.sort_fields,\n            &mut sort_fields_is_datetime,\n        )?;\n\n        // Validates the query by effectively building it against the current schema.\n        doc_mapper.query(doc_mapper.schema(), &query_ast_resolved_for_index, true)?;\n\n        let index_metadata_for_leaf_search = IndexMetasForLeafSearch {\n            index_uri: index_metadata.index_uri().clone(),\n            doc_mapper_str: serde_json::to_string(&doc_mapper).map_err(|err| {\n                SearchError::Internal(format!(\"failed to serialize doc mapper. cause: {err}\"))\n            })?,\n        };\n        indexes_meta_for_leaf_search.insert(\n            index_metadata.index_uid.clone(),\n            index_metadata_for_leaf_search,\n        );\n    }\n\n    let query_ast_resolved = query_ast_resolved_opt.ok_or_else(|| {\n        SearchError::Internal(\n            \"resolved query AST must be present. this should never happen\".to_string(),\n        )\n    })?;\n\n    Ok(RequestMetadata {\n        timestamp_field_opt,\n        query_ast_resolved,\n        indexes_meta_for_leaf_search,\n        sort_fields_is_datetime,\n    })\n}\n\n/// Validate sort field types.\nfn validate_sort_field_types(\n    schema: &Schema,\n    sort_fields: &[SortField],\n    sort_field_is_datetime: &mut HashMap<String, bool>,\n) -> crate::Result<()> {\n    for sort_field in sort_fields.iter() {\n        if let Some(sort_field_entry) = get_sort_by_field_entry(&sort_field.field_name, schema)? {\n            validate_sort_by_field_type(\n                sort_field_entry,\n                sort_field.sort_datetime_format.is_some(),\n            )?;\n            // If sort field type is a date, ensure it's true for all indexes.\n            if let Some(is_datetime) = sort_field_is_datetime.get(&sort_field.field_name) {\n                if *is_datetime != sort_field_entry.field_type().is_date() {\n                    return Err(SearchError::InvalidQuery(format!(\n                        \"sort datetime field `{}` must be of type datetime on all indexes\",\n                        sort_field_entry.name(),\n                    )));\n                }\n            } else {\n                sort_field_is_datetime.insert(\n                    sort_field.field_name.to_string(),\n                    sort_field_entry.field_type().is_date(),\n                );\n            }\n        } else {\n            sort_field_is_datetime.insert(sort_field.field_name.to_string(), false);\n        }\n    }\n    Ok(())\n}\n\nfn validate_requested_snippet_fields(\n    schema: &Schema,\n    snippet_fields: &[String],\n) -> anyhow::Result<()> {\n    for field_name in snippet_fields {\n        let field_entry = schema\n            .get_field(field_name)\n            .map(|field| schema.get_field_entry(field))?;\n        match field_entry.field_type() {\n            FieldType::Str(text_options) => {\n                if !text_options.is_stored() {\n                    return Err(anyhow::anyhow!(\n                        \"the snippet field `{}` must be stored\",\n                        field_name\n                    ));\n                }\n            }\n            other => {\n                return Err(anyhow::anyhow!(\n                    \"the snippet field `{}` must be of type `Str`, got `{}`\",\n                    field_name,\n                    other.value_type().name()\n                ))\n            }\n        }\n    }\n    Ok(())\n}\n\nfn simplify_search_request_for_scroll_api(req: &SearchRequest) -> crate::Result<SearchRequest> {\n    if req.search_after.is_some() {\n        return Err(SearchError::InvalidArgument(\n            \"search_after cannot be used in a scroll context\".to_string(),\n        ));\n    }\n\n    // We do not mutate\n    Ok(SearchRequest {\n        index_id_patterns: req.index_id_patterns.clone(),\n        query_ast: req.query_ast.clone(),\n        start_timestamp: req.start_timestamp,\n        end_timestamp: req.end_timestamp,\n        max_hits: req.max_hits,\n        start_offset: req.start_offset,\n        sort_fields: req.sort_fields.clone(),\n        // We remove all aggregation request.\n        // The aggregation will not be computed for each scroll request.\n        aggregation_request: None,\n        // We remove the snippet fields. This feature is not supported for scroll requests.\n        snippet_fields: Vec::new(),\n        // We remove the scroll ttl parameter. It is irrelevant to process later request\n        scroll_ttl_secs: None,\n        search_after: None,\n        // request is simplified after initial query, and we cache the hit count, so we don't need\n        // to recompute it afterward.\n        count_hits: quickwit_proto::search::CountHits::Underestimate as i32,\n    })\n}\n\n/// Validates sort fields and search after values.\n/// - validate sort fields length.\n/// - search after values must be set for all sort fields.\nfn validate_sort_by_fields_and_search_after(\n    sort_fields: &[SortField],\n    search_after: &Option<PartialHit>,\n) -> crate::Result<()> {\n    if sort_fields.is_empty() {\n        return Ok(());\n    }\n    if sort_fields.len() > 2 {\n        return Err(SearchError::InvalidArgument(format!(\n            \"sort by field must be up to 2 fields, got {}\",\n            sort_fields.len()\n        )));\n    }\n    let Some(search_after_partial_hit) = search_after.as_ref() else {\n        return Ok(());\n    };\n\n    let sort_fields_without_doc_count = sort_fields\n        .iter()\n        .filter(|sort_field| !SORT_DOC_FIELD_NAMES.contains(&sort_field.field_name.as_str()))\n        .count();\n    let has_doc_sort_field = sort_fields_without_doc_count != sort_fields.len();\n    if has_doc_sort_field && search_after_partial_hit.split_id.is_empty() {\n        return Err(SearchError::InvalidArgument(\n            \"search_after with a sort field `_doc` must define a split ID, segment ID and doc ID \\\n             values\"\n                .to_string(),\n        ));\n    }\n\n    let mut search_after_sort_value_count = 0;\n    // TODO: we could validate if the search after sort value types of consistent with the sort\n    // field types.\n    if let Some(sort_by_value) = search_after_partial_hit.sort_value.as_ref() {\n        sort_by_value.sort_value.context(\"sort value must be set\")?;\n        search_after_sort_value_count += 1;\n    }\n    if let Some(sort_by_value_2) = search_after_partial_hit.sort_value2.as_ref() {\n        sort_by_value_2\n            .sort_value\n            .context(\"sort value must be set\")?;\n        search_after_sort_value_count += 1;\n    }\n    if search_after_sort_value_count != sort_fields_without_doc_count {\n        return Err(SearchError::InvalidArgument(format!(\n            \"`search_after` must have the same number of sort values as sort by fields {:?}\",\n            sort_fields\n                .iter()\n                .map(|sort_field| &sort_field.field_name)\n                .collect_vec()\n        )));\n    }\n    Ok(())\n}\n\nfn get_sort_by_field_entry<'a>(\n    field_name: &str,\n    schema: &'a Schema,\n) -> crate::Result<Option<&'a FieldEntry>> {\n    if \"_score\" == field_name || SORT_DOC_FIELD_NAMES.contains(&field_name) {\n        return Ok(None);\n    }\n    let dynamic_field_opt = schema.get_field(DYNAMIC_FIELD_NAME).ok();\n    let (sort_by_field, _json_path) = schema\n        .find_field_with_default(field_name, dynamic_field_opt)\n        .ok_or_else(|| {\n            SearchError::InvalidArgument(format!(\"unknown field used in `sort by`: {field_name}\"))\n        })?;\n    let sort_by_field_entry = schema.get_field_entry(sort_by_field);\n    Ok(Some(sort_by_field_entry))\n}\n\n/// Validates sort field type.\nfn validate_sort_by_field_type(\n    sort_by_field_entry: &FieldEntry,\n    has_timestamp_format: bool,\n) -> crate::Result<()> {\n    let field_name = sort_by_field_entry.name();\n    if matches!(sort_by_field_entry.field_type(), FieldType::Str(_)) {\n        return Err(SearchError::InvalidArgument(format!(\n            \"sort by field on type text is currently not supported `{field_name}`\"\n        )));\n    }\n    if !sort_by_field_entry.is_fast() {\n        return Err(SearchError::InvalidArgument(format!(\n            \"sort by field must be a fast field, please add the fast property to your field \\\n             `{field_name}`\",\n        )));\n    }\n    if has_timestamp_format && !sort_by_field_entry.field_type().is_date() {\n        return Err(SearchError::InvalidArgument(format!(\n            \"sort by field with a timestamp format must be a datetime field and the field \\\n             `{field_name}` is not\",\n        )));\n    }\n    Ok(())\n}\n\nfn validate_request(\n    schema: &Schema,\n    timestamp_field_name: &Option<&str>,\n    search_request: &SearchRequest,\n) -> crate::Result<()> {\n    if timestamp_field_name.is_none()\n        && (search_request.start_timestamp.is_some() || search_request.end_timestamp.is_some())\n    {\n        return Err(SearchError::InvalidQuery(format!(\n            \"the timestamp field is not set in index: {:?} definition but start-timestamp or \\\n             end-timestamp are set in the query\",\n            search_request.index_id_patterns\n        )));\n    }\n\n    validate_requested_snippet_fields(schema, &search_request.snippet_fields)?;\n\n    if let Some(agg) = search_request.aggregation_request.as_ref() {\n        let _aggs: QuickwitAggregations = serde_json::from_str(agg).map_err(|_err| {\n            let err = serde_json::from_str::<tantivy::aggregation::agg_req::Aggregations>(agg)\n                .unwrap_err();\n            SearchError::InvalidAggregationRequest(err.to_string())\n        })?;\n    };\n\n    if search_request.start_offset > 10_000 {\n        return Err(SearchError::InvalidArgument(format!(\n            \"max value for start_offset is 10_000, but got {}\",\n            search_request.start_offset\n        )));\n    }\n\n    if search_request.max_hits > 10_000 {\n        return Err(SearchError::InvalidArgument(format!(\n            \"max value for max_hits is 10_000, but got {}\",\n            search_request.max_hits\n        )));\n    }\n\n    Ok(())\n}\n\nfn get_scroll_ttl_duration(search_request: &SearchRequest) -> crate::Result<Option<Duration>> {\n    let Some(scroll_ttl_secs) = search_request.scroll_ttl_secs else {\n        return Ok(None);\n    };\n    let scroll_ttl: Duration = Duration::from_secs(scroll_ttl_secs as u64);\n    let max_scroll_ttl = max_scroll_ttl();\n    if scroll_ttl > max_scroll_ttl {\n        return Err(SearchError::InvalidArgument(format!(\n            \"Quickwit only supports scroll TTL period up to {} secs\",\n            max_scroll_ttl.as_secs()\n        )));\n    }\n    Ok(Some(scroll_ttl))\n}\n\n#[instrument(level = \"debug\", skip_all)]\nasync fn search_partial_hits_phase_with_scroll(\n    searcher_context: &SearcherContext,\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    mut search_request: SearchRequest,\n    split_metadatas: &[SplitMetadata],\n    cluster_client: &ClusterClient,\n) -> crate::Result<(LeafSearchResponse, Option<ScrollKeyAndStartOffset>)> {\n    let scroll_ttl_opt = get_scroll_ttl_duration(&search_request)?;\n\n    if let Some(scroll_ttl) = scroll_ttl_opt {\n        let max_hits = search_request.max_hits;\n        // This is a scroll request.\n        //\n        // We increase max hits to add populate the scroll cache.\n        search_request.max_hits = search_request\n            .max_hits\n            .max(shared_consts::SCROLL_BATCH_LEN as u64);\n        search_request.scroll_ttl_secs = None;\n        let mut leaf_search_resp = search_partial_hits_phase(\n            searcher_context,\n            indexes_metas_for_leaf_search,\n            &search_request,\n            split_metadatas,\n            cluster_client,\n        )\n        .await?;\n        let cached_partial_hits = leaf_search_resp.partial_hits.clone();\n        leaf_search_resp.partial_hits.truncate(max_hits as usize);\n        let last_hit = leaf_search_resp\n            .partial_hits\n            .last()\n            .cloned()\n            .unwrap_or_default();\n\n        let scroll_context_search_request =\n            simplify_search_request_for_scroll_api(&search_request)?;\n        let mut scroll_ctx = ScrollContext {\n            indexes_metas_for_leaf_search: indexes_metas_for_leaf_search.clone(),\n            split_metadatas: split_metadatas.to_vec(),\n            search_request: scroll_context_search_request,\n            total_num_hits: leaf_search_resp.num_hits,\n            max_hits_per_page: max_hits,\n            cached_partial_hits_start_offset: search_request.start_offset,\n            cached_partial_hits,\n        };\n        let scroll_key_and_start_offset: ScrollKeyAndStartOffset =\n            ScrollKeyAndStartOffset::new_with_start_offset(\n                scroll_ctx.search_request.start_offset,\n                max_hits as u32,\n                last_hit.clone(),\n            )\n            .next_page(leaf_search_resp.partial_hits.len() as u64, last_hit);\n\n        scroll_ctx.clear_cache_if_unneeded();\n        let payload: Vec<u8> = scroll_ctx.serialize();\n        let scroll_key = scroll_key_and_start_offset.scroll_key();\n        cluster_client\n            .put_kv(&scroll_key, &payload, scroll_ttl)\n            .await;\n        Ok((leaf_search_resp, Some(scroll_key_and_start_offset)))\n    } else {\n        let leaf_search_resp = search_partial_hits_phase(\n            searcher_context,\n            indexes_metas_for_leaf_search,\n            &search_request,\n            split_metadatas,\n            cluster_client,\n        )\n        .await?;\n        Ok((leaf_search_resp, None))\n    }\n}\n\n/// Check if the request is a count request without any filters, so we can just return the split\n/// metadata count.\n///\n/// This is done by exclusion, so we will need to keep it up to date if fields are added.\npub fn is_metadata_count_request(request: &SearchRequest) -> bool {\n    let query_ast: QueryAst = serde_json::from_str(&request.query_ast).unwrap();\n    is_metadata_count_request_with_ast(&query_ast, request)\n}\n\n/// Check if the request is a count request without any filters, so we can just return the split\n/// metadata count.\n///\n/// This is done by exclusion, so we will need to keep it up to date if fields are added.\n///\n/// The passed query_ast should match the serialized on in request.\npub fn is_metadata_count_request_with_ast(query_ast: &QueryAst, request: &SearchRequest) -> bool {\n    if query_ast != &QueryAst::MatchAll {\n        return false;\n    }\n    if request.max_hits != 0 {\n        return false;\n    }\n\n    // If the start and end timestamp encompass the whole split, it is still a count query.\n    // We remove this currently on the leaf level, but not yet on the root level.\n    // There's a small advantage when we would do this on the root level, since we have the\n    // counts available on the split. On the leaf it is currently required to open the split\n    // to get the count.\n    if request.start_timestamp.is_some() || request.end_timestamp.is_some() {\n        return false;\n    }\n    if request.aggregation_request.is_some() || !request.snippet_fields.is_empty() {\n        return false;\n    }\n    true\n}\n\n/// Get a leaf search response that returns the num_docs of the split\npub fn get_count_from_metadata(split_metadatas: &[SplitMetadata]) -> Vec<LeafSearchResponse> {\n    split_metadatas\n        .iter()\n        .map(|metadata| LeafSearchResponse {\n            num_hits: metadata.num_docs as u64,\n            partial_hits: Vec::new(),\n            failed_splits: Vec::new(),\n            num_attempted_splits: 1,\n            intermediate_aggregation_result: None,\n        })\n        .collect()\n}\n\n#[instrument(level = \"debug\", skip_all)]\npub(crate) async fn search_partial_hits_phase(\n    searcher_context: &SearcherContext,\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    search_request: &SearchRequest,\n    split_metadatas: &[SplitMetadata],\n    cluster_client: &ClusterClient,\n) -> crate::Result<LeafSearchResponse> {\n    let leaf_search_responses: Vec<LeafSearchResponse> =\n        if is_metadata_count_request(search_request) {\n            get_count_from_metadata(split_metadatas)\n        } else {\n            let jobs: Vec<SearchJob> = split_metadatas.iter().map(SearchJob::from).collect();\n            let assigned_leaf_search_jobs = cluster_client\n                .search_job_placer\n                .assign_jobs(jobs, &HashSet::default())\n                .await?;\n            let mut leaf_request_tasks = Vec::new();\n            for (client, client_jobs) in assigned_leaf_search_jobs {\n                let leaf_request = jobs_to_leaf_request(\n                    search_request,\n                    indexes_metas_for_leaf_search,\n                    client_jobs,\n                )?;\n                leaf_request_tasks.push(cluster_client.leaf_search(leaf_request, client.clone()));\n            }\n            try_join_all(leaf_request_tasks).await?\n        };\n\n    // Creates a collector which merges responses into one\n    let merge_collector =\n        make_merge_collector(search_request, &searcher_context.get_aggregation_limits())?;\n\n    // Merging is a cpu-bound task.\n    // It should be executed by Tokio's blocking threads.\n\n    // Wrap into result for merge_fruits\n    let leaf_search_responses: Vec<tantivy::Result<LeafSearchResponse>> =\n        leaf_search_responses.into_iter().map(Ok).collect_vec();\n    let span = info_span!(\"merge_fruits\");\n    let leaf_search_response = crate::search_thread_pool()\n        .run_cpu_intensive(move || {\n            let _span_guard = span.enter();\n            merge_collector.merge_fruits(leaf_search_responses)\n        })\n        .await\n        .context(\"failed to merge leaf search responses\")?\n        .map_err(|error: TantivyError| crate::SearchError::Internal(error.to_string()))?;\n    debug!(\n        num_hits = leaf_search_response.num_hits,\n        failed_splits = ?leaf_search_response.failed_splits,\n        num_attempted_splits = leaf_search_response.num_attempted_splits,\n        has_intermediate_aggregation_result = leaf_search_response.intermediate_aggregation_result.is_some(),\n        \"Merged leaf search response.\"\n    );\n    if !leaf_search_response.failed_splits.is_empty() {\n        error!(failed_splits = ?leaf_search_response.failed_splits, \"leaf search response contains at least one failed split\");\n        let errors: String = leaf_search_response.failed_splits.iter().join(\", \");\n        return Err(SearchError::Internal(errors));\n    }\n    Ok(leaf_search_response)\n}\n\npub(crate) fn get_snippet_request(search_request: &SearchRequest) -> Option<SnippetRequest> {\n    if search_request.snippet_fields.is_empty() {\n        return None;\n    }\n    Some(SnippetRequest {\n        snippet_fields: search_request.snippet_fields.clone(),\n        query_ast_resolved: search_request.query_ast.clone(),\n    })\n}\n\n#[instrument(skip_all, fields(partial_hits_num=partial_hits.len()))]\npub(crate) async fn fetch_docs_phase(\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    partial_hits: &[PartialHit],\n    split_metadatas: &[SplitMetadata],\n    search_request: &SearchRequest,\n    cluster_client: &ClusterClient,\n) -> crate::Result<Vec<Hit>> {\n    let snippet_request: Option<SnippetRequest> = get_snippet_request(search_request);\n    let hit_order: HashMap<(String, u32, u32), usize> = partial_hits\n        .iter()\n        .enumerate()\n        .map(|(position, partial_hit)| {\n            let key = (\n                partial_hit.split_id.clone(),\n                partial_hit.segment_ord,\n                partial_hit.doc_id,\n            );\n            (key, position)\n        })\n        .collect();\n\n    let assigned_fetch_docs_jobs = assign_client_fetch_docs_jobs(\n        partial_hits,\n        split_metadatas,\n        &cluster_client.search_job_placer,\n    )\n    .await?;\n\n    let mut fetch_docs_tasks = Vec::new();\n    for (client, client_jobs) in assigned_fetch_docs_jobs {\n        let fetch_jobs_requests = jobs_to_fetch_docs_requests(\n            snippet_request.clone(),\n            indexes_metas_for_leaf_search,\n            client_jobs,\n        )?;\n        for fetch_docs_request in fetch_jobs_requests {\n            fetch_docs_tasks.push(cluster_client.fetch_docs(fetch_docs_request, client.clone()));\n        }\n    }\n    let fetch_docs_responses: Vec<FetchDocsResponse> = try_join_all(fetch_docs_tasks).await?;\n\n    // Merge the fetched docs.\n    let leaf_hits = fetch_docs_responses\n        .into_iter()\n        .flat_map(|response| response.hits.into_iter());\n\n    // Build map of Split ID > index ID to add the index ID to the hits.\n    // Used for ES compatibility.\n    let split_id_to_index_id_map: HashMap<&SplitId, &str> = split_metadatas\n        .iter()\n        .map(|split_metadata| {\n            (\n                &split_metadata.split_id,\n                split_metadata.index_uid.index_id.as_str(),\n            )\n        })\n        .collect();\n    let mut sort_field_iter = search_request.sort_fields.iter();\n    let sort_field_1_datetime_format_opt: Option<SortDatetimeFormat> =\n        get_sort_field_datetime_format(sort_field_iter.next())?;\n    let sort_field_2_datetime_format_opt: Option<SortDatetimeFormat> =\n        get_sort_field_datetime_format(sort_field_iter.next())?;\n    let mut hits_with_position: Vec<(usize, Hit)> = leaf_hits\n        .map(|leaf_hit| {\n            build_hit_with_position(\n                leaf_hit,\n                &split_id_to_index_id_map,\n                &hit_order,\n                &sort_field_1_datetime_format_opt,\n                &sort_field_2_datetime_format_opt,\n            )\n        })\n        .try_collect()?;\n\n    hits_with_position.sort_by_key(|(position, _)| *position);\n    let hits: Vec<Hit> = hits_with_position\n        .into_iter()\n        .map(|(_position, hit)| hit)\n        .collect();\n\n    Ok(hits)\n}\n\nfn build_hit_with_position(\n    mut leaf_hit: LeafHit,\n    split_id_to_index_id_map: &HashMap<&SplitId, &str>,\n    hit_order: &HashMap<(String, u32, u32), usize>,\n    sort_field_1_datetime_format_opt: &Option<SortDatetimeFormat>,\n    sort_field_2_datetime_format_opt: &Option<SortDatetimeFormat>,\n) -> crate::Result<(usize, Hit)> {\n    let partial_hit_ref = leaf_hit\n        .partial_hit\n        .as_mut()\n        .expect(\"partial hit must be present\");\n    let key = (\n        partial_hit_ref.split_id.clone(),\n        partial_hit_ref.segment_ord,\n        partial_hit_ref.doc_id,\n    );\n    let sort_value_opt = partial_hit_ref\n        .sort_value\n        .as_mut()\n        .and_then(|sort_field| sort_field.sort_value.as_mut());\n    if let Some(sort_by_value) = sort_value_opt {\n        if let Some(output_datetime_format) = &sort_field_1_datetime_format_opt {\n            convert_sort_datetime_value(sort_by_value, *output_datetime_format)?;\n        }\n    }\n    let sort_value_2_opt = partial_hit_ref\n        .sort_value2\n        .as_mut()\n        .and_then(|sort_field| sort_field.sort_value.as_mut());\n    if let Some(sort_by_value) = sort_value_2_opt {\n        if let Some(output_datetime_format) = &sort_field_2_datetime_format_opt {\n            convert_sort_datetime_value(sort_by_value, *output_datetime_format)?;\n        }\n    }\n    let position = *hit_order.get(&key).expect(\"hit order must be present\");\n    let index_id = split_id_to_index_id_map\n        .get(&partial_hit_ref.split_id)\n        .map(|split_id| split_id.to_string())\n        .unwrap_or_default();\n\n    Result::<(usize, Hit), SearchError>::Ok((\n        position,\n        Hit {\n            json: leaf_hit.leaf_json,\n            partial_hit: leaf_hit.partial_hit,\n            snippet: leaf_hit.leaf_snippet_json,\n            index_id,\n        },\n    ))\n}\n\nfn get_sort_field_datetime_format(\n    sort_field: Option<&SortField>,\n) -> crate::Result<Option<SortDatetimeFormat>> {\n    if let Some(sort_field) = sort_field {\n        if let Some(sort_field_datetime_format_int) = &sort_field.sort_datetime_format {\n            let sort_field_datetime_format =\n                SortDatetimeFormat::from_i32(*sort_field_datetime_format_int)\n                    .context(\"invalid sort datetime format\")?;\n            return Ok(Some(sort_field_datetime_format));\n        }\n    }\n    Ok(None)\n}\n\n/// Performs a distributed search.\n/// 1. Sends leaf request over gRPC to multiple leaf nodes.\n/// 2. Merges the search results.\n/// 3. Sends fetch docs requests to multiple leaf nodes.\n/// 4. Builds the response with docs and returns.\n#[instrument(skip_all, fields(num_splits=%split_metadatas.len()))]\nasync fn root_search_aux(\n    searcher_context: &SearcherContext,\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    search_request: SearchRequest,\n    split_metadatas: Vec<SplitMetadata>,\n    cluster_client: &ClusterClient,\n) -> crate::Result<SearchResponse> {\n    debug!(split_metadatas = ?PrettySample::new(&split_metadatas, 5));\n    let (first_phase_result, scroll_key_and_start_offset_opt): (\n        LeafSearchResponse,\n        Option<ScrollKeyAndStartOffset>,\n    ) = search_partial_hits_phase_with_scroll(\n        searcher_context,\n        indexes_metas_for_leaf_search,\n        search_request.clone(),\n        &split_metadatas[..],\n        cluster_client,\n    )\n    .await?;\n\n    let hits = fetch_docs_phase(\n        indexes_metas_for_leaf_search,\n        &first_phase_result.partial_hits,\n        &split_metadatas[..],\n        &search_request,\n        cluster_client,\n    )\n    .await?;\n\n    let mut aggregation_result_json_opt = finalize_aggregation_if_any(\n        &search_request,\n        first_phase_result.intermediate_aggregation_result,\n        searcher_context,\n    )?;\n    // In case there is no index, we don't want the response to contain any aggregation structure\n    if indexes_metas_for_leaf_search.is_empty() {\n        aggregation_result_json_opt = None;\n    }\n\n    Ok(SearchResponse {\n        aggregation: aggregation_result_json_opt,\n        num_hits: first_phase_result.num_hits,\n        hits,\n        elapsed_time_micros: 0u64,\n        errors: Vec::new(),\n        scroll_id: scroll_key_and_start_offset_opt\n            .as_ref()\n            .map(ToString::to_string),\n    })\n}\n\nfn finalize_aggregation(\n    intermediate_aggregation_result_bytes_opt: Option<Vec<u8>>,\n    aggregations: QuickwitAggregations,\n    searcher_context: &SearcherContext,\n) -> crate::Result<Option<String>> {\n    let merge_aggregation_result = match aggregations {\n        QuickwitAggregations::FindTraceIdsAggregation(_) => {\n            let Some(intermediate_aggregation_result_bytes) =\n                intermediate_aggregation_result_bytes_opt\n            else {\n                return Ok(None);\n            };\n            // The merge collector has already merged the intermediate results.\n            let aggs: Vec<Span> = postcard::from_bytes(&intermediate_aggregation_result_bytes)?;\n            serde_json::to_string(&aggs)?\n        }\n        QuickwitAggregations::TantivyAggregations(aggregations) => {\n            let intermediate_aggregation_results =\n                if let Some(intermediate_aggregation_result_bytes) =\n                    intermediate_aggregation_result_bytes_opt\n                {\n                    let intermediate_aggregation_results: IntermediateAggregationResults =\n                        postcard::from_bytes(&intermediate_aggregation_result_bytes)?;\n                    intermediate_aggregation_results\n                } else {\n                    // Default, to return correct structure\n                    Default::default()\n                };\n            let final_aggregation_results: AggregationResults = intermediate_aggregation_results\n                .into_final_result(aggregations, &searcher_context.get_aggregation_limits())?;\n            serde_json::to_string(&final_aggregation_results)?\n        }\n    };\n    Ok(Some(merge_aggregation_result))\n}\n\nfn finalize_aggregation_if_any(\n    search_request: &SearchRequest,\n    intermediate_aggregation_result_bytes_opt: Option<Vec<u8>>,\n    searcher_context: &SearcherContext,\n) -> crate::Result<Option<String>> {\n    let Some(aggregations_json) = search_request.aggregation_request.as_ref() else {\n        return Ok(None);\n    };\n    let aggregations: QuickwitAggregations = serde_json::from_str(aggregations_json)?;\n    let aggregation_result_json = finalize_aggregation(\n        intermediate_aggregation_result_bytes_opt,\n        aggregations,\n        searcher_context,\n    )?;\n    Ok(aggregation_result_json)\n}\n\n/// Checks that all of the index researched as found.\n///\n/// An index pattern (= containing a wildcard) not matching is not an error.\n/// A specific index id however must be found.\n///\n/// We put this check here and not in the metastore to make sure the logic is independent\n/// of the metastore implementation, and some different use cases could require different\n/// behaviors. This specification was principally motivated by #4042.\npub fn check_all_index_metadata_found(\n    index_metadatas: &[IndexMetadata],\n    index_id_patterns: &[String],\n) -> crate::Result<()> {\n    let mut index_ids: HashSet<&str> = index_id_patterns\n        .iter()\n        .map(|index_ptn| index_ptn.as_str())\n        .filter(|index_ptn| !index_ptn.contains('*') && !index_ptn.starts_with('-'))\n        .collect();\n\n    if index_ids.is_empty() {\n        // All of the patterns are wildcard patterns.\n        return Ok(());\n    }\n\n    for index_metadata in index_metadatas {\n        index_ids.remove(index_metadata.index_uid.index_id.as_str());\n    }\n\n    if !index_ids.is_empty() {\n        let missing_index_ids = index_ids\n            .into_iter()\n            .map(|missing_index_id| missing_index_id.to_string())\n            .collect();\n        return Err(SearchError::IndexesNotFound {\n            index_ids: missing_index_ids,\n        });\n    }\n\n    Ok(())\n}\n\n/// This function takes in the index metadatas and lists the relevant splits for the search request.\nasync fn refine_and_list_matches(\n    metastore: &mut MetastoreServiceClient,\n    search_request: &mut SearchRequest,\n    indexes_metadata: Vec<IndexMetadata>,\n    query_ast_resolved: QueryAst,\n    sort_fields_is_datetime: HashMap<String, bool>,\n    timestamp_field_opt: Option<String>,\n) -> crate::Result<Vec<SplitMetadata>> {\n    let index_uids = indexes_metadata\n        .iter()\n        .map(|index_metadata| index_metadata.index_uid.clone())\n        .collect_vec();\n    search_request.query_ast = serde_json::to_string(&query_ast_resolved)?;\n\n    // convert search_after datetime values from input datetime format to nanos.\n    convert_search_after_datetime_values(search_request, &sort_fields_is_datetime)?;\n\n    // update_search_after_datetime_in_nanos(&mut search_request)?;\n    if let Some(timestamp_field) = &timestamp_field_opt {\n        refine_start_end_timestamp_from_ast(\n            &query_ast_resolved,\n            timestamp_field,\n            &mut search_request.start_timestamp,\n            &mut search_request.end_timestamp,\n        );\n    }\n    let tag_filter_ast = extract_tags_from_query(query_ast_resolved);\n\n    // TODO if search after is set, we sort by timestamp and we don't want to count all results,\n    // we can refine more here. Same if we sort by _shard_doc\n    let split_metadatas: Vec<SplitMetadata> = list_relevant_splits(\n        index_uids,\n        search_request.start_timestamp,\n        search_request.end_timestamp,\n        tag_filter_ast,\n        metastore,\n    )\n    .await?;\n    Ok(split_metadatas)\n}\n\n/// Performs a distributed search.\n/// 1. Sends leaf request over gRPC to multiple leaf nodes.\n/// 2. Merges the search results.\n/// 3. Sends fetch docs requests to multiple leaf nodes.\n/// 4. Builds the response with docs and returns.\n#[instrument(skip_all)]\npub async fn root_search(\n    // contains split footer cache\n    searcher_context: &SearcherContext,\n    // search request will contains timestamps and tags to prune splits\n    mut search_request: SearchRequest,\n    // metastore client\n    mut metastore: MetastoreServiceClient,\n    // cluster client to communicate between nodes\n    cluster_client: &ClusterClient,\n) -> crate::Result<SearchResponse> {\n    info!(searcher_context = ?searcher_context, search_request = ?search_request);\n    let start_instant = tokio::time::Instant::now();\n    let list_indexes_metadatas_request = ListIndexesMetadataRequest {\n        index_id_patterns: search_request.index_id_patterns.clone(),\n    };\n    let indexes_metadata: Vec<IndexMetadata> = metastore\n        // codegen will generate the correct method call\n        // this will fetch the index metadata from the metastore\n        .list_indexes_metadata(list_indexes_metadatas_request)\n        .await?\n        .deserialize_indexes_metadata()\n        .await?;\n\n    check_all_index_metadata_found(&indexes_metadata[..], &search_request.index_id_patterns[..])?;\n\n    if indexes_metadata.is_empty() {\n        // We go through root_search_aux instead of directly\n        // returning an empty response to make sure we generate\n        // a (pretty useless) scroll id if requested.\n        let mut search_response = root_search_aux(\n            searcher_context,\n            &HashMap::default(),\n            search_request,\n            Vec::new(),\n            cluster_client,\n        )\n        .await?;\n        search_response.elapsed_time_micros = start_instant.elapsed().as_micros() as u64;\n        return Ok(search_response);\n    }\n\n    let request_metadata = validate_request_and_build_metadata(&indexes_metadata, &search_request)?;\n    let split_metadatas = refine_and_list_matches(\n        &mut metastore,\n        &mut search_request,\n        indexes_metadata,\n        request_metadata.query_ast_resolved,\n        request_metadata.sort_fields_is_datetime,\n        request_metadata.timestamp_field_opt,\n    )\n    .await?;\n\n    let mut search_response = root_search_aux(\n        searcher_context,\n        &request_metadata.indexes_meta_for_leaf_search,\n        search_request,\n        split_metadatas,\n        cluster_client,\n    )\n    .await?;\n\n    search_response.elapsed_time_micros = start_instant.elapsed().as_micros() as u64;\n    Ok(search_response)\n}\n\n/// Returns details on how a query would be executed\npub async fn search_plan(\n    mut search_request: SearchRequest,\n    mut metastore: MetastoreServiceClient,\n) -> crate::Result<SearchPlanResponse> {\n    let list_indexes_metadatas_request = ListIndexesMetadataRequest {\n        index_id_patterns: search_request.index_id_patterns.clone(),\n    };\n    let indexes_metadata: Vec<IndexMetadata> = metastore\n        .list_indexes_metadata(list_indexes_metadatas_request)\n        .await?\n        .deserialize_indexes_metadata()\n        .await?;\n\n    check_all_index_metadata_found(&indexes_metadata[..], &search_request.index_id_patterns[..])?;\n    if indexes_metadata.is_empty() {\n        return Ok(SearchPlanResponse {\n            result: serde_json::to_string(&SearchPlanResponseRest {\n                quickwit_ast: QueryAst::MatchAll,\n                tantivy_ast: String::new(),\n                searched_splits: Vec::new(),\n                storage_requests: StorageRequestCount::default(),\n            })?,\n        });\n    }\n    let doc_mapper = build_doc_mapper(\n        &indexes_metadata[0].index_config.doc_mapping,\n        &indexes_metadata[0].index_config.search_settings,\n    )\n    .map_err(|err| SearchError::Internal(format!(\"failed to build doc mapper. cause: {err}\")))?;\n\n    let request_metadata = validate_request_and_build_metadata(&indexes_metadata, &search_request)?;\n    let split_metadatas = refine_and_list_matches(\n        &mut metastore,\n        &mut search_request,\n        indexes_metadata,\n        request_metadata.query_ast_resolved.clone(),\n        request_metadata.sort_fields_is_datetime,\n        request_metadata.timestamp_field_opt,\n    )\n    .await?;\n\n    let (query, mut warmup_info) = doc_mapper.query(\n        doc_mapper.schema(),\n        &request_metadata.query_ast_resolved,\n        true,\n    )?;\n    let merge_collector = make_merge_collector(&search_request, &Default::default())?;\n    warmup_info.merge(merge_collector.warmup_info());\n    warmup_info.simplify();\n\n    let split_ids = split_metadatas\n        .into_iter()\n        .map(|split| format!(\"{}/{}\", split.index_uid.index_id, split.split_id))\n        .collect();\n    // this is an upper bound, we'd need access to a hotdir for more precise results\n    let fieldnorm_query_count = if warmup_info.field_norms {\n        doc_mapper\n            .schema()\n            .fields()\n            .filter(|(_, entry)| entry.has_fieldnorms())\n            .count()\n    } else {\n        0\n    };\n    let sstable_query_count = warmup_info.term_dict_fields.len()\n        + warmup_info\n            .terms_grouped_by_field\n            .values()\n            .map(|terms: &HashMap<tantivy::Term, bool>| terms.len())\n            .sum::<usize>()\n        + warmup_info\n            .term_ranges_grouped_by_field\n            .values()\n            .map(|terms: &HashMap<_, bool>| terms.len())\n            .sum::<usize>();\n    let position_query_count = warmup_info\n        .terms_grouped_by_field\n        .values()\n        .map(|terms: &HashMap<tantivy::Term, bool>| {\n            terms\n                .values()\n                .filter(|load_position| **load_position)\n                .count()\n        })\n        .sum::<usize>()\n        + warmup_info\n            .term_ranges_grouped_by_field\n            .values()\n            .map(|terms: &HashMap<_, bool>| {\n                terms\n                    .values()\n                    .filter(|load_position| **load_position)\n                    .count()\n            })\n            .sum::<usize>();\n    Ok(SearchPlanResponse {\n        result: serde_json::to_string(&SearchPlanResponseRest {\n            quickwit_ast: request_metadata.query_ast_resolved,\n            tantivy_ast: format!(\"{query:#?}\"),\n            searched_splits: split_ids,\n            storage_requests: StorageRequestCount {\n                footer: 1,\n                fastfield: warmup_info.fast_field_names.len(),\n                fieldnorm: fieldnorm_query_count,\n                sstable: sstable_query_count,\n                posting: sstable_query_count,\n                position: position_query_count,\n            },\n        })?,\n    })\n}\n\n/// Converts search after with datetime format to nanoseconds (representation in tantivy).\n/// If the sort field is a datetime field and no datetime format is set, the default format is\n/// milliseconds.\n/// `sort_fields_are_datetime_opt` must be of the same length as `search_request.sort_fields`.\nfn convert_search_after_datetime_values(\n    search_request: &mut SearchRequest,\n    sort_fields_is_datetime: &HashMap<String, bool>,\n) -> crate::Result<()> {\n    for sort_field in search_request.sort_fields.iter_mut() {\n        if *sort_fields_is_datetime\n            .get(&sort_field.field_name)\n            .unwrap_or(&false)\n            && sort_field.sort_datetime_format.is_none()\n        {\n            sort_field.sort_datetime_format = Some(SortDatetimeFormat::UnixTimestampMillis as i32);\n        }\n    }\n    if let Some(partial_hit) = search_request.search_after.as_mut() {\n        let search_after_values = [\n            partial_hit.sort_value.as_mut(),\n            partial_hit.sort_value2.as_mut(),\n        ];\n        for (sort_field, search_after_value_opt) in\n            search_request.sort_fields.iter().zip(search_after_values)\n        {\n            let Some(search_after_sort_by_value) = search_after_value_opt else {\n                continue;\n            };\n            let Some(search_after_sort_value) = search_after_sort_by_value.sort_value.as_mut()\n            else {\n                continue;\n            };\n            let Some(datetime_format_int) = sort_field.sort_datetime_format else {\n                continue;\n            };\n            let input_datetime_format = SortDatetimeFormat::from_i32(datetime_format_int)\n                .context(\"invalid sort datetime format\")?;\n            convert_sort_datetime_value_into_nanos(search_after_sort_value, input_datetime_format)?;\n        }\n    }\n    Ok(())\n}\n\n/// Convert sort values from input datetime format into nanoseconds.\n/// The conversion is done only for U64 and I64 sort values, an error is returned for other types.\nfn convert_sort_datetime_value_into_nanos(\n    sort_value: &mut SortValue,\n    input_format: SortDatetimeFormat,\n) -> crate::Result<()> {\n    match sort_value {\n        SortValue::U64(value) => match input_format {\n            SortDatetimeFormat::UnixTimestampMillis => {\n                *value = value.checked_mul(1_000_000).ok_or_else(|| {\n                    SearchError::Internal(format!(\n                        \"sort value defined in milliseconds is too large and cannot be converted \\\n                         into nanoseconds: {}\",\n                        value\n                    ))\n                })?;\n            }\n            SortDatetimeFormat::UnixTimestampNanos => {\n                // Nothing to do as the internal format is nanos.\n            }\n        },\n        SortValue::I64(value) => match input_format {\n            SortDatetimeFormat::UnixTimestampMillis => {\n                *value = value.checked_mul(1_000_000).ok_or_else(|| {\n                    SearchError::Internal(format!(\n                        \"sort value defined in milliseconds is too large and cannot be converted \\\n                         into nanoseconds: {}\",\n                        value\n                    ))\n                })?;\n            }\n            SortDatetimeFormat::UnixTimestampNanos => {\n                // Nothing to do as the internal format is nanos.\n            }\n        },\n        _ => {\n            return Err(SearchError::Internal(format!(\n                \"datetime conversion are only support for u64 and i64 sort values, not `{:?}`\",\n                sort_value\n            )));\n        }\n    }\n    Ok(())\n}\n\n/// Convert sort values from nanoseconds to the requested output format.\n/// The conversion is done only for U64 and I64 sort values, an error is returned for other types.\nfn convert_sort_datetime_value(\n    sort_value: &mut SortValue,\n    output_format: SortDatetimeFormat,\n) -> crate::Result<()> {\n    match sort_value {\n        SortValue::U64(value) => match output_format {\n            SortDatetimeFormat::UnixTimestampMillis => {\n                *value /= 1_000_000;\n            }\n            SortDatetimeFormat::UnixTimestampNanos => {\n                // Nothing todo as the internal format is in nanos.\n            }\n        },\n        SortValue::I64(value) => match output_format {\n            SortDatetimeFormat::UnixTimestampMillis => {\n                *value /= 1_000_000;\n            }\n            SortDatetimeFormat::UnixTimestampNanos => {\n                // Nothing todo as the internal format is in nanos.\n            }\n        },\n        _ => {\n            return Err(SearchError::Internal(format!(\n                \"datetime conversion are only support for u64 and i64 sort values, not `{:?}`\",\n                sort_value\n            )));\n        }\n    }\n    Ok(())\n}\n\npub(crate) fn refine_start_end_timestamp_from_ast(\n    query_ast: &QueryAst,\n    timestamp_field: &str,\n    start_timestamp: &mut Option<i64>,\n    end_timestamp: &mut Option<i64>,\n) {\n    let mut timestamp_range_extractor = ExtractTimestampRange {\n        timestamp_field,\n        start_timestamp: *start_timestamp,\n        end_timestamp: *end_timestamp,\n    };\n    timestamp_range_extractor\n        .visit(query_ast)\n        .expect(\"can't fail unwrapping Infallible\");\n    *start_timestamp = timestamp_range_extractor.start_timestamp;\n    *end_timestamp = timestamp_range_extractor.end_timestamp;\n}\n\n/// Boundaries identified as being implied by the QueryAst.\n///\n/// `start_timestamp` is to be interpreted as Inclusive (or Unbounded)\n/// `end_timestamp` is to be interpreted as Exclusive (or Unbounded)\n/// In other word, this is a `[start_timestamp..end_timestamp)` interval.\nstruct ExtractTimestampRange<'a> {\n    timestamp_field: &'a str,\n    start_timestamp: Option<i64>,\n    end_timestamp: Option<i64>,\n}\n\nimpl<'a> ExtractTimestampRange<'a> {\n    fn update_start_timestamp(\n        &mut self,\n        lower_bound: &quickwit_query::JsonLiteral,\n        included: bool,\n    ) {\n        use quickwit_query::InterpretUserInput;\n        let Some(lower_bound) = tantivy::DateTime::interpret_json(lower_bound) else {\n            return;\n        };\n        let mut lower_bound = lower_bound.into_timestamp_secs();\n        if !included {\n            // TODO saturating isn't exactly right, we should replace the RangeQuery with\n            // a match_none, but the visitor doesn't allow mutation.\n            lower_bound = lower_bound.saturating_add(1);\n        }\n        self.start_timestamp = Some(\n            self.start_timestamp\n                .map_or(lower_bound, |current| current.max(lower_bound)),\n        );\n    }\n\n    fn update_end_timestamp(&mut self, upper_bound: &quickwit_query::JsonLiteral, included: bool) {\n        use quickwit_query::InterpretUserInput;\n        let Some(upper_bound_timestamp) = tantivy::DateTime::interpret_json(upper_bound) else {\n            return;\n        };\n        let mut upper_bound = upper_bound_timestamp.into_timestamp_secs();\n        let round_up = (upper_bound_timestamp.into_timestamp_nanos() % 1_000_000_000) != 0;\n        if included || round_up {\n            // TODO saturating isn't exactly right, we should replace the RangeQuery with\n            // a match_none, but the visitor doesn't allow mutation.\n            upper_bound = upper_bound.saturating_add(1);\n        }\n        self.end_timestamp = Some(\n            self.end_timestamp\n                .map_or(upper_bound, |current| current.min(upper_bound)),\n        );\n    }\n}\n\nimpl<'a, 'b> QueryAstVisitor<'b> for ExtractTimestampRange<'a> {\n    type Err = std::convert::Infallible;\n\n    fn visit_bool(&mut self, bool_query: &'b BoolQuery) -> Result<(), Self::Err> {\n        // we only want to visit sub-queries which are strict (positive) requirements\n        for ast in bool_query.must.iter().chain(bool_query.filter.iter()) {\n            self.visit(ast)?;\n        }\n        Ok(())\n    }\n\n    fn visit_range(&mut self, range_query: &'b RangeQuery) -> Result<(), Self::Err> {\n        use std::ops::Bound;\n\n        if range_query.field == self.timestamp_field {\n            match &range_query.lower_bound {\n                Bound::Included(lower_bound) => self.update_start_timestamp(lower_bound, true),\n                Bound::Excluded(lower_bound) => self.update_start_timestamp(lower_bound, false),\n                Bound::Unbounded => (),\n            }\n            match &range_query.upper_bound {\n                Bound::Included(upper_bound) => self.update_end_timestamp(upper_bound, true),\n                Bound::Excluded(upper_bound) => self.update_end_timestamp(upper_bound, false),\n                Bound::Unbounded => (),\n            }\n        }\n        Ok(())\n    }\n\n    // if we visit a term, limit the range to DATE..=DATE\n    fn visit_term(&mut self, term_query: &'b TermQuery) -> Result<(), Self::Err> {\n        if term_query.field == self.timestamp_field {\n            // TODO when fixing #3323, this may need to be modified to support numbers too\n            let json_term = quickwit_query::JsonLiteral::String(term_query.value.clone());\n            self.update_start_timestamp(&json_term, true);\n            self.update_end_timestamp(&json_term, true);\n        }\n        Ok(())\n    }\n\n    // if we visit a termset, limit the range to LOWEST..=HIGHEST\n    fn visit_term_set(&mut self, term_query: &'b TermSetQuery) -> Result<(), Self::Err> {\n        if let Some(term_set) = term_query.terms_per_field.get(self.timestamp_field) {\n            // rfc3339 is lexicographically ordered if YEAR <= 9999, so we can use string\n            // ordering to get the start and end quickly.\n            if let Some(first) = term_set.first() {\n                let json_term = quickwit_query::JsonLiteral::String(first.clone());\n                self.update_start_timestamp(&json_term, true);\n            }\n            if let Some(last) = term_set.last() {\n                let json_term = quickwit_query::JsonLiteral::String(last.clone());\n                self.update_end_timestamp(&json_term, true);\n            }\n        }\n        Ok(())\n    }\n}\n\nasync fn assign_client_fetch_docs_jobs(\n    partial_hits: &[PartialHit],\n    split_metadatas: &[SplitMetadata],\n    client_pool: &SearchJobPlacer,\n) -> crate::Result<impl Iterator<Item = (SearchServiceClient, Vec<FetchDocsJob>)>> {\n    let index_uids_and_split_offsets_map: HashMap<String, (IndexUid, SplitIdAndFooterOffsets)> =\n        split_metadatas\n            .iter()\n            .map(|metadata| {\n                (\n                    metadata.split_id().to_string(),\n                    (\n                        metadata.index_uid.clone(),\n                        extract_split_and_footer_offsets(metadata),\n                    ),\n                )\n            })\n            .collect();\n\n    // Group the partial hits per split\n    let mut partial_hits_map: HashMap<String, Vec<PartialHit>> = HashMap::new();\n    for partial_hit in partial_hits.iter() {\n        partial_hits_map\n            .entry(partial_hit.split_id.clone())\n            .or_default()\n            .push(partial_hit.clone());\n    }\n\n    let mut fetch_docs_req_jobs: Vec<FetchDocsJob> = Vec::new();\n    for (split_id, partial_hits) in partial_hits_map {\n        let (index_uid, offsets) = index_uids_and_split_offsets_map\n            .get(&split_id)\n            .ok_or_else(|| {\n                crate::SearchError::Internal(format!(\n                    \"received partial hit from an unknown split {split_id}\"\n                ))\n            })?\n            .clone();\n        let fetch_docs_job = FetchDocsJob {\n            index_uid: index_uid.clone(),\n            offsets,\n            partial_hits,\n        };\n        fetch_docs_req_jobs.push(fetch_docs_job);\n    }\n\n    let assigned_jobs = client_pool\n        .assign_jobs(fetch_docs_req_jobs, &HashSet::new())\n        .await?;\n\n    Ok(assigned_jobs)\n}\n\n// Measure the cost associated to searching in a given split metadata.\nfn compute_split_cost(split_metadata: &SplitMetadata) -> usize {\n    // TODO this formula could be tuned a lot more. The general idea is that there is a fixed\n    // cost to searching a split, plus a somewhat-linear cost depending on the size of the split\n    5 + split_metadata.num_docs / 100_000\n}\n\n/// Builds a LeafSearchRequest to one node, from a list of [`SearchJob`].\npub fn jobs_to_leaf_request(\n    request: &SearchRequest,\n    search_indexes_metadatas: &IndexesMetasForLeafSearch,\n    jobs: Vec<SearchJob>,\n) -> crate::Result<LeafSearchRequest> {\n    let mut search_request_for_leaf = request.clone();\n    search_request_for_leaf.start_offset = 0;\n    search_request_for_leaf.max_hits += request.start_offset;\n\n    let mut leaf_search_request = LeafSearchRequest {\n        search_request: Some(search_request_for_leaf),\n        leaf_requests: Vec::new(),\n        doc_mappers: Vec::new(),\n        index_uris: Vec::new(),\n    };\n\n    let mut added_doc_mappers: HashMap<&str, u32> = HashMap::new();\n    // Group jobs by index uid, as the split offsets are relative to the index.\n    group_jobs_by_index_id(jobs, |job_group| {\n        let index_uid = &job_group[0].index_uid;\n        let search_index_meta = search_indexes_metadatas.get(index_uid).ok_or_else(|| {\n            SearchError::Internal(format!(\n                \"received job for an unknown index {index_uid}. it should never happen\"\n            ))\n        })?;\n        let doc_mapper_ord = *added_doc_mappers\n            .entry(&search_index_meta.doc_mapper_str)\n            .or_insert_with(|| {\n                let ord = leaf_search_request.doc_mappers.len();\n                leaf_search_request\n                    .doc_mappers\n                    .push(search_index_meta.doc_mapper_str.to_string());\n                ord as u32\n            });\n        let index_uri_ord = leaf_search_request.index_uris.len() as u32;\n        leaf_search_request\n            .index_uris\n            .push(search_index_meta.index_uri.to_string());\n\n        let leaf_search_request_ref = LeafRequestRef {\n            split_offsets: job_group.into_iter().map(|job| job.offsets).collect(),\n            doc_mapper_ord,\n            index_uri_ord,\n        };\n        leaf_search_request\n            .leaf_requests\n            .push(leaf_search_request_ref);\n        Ok(())\n    })?;\n    Ok(leaf_search_request)\n}\n\n/// Builds a list of [`FetchDocsRequest`], one per index, from a list of [`FetchDocsJob`].\npub fn jobs_to_fetch_docs_requests(\n    snippet_request_opt: Option<SnippetRequest>,\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    jobs: Vec<FetchDocsJob>,\n) -> crate::Result<Vec<FetchDocsRequest>> {\n    let mut fetch_docs_requests = Vec::new();\n    // Group jobs by index uid.\n    group_by(\n        jobs,\n        |job| &job.index_uid,\n        |fetch_docs_jobs| {\n            let index_uid = &fetch_docs_jobs[0].index_uid;\n\n            let index_meta = indexes_metas_for_leaf_search\n                .get(index_uid)\n                .ok_or_else(|| {\n                    SearchError::Internal(format!(\n                        \"received search job for an unknown index {index_uid}\"\n                    ))\n                })?;\n            let partial_hits: Vec<PartialHit> = fetch_docs_jobs\n                .iter()\n                .flat_map(|fetch_doc_job| fetch_doc_job.partial_hits.iter().cloned())\n                .collect();\n            let split_offsets: Vec<SplitIdAndFooterOffsets> = fetch_docs_jobs\n                .into_iter()\n                .map(|fetch_doc_job| fetch_doc_job.into())\n                .collect();\n            let fetch_docs_req = FetchDocsRequest {\n                partial_hits,\n                split_offsets,\n                index_uri: index_meta.index_uri.to_string(),\n                snippet_request: snippet_request_opt.clone(),\n                doc_mapper: index_meta.doc_mapper_str.clone(),\n            };\n            fetch_docs_requests.push(fetch_docs_req);\n\n            Ok(())\n        },\n    )?;\n    Ok(fetch_docs_requests)\n}\n\n#[cfg(test)]\nmod tests {\n    use std::ops::Range;\n    use std::str::FromStr;\n    use std::sync::{Arc, RwLock};\n\n    use quickwit_common::shared_consts::SCROLL_BATCH_LEN;\n    use quickwit_common::ServiceStream;\n    use quickwit_config::{DocMapping, IndexConfig, IndexingSettings, SearchSettings};\n    use quickwit_indexing::MockSplitBuilder;\n    use quickwit_metastore::{IndexMetadata, ListSplitsRequestExt, ListSplitsResponseExt};\n    use quickwit_proto::metastore::{\n        ListIndexesMetadataResponse, ListSplitsResponse, MockMetastoreService,\n    };\n    use quickwit_proto::search::{\n        ScrollRequest, SortByValue, SortOrder, SortValue, SplitSearchError,\n    };\n    use quickwit_query::query_ast::{qast_helper, qast_json_helper, query_ast_from_user_text};\n    use tantivy::schema::{FAST, STORED, TEXT};\n\n    use super::*;\n    use crate::{searcher_pool_for_test, MockSearchService};\n\n    #[track_caller]\n    fn check_snippet_fields_validation(snippet_fields: &[String]) -> anyhow::Result<()> {\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_text_field(\"title\", TEXT);\n        schema_builder.add_text_field(\"desc\", TEXT | STORED);\n        schema_builder.add_ip_addr_field(\"ip\", FAST | STORED);\n        let schema = schema_builder.build();\n        validate_requested_snippet_fields(&schema, snippet_fields)\n    }\n\n    #[test]\n    fn test_validate_requested_snippet_fields() {\n        check_snippet_fields_validation(&[\"desc\".to_string()]).unwrap();\n        let field_not_stored_err =\n            check_snippet_fields_validation(&[\"title\".to_string()]).unwrap_err();\n        assert_eq!(\n            field_not_stored_err.to_string(),\n            \"the snippet field `title` must be stored\"\n        );\n        let field_doesnotexist_err =\n            check_snippet_fields_validation(&[\"doesnotexist\".to_string()]).unwrap_err();\n        assert_eq!(\n            field_doesnotexist_err.to_string(),\n            \"The field does not exist: 'doesnotexist'\"\n        );\n        let field_is_not_text_err =\n            check_snippet_fields_validation(&[\"ip\".to_string()]).unwrap_err();\n        assert_eq!(\n            field_is_not_text_err.to_string(),\n            \"the snippet field `ip` must be of type `Str`, got `IpAddr`\"\n        );\n    }\n\n    #[test]\n    fn test_get_sort_by_field_entry() {\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_text_field(\"title\", TEXT);\n        schema_builder.add_text_field(\"desc\", TEXT | STORED);\n        schema_builder.add_u64_field(\"timestamp\", FAST | STORED);\n        let schema = schema_builder.build();\n        get_sort_by_field_entry(\"timestamp\", &schema)\n            .unwrap()\n            .unwrap();\n        let sort_by_field_entry_err = get_sort_by_field_entry(\"doesnotexist\", &schema).unwrap_err();\n        assert_eq!(\n            sort_by_field_entry_err.to_string(),\n            \"Invalid argument: unknown field used in `sort by`: doesnotexist\"\n        );\n        for sort_field_name in &[\"_doc\", \"_score\", \"_shard_doc\"] {\n            assert!(get_sort_by_field_entry(sort_field_name, &schema)\n                .unwrap()\n                .is_none());\n        }\n    }\n\n    fn index_metadata_for_multi_indexes_test(index_id: &str, index_uri: &str) -> IndexMetadata {\n        let index_uri = Uri::from_str(index_uri).unwrap();\n        let doc_mapping_json = r#\"{\n            \"mode\": \"lenient\",\n            \"field_mappings\": [\n                {\n                    \"name\": \"timestamp\",\n                    \"type\": \"datetime\",\n                    \"fast\": true\n                },\n                {\n                    \"name\": \"body\",\n                    \"type\": \"text\",\n                    \"stored\": true\n                }\n            ],\n            \"timestamp_field\": \"timestamp\",\n            \"store_source\": true\n        }\"#;\n        let doc_mapping = serde_json::from_str(doc_mapping_json).unwrap();\n        let indexing_settings = IndexingSettings::default();\n        let search_settings = SearchSettings {\n            default_search_fields: vec![\"body\".to_string()],\n        };\n        IndexMetadata::new(IndexConfig {\n            index_id: index_id.to_string(),\n            index_uri,\n            doc_mapping,\n            indexing_settings,\n            search_settings,\n            retention_policy_opt: Default::default(),\n        })\n    }\n\n    #[test]\n    fn test_validate_request_and_build_metadatas_ok() {\n        let request_query_ast = qast_helper(\"body:test\", &[]);\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: serde_json::to_string(&request_query_ast).unwrap(),\n            max_hits: 10,\n            start_offset: 10,\n            sort_fields: vec![\n                SortField {\n                    field_name: \"timestamp\".to_string(),\n                    sort_order: SortOrder::Desc as i32,\n                    sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n                },\n                SortField {\n                    field_name: \"_doc\".to_string(),\n                    sort_order: SortOrder::Asc as i32,\n                    sort_datetime_format: None,\n                },\n            ],\n            ..Default::default()\n        };\n        let index_metadata = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_metadata_with_other_config =\n            index_metadata_for_multi_indexes_test(\"test-index-2\", \"ram:///test-index-2\");\n        let mut index_metadata_no_timestamp =\n            IndexMetadata::for_test(\"test-index-3\", \"ram:///test-index-3\");\n        index_metadata_no_timestamp\n            .index_config\n            .doc_mapping\n            .timestamp_field = None;\n        let request_metadata = validate_request_and_build_metadata(\n            &[\n                index_metadata,\n                index_metadata_with_other_config,\n                index_metadata_no_timestamp,\n            ],\n            &search_request,\n        )\n        .unwrap();\n        assert_eq!(\n            request_metadata.timestamp_field_opt,\n            Some(\"timestamp\".to_string())\n        );\n        assert_eq!(request_metadata.query_ast_resolved, request_query_ast);\n        assert_eq!(request_metadata.indexes_meta_for_leaf_search.len(), 3);\n        assert_eq!(request_metadata.sort_fields_is_datetime.len(), 2);\n        assert_eq!(\n            request_metadata.sort_fields_is_datetime.get(\"timestamp\"),\n            Some(&true)\n        );\n        assert_eq!(\n            request_metadata.sort_fields_is_datetime.get(\"_doc\"),\n            Some(&false)\n        );\n    }\n\n    #[test]\n    fn test_validate_request_and_build_metadatas_fail_with_different_timestamps() {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            start_offset: 10,\n            ..Default::default()\n        };\n        let index_metadata_1 = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let mut index_metadata_2 = IndexMetadata::for_test(\"test-index-2\", \"ram:///test-index-2\");\n        let doc_mapping_json_2 = r#\"{\n            \"mode\": \"lenient\",\n            \"field_mappings\": [\n                {\n                    \"name\": \"timestamp-2\",\n                    \"type\": \"datetime\",\n                    \"fast\": true\n                },\n                {\n                    \"name\": \"body\",\n                    \"type\": \"text\"\n                }\n            ],\n            \"timestamp_field\": \"timestamp-2\",\n            \"store_source\": true\n        }\"#;\n        let doc_mapping_2: DocMapping = serde_json::from_str(doc_mapping_json_2).unwrap();\n        index_metadata_2.index_config.doc_mapping = doc_mapping_2;\n        index_metadata_2\n            .index_config\n            .search_settings\n            .default_search_fields = Vec::new();\n        let timestamp_field_different = validate_request_and_build_metadata(\n            &[index_metadata_1, index_metadata_2],\n            &search_request,\n        )\n        .unwrap_err();\n        assert_eq!(\n            timestamp_field_different.to_string(),\n            \"the timestamp field (if present) must be the same for all indexes\"\n        );\n    }\n\n    #[test]\n    fn test_validate_request_and_build_metadatas_fail_with_different_resolved_qast() {\n        let qast = query_ast_from_user_text(\"test\", None);\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: serde_json::to_string(&qast).unwrap(),\n            max_hits: 10,\n            start_offset: 10,\n            ..Default::default()\n        };\n        let index_metadata_1 = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let mut index_metadata_2 = IndexMetadata::for_test(\"test-index-2\", \"ram:///test-index-2\");\n        index_metadata_2\n            .index_config\n            .search_settings\n            .default_search_fields = vec![\"owner\".to_string()];\n        let timestamp_field_different = validate_request_and_build_metadata(\n            &[index_metadata_1, index_metadata_2],\n            &search_request,\n        )\n        .unwrap_err();\n        assert_eq!(\n            timestamp_field_different.to_string(),\n            \"resolved query ASTs must be the same across indexes. resolving queries with \\\n             different default fields are different between indexes is not supported\"\n        );\n    }\n\n    fn index_metadata_for_multi_indexes_test_with_incompatible_sort_type(\n        index_id: &str,\n        index_uri: &str,\n    ) -> IndexMetadata {\n        let index_uri = Uri::from_str(index_uri).unwrap();\n        let doc_mapping_json = r#\"{\n            \"mode\": \"lenient\",\n            \"field_mappings\": [\n                {\n                    \"name\": \"timestamp\",\n                    \"type\": \"datetime\",\n                    \"fast\": true\n                },\n                {\n                    \"name\": \"body\",\n                    \"type\": \"text\",\n                    \"stored\": true\n                },\n                {\n                    \"name\": \"response_date\",\n                    \"type\": \"i64\",\n                    \"stored\": true,\n                    \"fast\": true\n                }\n            ],\n            \"timestamp_field\": \"timestamp\",\n            \"store_source\": true\n        }\"#;\n        let doc_mapping = serde_json::from_str(doc_mapping_json).unwrap();\n        let indexing_settings = IndexingSettings::default();\n        let search_settings = SearchSettings {\n            default_search_fields: vec![\"body\".to_string()],\n        };\n        IndexMetadata::new(IndexConfig {\n            index_id: index_id.to_string(),\n            index_uri,\n            doc_mapping,\n            indexing_settings,\n            search_settings,\n            retention_policy_opt: Default::default(),\n        })\n    }\n\n    #[test]\n    fn test_validate_request_and_build_metadatas_fail_with_incompatible_sort_field_types() {\n        let request_query_ast = qast_helper(\"body:test\", &[]);\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: serde_json::to_string(&request_query_ast).unwrap(),\n            max_hits: 10,\n            start_offset: 10,\n            sort_fields: vec![SortField {\n                field_name: \"response_date\".to_string(),\n                sort_order: SortOrder::Desc as i32,\n                sort_datetime_format: None,\n            }],\n            ..Default::default()\n        };\n        let index_metadata = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_metadata_with_other_config =\n            index_metadata_for_multi_indexes_test_with_incompatible_sort_type(\n                \"test-index-2\",\n                \"ram:///test-index-2\",\n            );\n        let search_error = validate_request_and_build_metadata(\n            &[index_metadata, index_metadata_with_other_config],\n            &search_request,\n        )\n        .unwrap_err();\n        assert_eq!(\n            search_error.to_string(),\n            \"sort datetime field `response_date` must be of type datetime on all indexes\"\n        );\n    }\n\n    #[test]\n    fn test_convert_sort_datetime_value() {\n        let mut sort_value = SortValue::U64(1617000000000000000);\n        convert_sort_datetime_value(&mut sort_value, SortDatetimeFormat::UnixTimestampMillis)\n            .unwrap();\n        assert_eq!(sort_value, SortValue::U64(1617000000000));\n        let mut sort_value = SortValue::I64(1617000000000000000);\n        convert_sort_datetime_value(&mut sort_value, SortDatetimeFormat::UnixTimestampMillis)\n            .unwrap();\n        assert_eq!(sort_value, SortValue::I64(1617000000000));\n\n        // conversion with float values should fail.\n        let mut sort_value = SortValue::F64(1617000000000000000.0);\n        let error =\n            convert_sort_datetime_value(&mut sort_value, SortDatetimeFormat::UnixTimestampMillis)\n                .unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"internal error: `datetime conversion are only support for u64 and i64 sort values, \\\n             not `F64(1.617e18)``\"\n        );\n    }\n\n    #[test]\n    fn test_convert_sort_datetime_value_into_nanos() {\n        let mut sort_value = SortValue::U64(1617000000000);\n        convert_sort_datetime_value_into_nanos(\n            &mut sort_value,\n            SortDatetimeFormat::UnixTimestampMillis,\n        )\n        .unwrap();\n        assert_eq!(sort_value, SortValue::U64(1617000000000000000));\n        let mut sort_value = SortValue::I64(1617000000000);\n        convert_sort_datetime_value_into_nanos(\n            &mut sort_value,\n            SortDatetimeFormat::UnixTimestampMillis,\n        )\n        .unwrap();\n        assert_eq!(sort_value, SortValue::I64(1617000000000000000));\n\n        // conversion with a too large millisecond value should fail.\n        let mut sort_value = SortValue::I64(1617000000000000);\n        let error = convert_sort_datetime_value_into_nanos(\n            &mut sort_value,\n            SortDatetimeFormat::UnixTimestampMillis,\n        )\n        .unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"internal error: `sort value defined in milliseconds is too large and cannot be \\\n             converted into nanoseconds: 1617000000000000`\"\n        );\n        // conversion with float values should fail.\n        let mut sort_value = SortValue::F64(1617000000000000.0);\n        let error = convert_sort_datetime_value_into_nanos(\n            &mut sort_value,\n            SortDatetimeFormat::UnixTimestampMillis,\n        )\n        .unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"internal error: `datetime conversion are only support for u64 and i64 sort values, \\\n             not `F64(1617000000000000.0)``\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_field_types_with_doc_and_shard_doc() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"_doc\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n            SortField {\n                field_name: \"_shard_doc\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_date_field(\"timestamp\", FAST);\n        schema_builder.add_u64_field(\"id\", FAST);\n        let schema = schema_builder.build();\n        let mut sort_field_are_datetime = HashMap::new();\n        validate_sort_field_types(&schema, &sort_fields, &mut sort_field_are_datetime).unwrap();\n        assert_eq!(sort_field_are_datetime.get(\"_doc\"), Some(&false));\n        assert_eq!(sort_field_are_datetime.get(\"_shard_doc\"), Some(&false));\n    }\n\n    #[test]\n    fn test_validate_sort_field_types_valid() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_date_field(\"timestamp\", FAST);\n        schema_builder.add_u64_field(\"id\", FAST);\n        let schema = schema_builder.build();\n        let mut sort_field_are_datetime = HashMap::new();\n        validate_sort_field_types(&schema, &sort_fields, &mut sort_field_are_datetime).unwrap();\n        assert_eq!(sort_field_are_datetime.get(\"timestamp\"), Some(&true));\n        assert_eq!(sort_field_are_datetime.get(\"id\"), Some(&false));\n    }\n\n    #[test]\n    fn test_validate_sort_field_types_with_inconsistent_datetime_type() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_date_field(\"timestamp\", FAST);\n        schema_builder.add_u64_field(\"id\", FAST);\n        let schema = schema_builder.build();\n        {\n            let mut sort_field_are_datetime = HashMap::new();\n            sort_field_are_datetime.insert(\"timestamp\".to_string(), false);\n            sort_field_are_datetime.insert(\"id\".to_string(), false);\n            let error =\n                validate_sort_field_types(&schema, &sort_fields, &mut sort_field_are_datetime)\n                    .unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"sort datetime field `timestamp` must be of type datetime on all indexes\"\n            );\n        }\n        {\n            let mut sort_field_are_datetime = HashMap::new();\n            sort_field_are_datetime.insert(\"id\".to_string(), true);\n            let error =\n                validate_sort_field_types(&schema, &sort_fields, &mut sort_field_are_datetime)\n                    .unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"sort datetime field `id` must be of type datetime on all indexes\"\n            );\n        }\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_with_datetime_format_ok() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        validate_sort_by_fields_and_search_after(&sort_fields, &None).unwrap();\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_ok() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: Some(SortByValue {\n                sort_value: Some(SortValue::U64(2)),\n            }),\n            split_id: \"\".to_string(),\n            segment_ord: 0,\n            doc_id: 0,\n        };\n        validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap();\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_ok_with_doc_sort_field() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"_doc\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: None,\n            split_id: \"split1\".to_string(),\n            segment_ord: 1,\n            doc_id: 1,\n        };\n        validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap();\n    }\n\n    #[test]\n    fn test_validate_sort_by_field_type() {\n        let mut schema_builder = Schema::builder();\n        let timestamp_field = schema_builder.add_date_field(\"timestamp\", FAST);\n        let id_field = schema_builder.add_u64_field(\"id\", FAST);\n        let no_fast_field = schema_builder.add_u64_field(\"no_fast\", STORED);\n        let text_field = schema_builder.add_text_field(\"text\", STORED);\n        let schema = schema_builder.build();\n        {\n            let sort_by_field_entry = schema.get_field_entry(timestamp_field);\n            validate_sort_by_field_type(sort_by_field_entry, false).unwrap();\n            validate_sort_by_field_type(sort_by_field_entry, true).unwrap();\n        }\n        {\n            let sort_by_field_entry = schema.get_field_entry(id_field);\n            validate_sort_by_field_type(sort_by_field_entry, false).unwrap();\n            let error = validate_sort_by_field_type(sort_by_field_entry, true).unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"Invalid argument: sort by field with a timestamp format must be a datetime field \\\n                 and the field `id` is not\"\n            );\n        }\n        {\n            let sort_by_field_entry = schema.get_field_entry(no_fast_field);\n            let error = validate_sort_by_field_type(sort_by_field_entry, true).unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"Invalid argument: sort by field must be a fast field, please add the fast \\\n                 property to your field `no_fast`\"\n            );\n        }\n        {\n            let sort_by_field_entry = schema.get_field_entry(text_field);\n            let error = validate_sort_by_field_type(sort_by_field_entry, true).unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"Invalid argument: sort by field on type text is currently not supported `text`\"\n            );\n        }\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_invalid_1() {\n        // 2 sort fields + search after with only one sort value is invalid.\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: None,\n            split_id: \"split1\".to_string(),\n            segment_ord: 1,\n            doc_id: 1,\n        };\n        let error =\n            validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: `search_after` must have the same number of sort values as sort by \\\n             fields [\\\"timestamp\\\", \\\"id\\\"]\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_invalid_with_missing_split_id() {\n        // 2 sort fields + search after with only one sort value is invalid.\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"_doc\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: None,\n            split_id: \"\".to_string(),\n            segment_ord: 1,\n            doc_id: 1,\n        };\n        let error =\n            validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: search_after with a sort field `_doc` must define a split ID, \\\n             segment ID and doc ID values\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_valid_1() {\n        // 2 sort fields + search after with only one sort value is invalid.\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: None,\n            split_id: \"split1\".to_string(),\n            segment_ord: 1,\n            doc_id: 1,\n        };\n        let error =\n            validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: `search_after` must have the same number of sort values as sort by \\\n             fields [\\\"timestamp\\\", \\\"id\\\"]\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_by_field_type_invalid() {\n        // sort non-datetime field with a datetime format is invalid.\n        let mut schema_builder = Schema::builder();\n        let field = schema_builder.add_u64_field(\"timestamp\", FAST);\n        let schema = schema_builder.build();\n        let field_entry = schema.get_field_entry(field);\n        let error = validate_sort_by_field_type(field_entry, true).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: sort by field with a timestamp format must be a datetime field and \\\n             the field `timestamp` is not\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_invalid_3() {\n        // 3 sort fields is not possible.\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n        ];\n        let error = validate_sort_by_fields_and_search_after(&sort_fields, &None).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: sort by field must be up to 2 fields, got 3\"\n        );\n    }\n\n    fn mock_partial_hit(\n        split_id: &str,\n        sort_value: u64,\n        doc_id: u32,\n    ) -> quickwit_proto::search::PartialHit {\n        quickwit_proto::search::PartialHit {\n            sort_value: Some(SortValue::U64(sort_value).into()),\n            sort_value2: None,\n            split_id: split_id.to_string(),\n            segment_ord: 1,\n            doc_id,\n        }\n    }\n\n    fn mock_partial_hit_opt_sort_value(\n        split_id: &str,\n        sort_value: Option<u64>,\n        doc_id: u32,\n    ) -> quickwit_proto::search::PartialHit {\n        quickwit_proto::search::PartialHit {\n            sort_value: sort_value.map(|sort_value| SortValue::U64(sort_value).into()),\n            sort_value2: None,\n            split_id: split_id.to_string(),\n            segment_ord: 1,\n            doc_id,\n        }\n    }\n\n    fn get_doc_for_fetch_req(\n        fetch_docs_req: quickwit_proto::search::FetchDocsRequest,\n    ) -> Vec<quickwit_proto::search::LeafHit> {\n        fetch_docs_req\n            .partial_hits\n            .into_iter()\n            .map(|req| quickwit_proto::search::LeafHit {\n                leaf_json: serde_json::to_string_pretty(&serde_json::json!({\n                    \"title\": [req.doc_id.to_string()],\n                    \"body\": [\"test 1\"],\n                    \"url\": [\"http://127.0.0.1/1\"]\n                }))\n                .expect(\"Json serialization should not fail\"),\n                partial_hit: Some(req),\n                leaf_snippet_json: None,\n            })\n            .collect()\n    }\n\n    #[tokio::test]\n    async fn test_root_search_offset_out_of_bounds_1085() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            start_offset: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_indexes_metadata_request| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 3,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split1\", 3, 1),\n                        mock_partial_hit(\"split1\", 2, 2),\n                        mock_partial_hit(\"split1\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split2\", 3, 1),\n                        mock_partial_hit(\"split2\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 5);\n        assert_eq!(search_response.hits.len(), 0);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_single_split() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_list_splits_request| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service = MockSearchService::new();\n        mock_search_service.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 3,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split1\", 3, 1),\n                        mock_partial_hit(\"split1\", 2, 2),\n                        mock_partial_hit(\"split1\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n\n        let searcher_context = SearcherContext::for_test();\n        let search_response = root_search(\n            &searcher_context,\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split1\", 3, 1),\n                        mock_partial_hit(\"split1\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 1,\n                    partial_hits: vec![mock_partial_hit(\"split2\", 2, 2)],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_with_failure() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 2,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                if leaf_search_req.leaf_requests[0].split_offsets.len() == 2 {\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: 2,\n                        partial_hits: vec![\n                            mock_partial_hit(\"split1\", 3, 1),\n                            mock_partial_hit(\"split1\", 1, 3),\n                        ],\n                        failed_splits: vec![SplitSearchError {\n                            error: \"some error\".to_string(),\n                            split_id: \"split2\".to_string(),\n                            retryable_error: true,\n                        }],\n                        num_attempted_splits: 2,\n                        ..Default::default()\n                    })\n                } else {\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: 1,\n                        partial_hits: vec![mock_partial_hit(\"split2\", 2, 2)],\n                        failed_splits: Vec::new(),\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                }\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service_1)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 2);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_sort_heteregeneous_field_ascending(\n    ) -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            sort_fields: vec![SortField {\n                field_name: \"response_date\".to_string(),\n                sort_order: SortOrder::Asc.into(),\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampNanos as i32),\n            }],\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::U64(2u64).into()),\n                            sort_value2: None,\n                            split_id: \"split1\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 0,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: None,\n                            sort_value2: None,\n                            split_id: \"split1\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 1,\n                        },\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 3,\n                    partial_hits: vec![\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::I64(-1i64).into()),\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 1,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::I64(1i64).into()),\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 0,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: None,\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 2,\n                        },\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request.clone(),\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await?;\n\n        assert_eq!(search_response.num_hits, 5);\n        assert_eq!(search_response.hits.len(), 5);\n        assert_eq!(\n            search_response.hits[0].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 1,\n                sort_value: Some(SortValue::I64(-1i64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[1].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 0,\n                sort_value: Some(SortValue::I64(1i64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[2].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split1\".to_string(),\n                segment_ord: 0,\n                doc_id: 0,\n                sort_value: Some(SortValue::U64(2u64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[3].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split1\".to_string(),\n                segment_ord: 0,\n                doc_id: 1,\n                sort_value: None,\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[4].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 2,\n                sort_value: None,\n                sort_value2: None,\n            }\n        );\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_sort_heteregeneous_field_descending(\n    ) -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            sort_fields: vec![SortField {\n                field_name: \"response_date\".to_string(),\n                sort_order: SortOrder::Desc.into(),\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampNanos as i32),\n            }],\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::U64(2u64).into()),\n                            sort_value2: None,\n                            split_id: \"split1\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 0,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: None,\n                            sort_value2: None,\n                            split_id: \"split1\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 1,\n                        },\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 3,\n                    partial_hits: vec![\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::I64(1i64).into()),\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 0,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::I64(-1i64).into()),\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 1,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: None,\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 2,\n                        },\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request.clone(),\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await?;\n\n        assert_eq!(search_response.num_hits, 5);\n        assert_eq!(search_response.hits.len(), 5);\n        assert_eq!(\n            search_response.hits[0].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split1\".to_string(),\n                segment_ord: 0,\n                doc_id: 0,\n                sort_value: Some(SortValue::U64(2u64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[1].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 0,\n                sort_value: Some(SortValue::I64(1i64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[2].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 1,\n                sort_value: Some(SortValue::I64(-1i64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[3].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 2,\n                sort_value: None,\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[4].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split1\".to_string(),\n                segment_ord: 0,\n                doc_id: 1,\n                sort_value: None,\n                sort_value2: None,\n            }\n        );\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_retry_on_other_node() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1\n            .expect_leaf_search()\n            .times(2)\n            .returning(\n                |leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                    let split_ids: Vec<&str> = leaf_search_req.leaf_requests[0]\n                        .split_offsets\n                        .iter()\n                        .map(|metadata| metadata.split_id.as_str())\n                        .collect();\n                    if split_ids == [\"split1\"] {\n                        Ok(quickwit_proto::search::LeafSearchResponse {\n                            num_hits: 2,\n                            partial_hits: vec![\n                                mock_partial_hit(\"split1\", 3, 1),\n                                mock_partial_hit(\"split1\", 1, 3),\n                            ],\n                            failed_splits: Vec::new(),\n                            num_attempted_splits: 1,\n                            ..Default::default()\n                        })\n                    } else if split_ids == [\"split2\"] {\n                        // RETRY REQUEST!\n                        Ok(quickwit_proto::search::LeafSearchResponse {\n                            num_hits: 1,\n                            partial_hits: vec![mock_partial_hit(\"split2\", 2, 2)],\n                            failed_splits: Vec::new(),\n                            num_attempted_splits: 1,\n                            ..Default::default()\n                        })\n                    } else {\n                        panic!(\"unexpected request in test {split_ids:?}\");\n                    }\n                },\n            );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2\n            .expect_leaf_search()\n            .times(1)\n            .returning(\n                |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        // requests from split 2 arrive here - simulate failure\n                        num_hits: 0,\n                        partial_hits: Vec::new(),\n                        failed_splits: vec![SplitSearchError {\n                            error: \"mock_error\".to_string(),\n                            split_id: \"split2\".to_string(),\n                            retryable_error: true,\n                        }],\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                },\n            );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_retry_on_all_nodes() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_indexes_metadata_request| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1\n            .expect_leaf_search()\n            .withf(|leaf_search_req| {\n                leaf_search_req.leaf_requests[0].split_offsets[0].split_id == \"split2\"\n            })\n            .return_once(|_| {\n                // requests from split 2 arrive here - simulate failure.\n                // a retry will be made on the second service.\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 0,\n                    partial_hits: Vec::new(),\n                    failed_splits: vec![SplitSearchError {\n                        error: \"mock_error\".to_string(),\n                        split_id: \"split2\".to_string(),\n                        retryable_error: true,\n                    }],\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            });\n        mock_search_service_1\n            .expect_leaf_search()\n            .withf(|leaf_search_req| {\n                leaf_search_req.leaf_requests[0].split_offsets[0].split_id == \"split1\"\n            })\n            .return_once(|_| {\n                // RETRY REQUEST from split1\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split1\", 3, 1),\n                        mock_partial_hit(\"split1\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            });\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2\n            .expect_leaf_search()\n            .withf(|leaf_search_req| {\n                leaf_search_req.leaf_requests[0].split_offsets[0].split_id == \"split2\"\n            })\n            .return_once(|_| {\n                // retry for split 2 arrive here, simulate success.\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 1,\n                    partial_hits: vec![mock_partial_hit(\"split2\", 2, 2)],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            });\n        mock_search_service_2\n            .expect_leaf_search()\n            .withf(|leaf_search_req| {\n                leaf_search_req.leaf_requests[0].split_offsets[0].split_id == \"split1\"\n            })\n            .return_once(|_| {\n                // requests from split 1 arrive here - simulate failure, then success.\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    // requests from split 2 arrive here - simulate failure\n                    num_hits: 0,\n                    partial_hits: Vec::new(),\n                    failed_splits: vec![SplitSearchError {\n                        error: \"mock_error\".to_string(),\n                        split_id: \"split1\".to_string(),\n                        retryable_error: true,\n                    }],\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            });\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_single_split_retry_single_node() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_list_splits_request| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut first_call = true;\n        let mut mock_search_service = MockSearchService::new();\n        mock_search_service.expect_leaf_search().times(2).returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                // requests from split 2 arrive here - simulate failure, then success\n                if first_call {\n                    first_call = false;\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: 0,\n                        partial_hits: Vec::new(),\n                        failed_splits: vec![SplitSearchError {\n                            error: \"mock_error\".to_string(),\n                            split_id: \"split1\".to_string(),\n                            retryable_error: true,\n                        }],\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                } else {\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: 1,\n                        partial_hits: vec![mock_partial_hit(\"split1\", 2, 2)],\n                        failed_splits: Vec::new(),\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                }\n            },\n        );\n        mock_search_service.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 1);\n        assert_eq!(search_response.hits.len(), 1);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_single_split_retry_single_node_fails() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n\n        let mut mock_search_service = MockSearchService::new();\n        mock_search_service.expect_leaf_search().times(2).returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 0,\n                    partial_hits: Vec::new(),\n                    failed_splits: vec![SplitSearchError {\n                        error: \"mock_error\".to_string(),\n                        split_id: \"split1\".to_string(),\n                        retryable_error: true,\n                    }],\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service.expect_fetch_docs().returning(\n            |_fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Err(SearchError::Internal(\"mockerr docs\".to_string()))\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await;\n        assert!(search_response.is_err());\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_one_splits_two_nodes_but_one_is_failing_for_split(\n    ) -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        // Service1 - broken node.\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                // retry requests from split 1 arrive here\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 1,\n                    partial_hits: vec![mock_partial_hit(\"split1\", 2, 2)],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        // Service2 - working node.\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 0,\n                    partial_hits: Vec::new(),\n                    failed_splits: vec![SplitSearchError {\n                        error: \"mock_error\".to_string(),\n                        split_id: \"split1\".to_string(),\n                        retryable_error: true,\n                    }],\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |_fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Err(SearchError::Internal(\"mockerr docs\".to_string()))\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 1);\n        assert_eq!(search_response.hits.len(), 1);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_one_splits_two_nodes_but_one_is_failing_completely(\n    ) -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n\n        // Service1 - working node.\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 1,\n                    partial_hits: vec![mock_partial_hit(\"split1\", 2, 2)],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        // Service2 - broken node.\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Err(SearchError::Internal(\"mockerr search\".to_string()))\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |_fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Err(SearchError::Internal(\"mockerr docs\".to_string()))\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 1);\n        assert_eq!(search_response.hits.len(), 1);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_invalid_queries() -> anyhow::Result<()> {\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", MockSearchService::new())]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let searcher_context = SearcherContext::for_test();\n        let metastore = MetastoreServiceClient::from_mock(mock_metastore);\n\n        assert!(root_search(\n            &searcher_context,\n            quickwit_proto::search::SearchRequest {\n                index_id_patterns: vec![\"test-index\".to_string()],\n                query_ast: qast_json_helper(\"invalid_field:\\\"test\\\"\", &[\"body\"]),\n                max_hits: 10,\n                ..Default::default()\n            },\n            metastore.clone(),\n            &cluster_client,\n        )\n        .await\n        .is_err());\n\n        assert!(root_search(\n            &searcher_context,\n            quickwit_proto::search::SearchRequest {\n                index_id_patterns: vec![\"test-index\".to_string()],\n                query_ast: qast_json_helper(\"test\", &[\"invalid_field\"]),\n                max_hits: 10,\n                ..Default::default()\n            },\n            metastore,\n            &cluster_client,\n        )\n        .await\n        .is_err());\n\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_invalid_aggregation() -> anyhow::Result<()> {\n        let agg_req = r#\"\n            {\n                \"expensive_colors\": {\n                    \"termss\": {\n                        \"field\": \"color\",\n                        \"order\": {\n                            \"price_stats.max\": \"desc\"\n                        }\n                    },\n                    \"aggs\": {\n                        \"price_stats\" : {\n                            \"stats\": {\n                                \"field\": \"price\"\n                            }\n                        }\n                    }\n                }\n            }\"#;\n\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            aggregation_request: Some(agg_req.to_string()),\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", MockSearchService::new())]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await;\n        assert!(search_response.is_err());\n        assert!(search_response\n            .unwrap_err()\n            .to_string()\n            .starts_with(\"invalid aggregation request: unknown variant `termss`, expected one of\"));\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_invalid_request() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            start_offset: 20_000,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", MockSearchService::new())]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let metastore = MetastoreServiceClient::from_mock(mock_metastore);\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            metastore.clone(),\n            &cluster_client,\n        )\n        .await;\n        assert!(search_response.is_err());\n        assert_eq!(\n            search_response.unwrap_err().to_string(),\n            \"Invalid argument: max value for start_offset is 10_000, but got 20000\",\n        );\n\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 20_000,\n            ..Default::default()\n        };\n\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            metastore,\n            &cluster_client,\n        )\n        .await;\n        assert!(search_response.is_err());\n        assert_eq!(\n            search_response.unwrap_err().to_string(),\n            \"Invalid argument: max value for max_hits is 10_000, but got 20000\",\n        );\n\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_search_plan_multiple_splits() -> anyhow::Result<()> {\n        use quickwit_query::query_ast::{FullTextMode, FullTextParams, FullTextQuery};\n        use quickwit_query::MatchAllOrNone;\n\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test-query\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let search_response = search_plan(\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n        )\n        .await\n        .unwrap();\n        let response: SearchPlanResponseRest =\n            serde_json::from_str(&search_response.result).unwrap();\n        assert_eq!(\n            response,\n            SearchPlanResponseRest {\n                quickwit_ast: QueryAst::FullText(FullTextQuery {\n                    field: \"body\".to_string(),\n                    text: \"test-query\".to_string(),\n                    params: FullTextParams {\n                        tokenizer: None,\n                        mode: FullTextMode::PhraseFallbackToIntersection,\n                        zero_terms_query: MatchAllOrNone::MatchNone,\n                    },\n                    lenient: false,\n                },),\n                tantivy_ast: r#\"BooleanQuery {\n    subqueries: [\n        (\n            Must,\n            TermQuery(Term(field=3, type=Str, \"test\")),\n        ),\n        (\n            Must,\n            TermQuery(Term(field=3, type=Str, \"query\")),\n        ),\n    ],\n    minimum_number_should_match: 0,\n}\"#\n                .to_string(),\n                searched_splits: vec![\n                    \"test-index/split1\".to_string(),\n                    \"test-index/split2\".to_string()\n                ],\n                storage_requests: StorageRequestCount {\n                    footer: 1,\n                    fastfield: 0,\n                    fieldnorm: 0,\n                    sstable: 2,\n                    posting: 2,\n                    position: 0,\n                },\n            }\n        );\n        Ok(())\n    }\n\n    #[test]\n    fn test_extract_timestamp_range_from_ast() {\n        use std::ops::Bound;\n\n        use quickwit_query::JsonLiteral;\n\n        let timestamp_field = \"timestamp\";\n\n        let simple_range = quickwit_query::query_ast::RangeQuery {\n            field: timestamp_field.to_string(),\n            lower_bound: Bound::Included(JsonLiteral::String(\"2021-04-13T22:45:41Z\".to_owned())),\n            upper_bound: Bound::Excluded(JsonLiteral::String(\"2021-05-06T06:51:19Z\".to_owned())),\n        }\n        .into();\n\n        // direct range\n        let mut timestamp_range_extractor = ExtractTimestampRange {\n            timestamp_field,\n            start_timestamp: None,\n            end_timestamp: None,\n        };\n        timestamp_range_extractor.visit(&simple_range).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353941));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283879));\n\n        // range inside a must bool query\n        let bool_query_must = quickwit_query::query_ast::BoolQuery {\n            must: vec![simple_range.clone()],\n            ..Default::default()\n        };\n        timestamp_range_extractor.start_timestamp = None;\n        timestamp_range_extractor.end_timestamp = None;\n        timestamp_range_extractor\n            .visit(&bool_query_must.into())\n            .unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353941));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283879));\n\n        // range inside a should bool query\n        let bool_query_should = quickwit_query::query_ast::BoolQuery {\n            should: vec![simple_range.clone()],\n            ..Default::default()\n        };\n        timestamp_range_extractor.start_timestamp = Some(123);\n        timestamp_range_extractor.end_timestamp = None;\n        timestamp_range_extractor\n            .visit(&bool_query_should.into())\n            .unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(123));\n        assert_eq!(timestamp_range_extractor.end_timestamp, None);\n\n        // start bound was already more restrictive\n        timestamp_range_extractor.start_timestamp = Some(1618601297);\n        timestamp_range_extractor.end_timestamp = Some(i64::MAX);\n        timestamp_range_extractor.visit(&simple_range).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618601297));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283879));\n\n        // end bound was already more restrictive\n        timestamp_range_extractor.start_timestamp = Some(1);\n        timestamp_range_extractor.end_timestamp = Some(1618601297);\n        timestamp_range_extractor.visit(&simple_range).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353941));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1618601297));\n\n        // bounds are (start..end] instead of [start..end)\n        let unusual_bounds = quickwit_query::query_ast::RangeQuery {\n            field: timestamp_field.to_string(),\n            lower_bound: Bound::Excluded(JsonLiteral::String(\"2021-04-13T22:45:41Z\".to_owned())),\n            upper_bound: Bound::Included(JsonLiteral::String(\"2021-05-06T06:51:19Z\".to_owned())),\n        }\n        .into();\n        timestamp_range_extractor.start_timestamp = None;\n        timestamp_range_extractor.end_timestamp = None;\n        timestamp_range_extractor.visit(&unusual_bounds).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353942));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283880));\n\n        let wrong_field = quickwit_query::query_ast::RangeQuery {\n            field: \"other_field\".to_string(),\n            lower_bound: Bound::Included(JsonLiteral::String(\"2021-04-13T22:45:41Z\".to_owned())),\n            upper_bound: Bound::Excluded(JsonLiteral::String(\"2021-05-06T06:51:19Z\".to_owned())),\n        }\n        .into();\n        timestamp_range_extractor.start_timestamp = None;\n        timestamp_range_extractor.end_timestamp = None;\n        timestamp_range_extractor.visit(&wrong_field).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, None);\n        assert_eq!(timestamp_range_extractor.end_timestamp, None);\n\n        let high_precision = quickwit_query::query_ast::RangeQuery {\n            field: timestamp_field.to_string(),\n            lower_bound: Bound::Included(JsonLiteral::String(\n                \"2021-04-13T22:45:41.001Z\".to_owned(),\n            )),\n            upper_bound: Bound::Excluded(JsonLiteral::String(\n                \"2021-05-06T06:51:19.001Z\".to_owned(),\n            )),\n        }\n        .into();\n\n        // the upper bound should be rounded up as to includes documents from X.000 to X.001\n        let mut timestamp_range_extractor = ExtractTimestampRange {\n            timestamp_field,\n            start_timestamp: None,\n            end_timestamp: None,\n        };\n        timestamp_range_extractor.visit(&high_precision).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353941));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283880));\n    }\n\n    fn create_search_resp(\n        index_uri: &str,\n        hit_range: Range<usize>,\n        search_after: Option<PartialHit>,\n    ) -> LeafSearchResponse {\n        let (num_total_hits, split_id) = match index_uri {\n            \"ram:///test-index-1\" => (TOTAL_NUM_HITS_INDEX_1, \"split1\"),\n            \"ram:///test-index-2\" => (TOTAL_NUM_HITS_INDEX_2, \"split2\"),\n            _ => panic!(\"unexpected index uri\"),\n        };\n\n        let doc_ids = (0..num_total_hits)\n            .rev()\n            .filter(|elem| {\n                if let Some(search_after) = &search_after {\n                    if split_id == search_after.split_id {\n                        *elem < (search_after.doc_id as usize)\n                    } else {\n                        split_id < search_after.split_id.as_str()\n                    }\n                } else {\n                    true\n                }\n            })\n            .skip(hit_range.start)\n            .take(hit_range.end - hit_range.start);\n        quickwit_proto::search::LeafSearchResponse {\n            num_hits: num_total_hits as u64,\n            partial_hits: doc_ids\n                .map(|doc_id| mock_partial_hit_opt_sort_value(split_id, None, doc_id as u32))\n                .collect(),\n            num_attempted_splits: 1,\n            ..Default::default()\n        }\n    }\n\n    const TOTAL_NUM_HITS_INDEX_1: usize = 2_005;\n    const TOTAL_NUM_HITS_INDEX_2: usize = 10;\n    const MAX_HITS_PER_PAGE: usize = 93;\n    const MAX_HITS_PER_PAGE_LARGE: usize = 1_005;\n\n    #[tokio::test]\n    async fn test_root_search_with_scroll() {\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_uid = index_metadata.index_uid.clone();\n        let index_metadata_2 = IndexMetadata::for_test(\"test-index-2\", \"ram:///test-index-2\");\n        let index_uid_2 = index_metadata_2.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                let indexes_metadata = vec![index_metadata.clone(), index_metadata_2.clone()];\n                Ok(ListIndexesMetadataResponse::for_test(indexes_metadata))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid_2)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        // We add two mock_search_service to simulate a multi node environment, where the requests\n        // are forwarded two node.\n        let mut mock_search_service1 = MockSearchService::new();\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_none());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n\n        let mut mock_search_service2 = MockSearchService::new();\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_none());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n\n        let kv: Arc<RwLock<HashMap<Vec<u8>, Vec<u8>>>> = Default::default();\n        let kv_clone = kv.clone();\n        mock_search_service1\n            .expect_put_kv()\n            .returning(move |put_kv_req| {\n                kv_clone\n                    .write()\n                    .unwrap()\n                    .insert(put_kv_req.key, put_kv_req.payload);\n            });\n        mock_search_service1\n            .expect_get_kv()\n            .returning(move |get_kv_req| kv.read().unwrap().get(&get_kv_req.key).cloned());\n\n        let kv: Arc<RwLock<HashMap<Vec<u8>, Vec<u8>>>> = Default::default();\n        let kv_clone = kv.clone();\n        mock_search_service2\n            .expect_put_kv()\n            .returning(move |put_kv_req| {\n                kv_clone\n                    .write()\n                    .unwrap()\n                    .insert(put_kv_req.key, put_kv_req.payload);\n            });\n        mock_search_service2\n            .expect_get_kv()\n            .returning(move |get_kv_req| kv.read().unwrap().get(&get_kv_req.key).cloned());\n\n        mock_search_service1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                assert!(fetch_docs_req.partial_hits.len() <= MAX_HITS_PER_PAGE);\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n\n        mock_search_service2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                assert!(fetch_docs_req.partial_hits.len() <= MAX_HITS_PER_PAGE);\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service1),\n            (\"127.0.0.1:1002\", mock_search_service2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let searcher_context = SearcherContext::for_test();\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n\n        let mut count_seen_hits = 0;\n\n        let mut scroll_id: String = {\n            let search_request = quickwit_proto::search::SearchRequest {\n                index_id_patterns: vec![\"test-index-*\".to_string()],\n                query_ast: qast_json_helper(\"test\", &[\"body\"]),\n                max_hits: MAX_HITS_PER_PAGE as u64,\n                scroll_ttl_secs: Some(60),\n                ..Default::default()\n            };\n            let search_response = root_search(\n                &searcher_context,\n                search_request,\n                MetastoreServiceClient::from_mock(mock_metastore),\n                &cluster_client,\n            )\n            .await\n            .unwrap();\n            assert_eq!(\n                search_response.num_hits,\n                (TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2) as u64\n            );\n            assert_eq!(search_response.hits.len(), MAX_HITS_PER_PAGE);\n            let expected = (0..TOTAL_NUM_HITS_INDEX_2)\n                .rev()\n                .zip(std::iter::repeat(\"split2\"))\n                .chain(\n                    (0..TOTAL_NUM_HITS_INDEX_1)\n                        .rev()\n                        .zip(std::iter::repeat(\"split1\")),\n                );\n            for (hit, (doc_id, split)) in search_response.hits.iter().zip(expected) {\n                assert_eq!(\n                    hit.partial_hit.as_ref().unwrap(),\n                    &mock_partial_hit_opt_sort_value(split, None, doc_id as u32)\n                );\n            }\n            count_seen_hits += search_response.hits.len();\n            search_response.scroll_id.unwrap()\n        };\n        for page in 1.. {\n            let scroll_req = ScrollRequest {\n                scroll_id,\n                scroll_ttl_secs: Some(60),\n            };\n            let scroll_resp =\n                crate::service::scroll(scroll_req, &cluster_client, &searcher_context)\n                    .await\n                    .unwrap();\n            assert_eq!(\n                scroll_resp.num_hits,\n                (TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2) as u64\n            );\n            let expected = (0..TOTAL_NUM_HITS_INDEX_2)\n                .rev()\n                .zip(std::iter::repeat(\"split2\"))\n                .chain(\n                    (0..TOTAL_NUM_HITS_INDEX_1)\n                        .rev()\n                        .zip(std::iter::repeat(\"split1\")),\n                )\n                .skip(page * MAX_HITS_PER_PAGE);\n            for (hit, (doc_id, split)) in scroll_resp.hits.iter().zip(expected) {\n                assert_eq!(\n                    hit.partial_hit.as_ref().unwrap(),\n                    &mock_partial_hit_opt_sort_value(split, None, doc_id as u32)\n                );\n            }\n            scroll_id = scroll_resp.scroll_id.unwrap();\n            count_seen_hits += scroll_resp.hits.len();\n            if scroll_resp.hits.is_empty() {\n                break;\n            }\n        }\n\n        assert_eq!(\n            count_seen_hits,\n            TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2\n        );\n    }\n\n    #[tokio::test]\n    async fn test_root_search_with_scroll_large_page() {\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_uid = index_metadata.index_uid.clone();\n        let index_metadata_2 = IndexMetadata::for_test(\"test-index-2\", \"ram:///test-index-2\");\n        let index_uid_2 = index_metadata_2.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                let indexes_metadata = vec![index_metadata.clone(), index_metadata_2.clone()];\n                Ok(ListIndexesMetadataResponse::for_test(indexes_metadata))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid_2)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        // We add two mock_search_service to simulate a multi node environment, where the requests\n        // are forwarded two nodes.\n        let mut mock_search_service1 = MockSearchService::new();\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_none());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        let kv: Arc<RwLock<HashMap<Vec<u8>, Vec<u8>>>> = Default::default();\n        let kv_clone = kv.clone();\n        mock_search_service1\n            .expect_put_kv()\n            .returning(move |put_kv_req| {\n                kv_clone\n                    .write()\n                    .unwrap()\n                    .insert(put_kv_req.key, put_kv_req.payload);\n            });\n        mock_search_service1\n            .expect_get_kv()\n            .returning(move |get_kv_req| kv.read().unwrap().get(&get_kv_req.key).cloned());\n        mock_search_service1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                assert!(fetch_docs_req.partial_hits.len() <= MAX_HITS_PER_PAGE_LARGE);\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n\n        let mut mock_search_service2 = MockSearchService::new();\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_none());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        let kv: Arc<RwLock<HashMap<Vec<u8>, Vec<u8>>>> = Default::default();\n        let kv_clone = kv.clone();\n        mock_search_service2\n            .expect_put_kv()\n            .returning(move |put_kv_req| {\n                kv_clone\n                    .write()\n                    .unwrap()\n                    .insert(put_kv_req.key, put_kv_req.payload);\n            });\n        mock_search_service2\n            .expect_get_kv()\n            .returning(move |get_kv_req| kv.read().unwrap().get(&get_kv_req.key).cloned());\n        mock_search_service2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                assert!(fetch_docs_req.partial_hits.len() <= MAX_HITS_PER_PAGE_LARGE);\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service1),\n            (\"127.0.0.1:1002\", mock_search_service2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let searcher_context = SearcherContext::for_test();\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n\n        let mut count_seen_hits = 0;\n\n        let mut scroll_id: String = {\n            let search_request = quickwit_proto::search::SearchRequest {\n                index_id_patterns: vec![\"test-index-*\".to_string()],\n                query_ast: qast_json_helper(\"test\", &[\"body\"]),\n                max_hits: MAX_HITS_PER_PAGE_LARGE as u64,\n                scroll_ttl_secs: Some(60),\n                ..Default::default()\n            };\n            let search_response = root_search(\n                &searcher_context,\n                search_request,\n                MetastoreServiceClient::from_mock(mock_metastore),\n                &cluster_client,\n            )\n            .await\n            .unwrap();\n            assert_eq!(\n                search_response.num_hits,\n                (TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2) as u64\n            );\n            assert_eq!(search_response.hits.len(), MAX_HITS_PER_PAGE_LARGE);\n            let expected = (0..TOTAL_NUM_HITS_INDEX_2)\n                .rev()\n                .zip(std::iter::repeat(\"split2\"))\n                .chain(\n                    (0..TOTAL_NUM_HITS_INDEX_1)\n                        .rev()\n                        .zip(std::iter::repeat(\"split1\")),\n                );\n            for (hit, (doc_id, split)) in search_response.hits.iter().zip(expected) {\n                assert_eq!(\n                    hit.partial_hit.as_ref().unwrap(),\n                    &mock_partial_hit_opt_sort_value(split, None, doc_id as u32)\n                );\n            }\n            count_seen_hits += search_response.hits.len();\n            search_response.scroll_id.unwrap()\n        };\n        for page in 1.. {\n            let scroll_req = ScrollRequest {\n                scroll_id,\n                scroll_ttl_secs: Some(60),\n            };\n            let scroll_resp =\n                crate::service::scroll(scroll_req, &cluster_client, &searcher_context)\n                    .await\n                    .unwrap();\n            assert_eq!(\n                scroll_resp.num_hits,\n                (TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2) as u64\n            );\n            let expected = (0..TOTAL_NUM_HITS_INDEX_2)\n                .rev()\n                .zip(std::iter::repeat(\"split2\"))\n                .chain(\n                    (0..TOTAL_NUM_HITS_INDEX_1)\n                        .rev()\n                        .zip(std::iter::repeat(\"split1\")),\n                )\n                .skip(page * MAX_HITS_PER_PAGE_LARGE);\n            for (hit, (doc_id, split)) in scroll_resp.hits.iter().zip(expected) {\n                assert_eq!(\n                    hit.partial_hit.as_ref().unwrap(),\n                    &mock_partial_hit_opt_sort_value(split, None, doc_id as u32)\n                );\n            }\n            scroll_id = scroll_resp.scroll_id.unwrap();\n            count_seen_hits += scroll_resp.hits.len();\n            if scroll_resp.hits.is_empty() {\n                break;\n            }\n        }\n\n        assert_eq!(\n            count_seen_hits,\n            TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2\n        );\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multi_indices() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index-*\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata_1 = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_uid_1 = index_metadata_1.index_uid.clone();\n        let index_metadata_2 =\n            index_metadata_for_multi_indexes_test(\"test-index-2\", \"ram:///test-index-2\");\n        let index_uid_2 = index_metadata_2.index_uid.clone();\n        let index_metadata_3 =\n            index_metadata_for_multi_indexes_test(\"test-index-3\", \"ram:///test-index-3\");\n        let index_uid_3 = index_metadata_3.index_uid.clone();\n        mock_metastore.expect_list_indexes_metadata().return_once(\n            move |list_indexes_metadata_request: ListIndexesMetadataRequest| {\n                let index_id_patterns = list_indexes_metadata_request.index_id_patterns;\n                assert_eq!(&index_id_patterns, &[\"test-index-*\".to_string()]);\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata_1,\n                    index_metadata_2,\n                    index_metadata_3,\n                ]))\n            },\n        );\n        mock_metastore\n            .expect_list_splits()\n            .return_once(move |list_splits_request| {\n                let list_splits_query =\n                    list_splits_request.deserialize_list_splits_query().unwrap();\n                assert!(\n                    list_splits_query.index_uids\n                        == vec![\n                            index_uid_1.clone(),\n                            index_uid_2.clone(),\n                            index_uid_3.clone()\n                        ]\n                );\n                let splits = vec![\n                    MockSplitBuilder::new(\"index-1-split-1\")\n                        .with_index_uid(&index_uid_1)\n                        .build(),\n                    MockSplitBuilder::new(\"index-1-split-2\")\n                        .with_index_uid(&index_uid_1)\n                        .build(),\n                    MockSplitBuilder::new(\"index-2-split-1\")\n                        .with_index_uid(&index_uid_2)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1\n            .expect_leaf_search()\n            .times(1)\n            .withf(|leaf_search_req| {\n                (&leaf_search_req.index_uris[0] == \"ram:///test-index-1\"\n                    && leaf_search_req.leaf_requests[0].split_offsets.len() == 2)\n                    || (leaf_search_req.index_uris[0] == \"ram:///test-index-2\"\n                        && leaf_search_req.leaf_requests[0].split_offsets[0].split_id\n                            == \"index-2-split-1\")\n            })\n            .returning(\n                |leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                    let mut partial_hits = leaf_search_req.leaf_requests[0]\n                        .split_offsets\n                        .iter()\n                        .map(|split_offset| mock_partial_hit(&split_offset.split_id, 3, 1))\n                        .collect_vec();\n                    let partial_hits2 = leaf_search_req.leaf_requests[1]\n                        .split_offsets\n                        .iter()\n                        .map(|split_offset| mock_partial_hit(&split_offset.split_id, 3, 1))\n                        .collect_vec();\n                    partial_hits.extend_from_slice(&partial_hits2);\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: leaf_search_req.leaf_requests[0].split_offsets.len() as u64\n                            + leaf_search_req.leaf_requests[1].split_offsets.len() as u64,\n                        partial_hits,\n                        failed_splits: Vec::new(),\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                },\n            );\n        mock_search_service_1\n            .expect_fetch_docs()\n            .times(2)\n            .withf(|fetch_docs_req: &FetchDocsRequest| {\n                (fetch_docs_req.index_uri == \"ram:///test-index-1\"\n                    && fetch_docs_req.partial_hits.len() == 2)\n                    || (fetch_docs_req.index_uri == \"ram:///test-index-2\"\n                        && fetch_docs_req.partial_hits[0].split_id == \"index-2-split-1\")\n            })\n            .returning(|fetch_docs_req| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            });\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service_1)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        assert_eq!(\n            search_response\n                .hits\n                .iter()\n                .map(|hit| &hit.index_id)\n                .collect_vec(),\n            vec![\"test-index-1\", \"test-index-1\", \"test-index-2\"]\n        );\n        Ok(())\n    }\n}\n```\nasync fn search_partial_hits_phase_with_scroll(\nexplain me this function \n\n```rs quickwit/quickwit/quickwit-search/src/root.rs\n// Copyright (C) 2024 Quickwit, Inc.\n//\n// Quickwit is offered under the AGPL v3.0 and as commercial software.\n// For commercial licensing, contact us at hello@quickwit.io.\n//\n// AGPL:\n// This program is free software: you can redistribute it and/or modify\n// it under the terms of the GNU Affero General Public License as\n// published by the Free Software Foundation, either version 3 of the\n// License, or (at your option) any later version.\n//\n// This program is distributed in the hope that it will be useful,\n// but WITHOUT ANY WARRANTY; without even the implied warranty of\n// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n// GNU Affero General Public License for more details.\n//\n// You should have received a copy of the GNU Affero General Public License\n// along with this program. If not, see <http://www.gnu.org/licenses/>.\n\nuse std::collections::{HashMap, HashSet};\nuse std::sync::OnceLock;\nuse std::time::Duration;\n\nuse anyhow::Context;\nuse futures::future::try_join_all;\nuse itertools::Itertools;\nuse quickwit_common::pretty::PrettySample;\nuse quickwit_common::shared_consts;\nuse quickwit_common::uri::Uri;\nuse quickwit_config::build_doc_mapper;\nuse quickwit_doc_mapper::tag_pruning::extract_tags_from_query;\nuse quickwit_doc_mapper::DYNAMIC_FIELD_NAME;\nuse quickwit_metastore::{IndexMetadata, ListIndexesMetadataResponseExt, SplitMetadata};\nuse quickwit_proto::metastore::{\n    ListIndexesMetadataRequest, MetastoreService, MetastoreServiceClient,\n};\nuse quickwit_proto::search::{\n    FetchDocsRequest, FetchDocsResponse, Hit, LeafHit, LeafRequestRef, LeafSearchRequest,\n    LeafSearchResponse, PartialHit, SearchPlanResponse, SearchRequest, SearchResponse,\n    SnippetRequest, SortDatetimeFormat, SortField, SortValue, SplitIdAndFooterOffsets,\n};\nuse quickwit_proto::types::{IndexUid, SplitId};\nuse quickwit_query::query_ast::{\n    BoolQuery, QueryAst, QueryAstVisitor, RangeQuery, TermQuery, TermSetQuery,\n};\nuse serde::{Deserialize, Serialize};\nuse tantivy::aggregation::agg_result::AggregationResults;\nuse tantivy::aggregation::intermediate_agg_result::IntermediateAggregationResults;\nuse tantivy::collector::Collector;\nuse tantivy::schema::{FieldEntry, FieldType, Schema};\nuse tantivy::TantivyError;\nuse tracing::{debug, error, info, info_span, instrument};\n\nuse crate::cluster_client::ClusterClient;\nuse crate::collector::{make_merge_collector, QuickwitAggregations};\nuse crate::find_trace_ids_collector::Span;\nuse crate::scroll_context::{ScrollContext, ScrollKeyAndStartOffset};\nuse crate::search_job_placer::{group_by, group_jobs_by_index_id, Job};\nuse crate::search_response_rest::StorageRequestCount;\nuse crate::service::SearcherContext;\nuse crate::{\n    extract_split_and_footer_offsets, list_relevant_splits, SearchError, SearchJobPlacer,\n    SearchPlanResponseRest, SearchServiceClient,\n};\n\n/// Maximum accepted scroll TTL.\nfn max_scroll_ttl() -> Duration {\n    static MAX_SCROLL_TTL_LOCK: OnceLock<Duration> = OnceLock::new();\n    *MAX_SCROLL_TTL_LOCK.get_or_init(|| {\n        let split_deletion_grace_period = shared_consts::split_deletion_grace_period();\n        assert!(\n            split_deletion_grace_period >= shared_consts::MINIMUM_DELETION_GRACE_PERIOD,\n            \"The split deletion grace period is too short ({split_deletion_grace_period:?}). This \\\n             should not happen.\"\n        );\n        // We remove an extra margin of 2minutes from the split deletion grace period.\n        split_deletion_grace_period - Duration::from_secs(60 * 2)\n    })\n}\n\nconst SORT_DOC_FIELD_NAMES: &[&str] = &[\"_shard_doc\", \"_doc\"];\n\n/// SearchJob to be assigned to search clients by the [`SearchJobPlacer`].\n#[derive(Debug, Clone, PartialEq)]\npub struct SearchJob {\n    /// The index UID.\n    pub index_uid: IndexUid,\n    cost: usize,\n    /// The split ID and footer offsets of the split.\n    pub offsets: SplitIdAndFooterOffsets,\n}\n\nimpl SearchJob {\n    #[cfg(test)]\n    pub fn for_test(split_id: &str, cost: usize) -> SearchJob {\n        use std::str::FromStr;\n        SearchJob {\n            index_uid: IndexUid::from_str(\"test-index:00000000000000000000000000\").unwrap(),\n            cost,\n            offsets: SplitIdAndFooterOffsets {\n                split_id: split_id.to_string(),\n                ..Default::default()\n            },\n        }\n    }\n}\n\nimpl From<SearchJob> for SplitIdAndFooterOffsets {\n    fn from(search_job: SearchJob) -> Self {\n        search_job.offsets\n    }\n}\n\nimpl<'a> From<&'a SplitMetadata> for SearchJob {\n    fn from(split_metadata: &'a SplitMetadata) -> Self {\n        SearchJob {\n            index_uid: split_metadata.index_uid.clone(),\n            cost: compute_split_cost(split_metadata),\n            offsets: extract_split_and_footer_offsets(split_metadata),\n        }\n    }\n}\n\nimpl Job for SearchJob {\n    fn split_id(&self) -> &str {\n        &self.offsets.split_id\n    }\n\n    fn cost(&self) -> usize {\n        self.cost\n    }\n}\n\npub struct FetchDocsJob {\n    index_uid: IndexUid,\n    offsets: SplitIdAndFooterOffsets,\n    pub partial_hits: Vec<PartialHit>,\n}\n\nimpl Job for FetchDocsJob {\n    fn split_id(&self) -> &str {\n        &self.offsets.split_id\n    }\n\n    fn cost(&self) -> usize {\n        self.partial_hits.len()\n    }\n}\n\nimpl From<FetchDocsJob> for SplitIdAndFooterOffsets {\n    fn from(fetch_docs_job: FetchDocsJob) -> SplitIdAndFooterOffsets {\n        fetch_docs_job.offsets\n    }\n}\n\n/// Index metas needed for executing a leaf search request.\n#[derive(Serialize, Deserialize, Clone, Debug)]\npub struct IndexMetasForLeafSearch {\n    /// Index URI.\n    pub index_uri: Uri,\n    /// Doc mapper json string.\n    pub doc_mapper_str: String,\n}\n\npub(crate) type IndexesMetasForLeafSearch = HashMap<IndexUid, IndexMetasForLeafSearch>;\n\n#[derive(Debug)]\nstruct RequestMetadata {\n    timestamp_field_opt: Option<String>,\n    query_ast_resolved: QueryAst,\n    indexes_meta_for_leaf_search: IndexesMetasForLeafSearch,\n    sort_fields_is_datetime: HashMap<String, bool>,\n}\n\n/// Validates request against each index's doc mapper and ensures that:\n/// - timestamp fields (if any) are equal across indexes.\n/// - resolved query ASTs are the same across indexes.\n/// - if a sort field is of type datetime, it must be a datetime field on all indexes. This\n///   constraint come from the need to support datetime formatting on sort values.\n/// Returns the timestamp field, the resolved query AST and the indexes metadatas\n/// needed for leaf search requests.\n/// Note: the requirements on timestamp fields and resolved query ASTs can be lifted\n/// but it adds complexity that does not seem needed right now.\nfn validate_request_and_build_metadata(\n    indexes_metadata: &[IndexMetadata],\n    search_request: &SearchRequest,\n) -> crate::Result<RequestMetadata> {\n    validate_sort_by_fields_and_search_after(\n        &search_request.sort_fields,\n        &search_request.search_after,\n    )?;\n    let query_ast: QueryAst = serde_json::from_str(&search_request.query_ast)\n        .map_err(|err| SearchError::InvalidQuery(err.to_string()))?;\n    let mut indexes_meta_for_leaf_search: HashMap<IndexUid, IndexMetasForLeafSearch> =\n        HashMap::new();\n    let mut query_ast_resolved_opt: Option<QueryAst> = None;\n    let mut timestamp_field_opt: Option<String> = None;\n    let mut sort_fields_is_datetime: HashMap<String, bool> = HashMap::new();\n\n    for index_metadata in indexes_metadata {\n        let doc_mapper = build_doc_mapper(\n            &index_metadata.index_config.doc_mapping,\n            &index_metadata.index_config.search_settings,\n        )\n        .map_err(|err| {\n            SearchError::Internal(format!(\"failed to build doc mapper. cause: {err}\"))\n        })?;\n        let query_ast_resolved_for_index = query_ast\n            .clone()\n            .parse_user_query(doc_mapper.default_search_fields())\n            // We convert the error to return a 400 to the user (and not a 500).\n            .map_err(|err| SearchError::InvalidQuery(err.to_string()))?;\n\n        // Validate uniqueness of resolved query AST.\n        if let Some(query_ast_resolved) = &query_ast_resolved_opt {\n            if query_ast_resolved != &query_ast_resolved_for_index {\n                return Err(SearchError::InvalidQuery(\n                    \"resolved query ASTs must be the same across indexes. resolving queries with \\\n                     different default fields are different between indexes is not supported\"\n                        .to_string(),\n                ));\n            }\n        } else {\n            query_ast_resolved_opt = Some(query_ast_resolved_for_index.clone());\n        }\n\n        // Validate uniqueness of timestamp field if any.\n        if let Some(timestamp_field_for_index) = doc_mapper.timestamp_field_name() {\n            match timestamp_field_opt {\n                Some(timestamp_field) if timestamp_field != timestamp_field_for_index => {\n                    return Err(SearchError::InvalidQuery(\n                        \"the timestamp field (if present) must be the same for all indexes\"\n                            .to_string(),\n                    ));\n                }\n                None => {\n                    timestamp_field_opt = Some(timestamp_field_for_index.to_string());\n                }\n                _ => {}\n            }\n        }\n\n        // Validate request against the current index schema.\n        let schema = doc_mapper.schema();\n        validate_request(&schema, &doc_mapper.timestamp_field_name(), search_request)?;\n\n        validate_sort_field_types(\n            &schema,\n            &search_request.sort_fields,\n            &mut sort_fields_is_datetime,\n        )?;\n\n        // Validates the query by effectively building it against the current schema.\n        doc_mapper.query(doc_mapper.schema(), &query_ast_resolved_for_index, true)?;\n\n        let index_metadata_for_leaf_search = IndexMetasForLeafSearch {\n            index_uri: index_metadata.index_uri().clone(),\n            doc_mapper_str: serde_json::to_string(&doc_mapper).map_err(|err| {\n                SearchError::Internal(format!(\"failed to serialize doc mapper. cause: {err}\"))\n            })?,\n        };\n        indexes_meta_for_leaf_search.insert(\n            index_metadata.index_uid.clone(),\n            index_metadata_for_leaf_search,\n        );\n    }\n\n    let query_ast_resolved = query_ast_resolved_opt.ok_or_else(|| {\n        SearchError::Internal(\n            \"resolved query AST must be present. this should never happen\".to_string(),\n        )\n    })?;\n\n    Ok(RequestMetadata {\n        timestamp_field_opt,\n        query_ast_resolved,\n        indexes_meta_for_leaf_search,\n        sort_fields_is_datetime,\n    })\n}\n\n/// Validate sort field types.\nfn validate_sort_field_types(\n    schema: &Schema,\n    sort_fields: &[SortField],\n    sort_field_is_datetime: &mut HashMap<String, bool>,\n) -> crate::Result<()> {\n    for sort_field in sort_fields.iter() {\n        if let Some(sort_field_entry) = get_sort_by_field_entry(&sort_field.field_name, schema)? {\n            validate_sort_by_field_type(\n                sort_field_entry,\n                sort_field.sort_datetime_format.is_some(),\n            )?;\n            // If sort field type is a date, ensure it's true for all indexes.\n            if let Some(is_datetime) = sort_field_is_datetime.get(&sort_field.field_name) {\n                if *is_datetime != sort_field_entry.field_type().is_date() {\n                    return Err(SearchError::InvalidQuery(format!(\n                        \"sort datetime field `{}` must be of type datetime on all indexes\",\n                        sort_field_entry.name(),\n                    )));\n                }\n            } else {\n                sort_field_is_datetime.insert(\n                    sort_field.field_name.to_string(),\n                    sort_field_entry.field_type().is_date(),\n                );\n            }\n        } else {\n            sort_field_is_datetime.insert(sort_field.field_name.to_string(), false);\n        }\n    }\n    Ok(())\n}\n\nfn validate_requested_snippet_fields(\n    schema: &Schema,\n    snippet_fields: &[String],\n) -> anyhow::Result<()> {\n    for field_name in snippet_fields {\n        let field_entry = schema\n            .get_field(field_name)\n            .map(|field| schema.get_field_entry(field))?;\n        match field_entry.field_type() {\n            FieldType::Str(text_options) => {\n                if !text_options.is_stored() {\n                    return Err(anyhow::anyhow!(\n                        \"the snippet field `{}` must be stored\",\n                        field_name\n                    ));\n                }\n            }\n            other => {\n                return Err(anyhow::anyhow!(\n                    \"the snippet field `{}` must be of type `Str`, got `{}`\",\n                    field_name,\n                    other.value_type().name()\n                ))\n            }\n        }\n    }\n    Ok(())\n}\n\nfn simplify_search_request_for_scroll_api(req: &SearchRequest) -> crate::Result<SearchRequest> {\n    if req.search_after.is_some() {\n        return Err(SearchError::InvalidArgument(\n            \"search_after cannot be used in a scroll context\".to_string(),\n        ));\n    }\n\n    // We do not mutate\n    Ok(SearchRequest {\n        index_id_patterns: req.index_id_patterns.clone(),\n        query_ast: req.query_ast.clone(),\n        start_timestamp: req.start_timestamp,\n        end_timestamp: req.end_timestamp,\n        max_hits: req.max_hits,\n        start_offset: req.start_offset,\n        sort_fields: req.sort_fields.clone(),\n        // We remove all aggregation request.\n        // The aggregation will not be computed for each scroll request.\n        aggregation_request: None,\n        // We remove the snippet fields. This feature is not supported for scroll requests.\n        snippet_fields: Vec::new(),\n        // We remove the scroll ttl parameter. It is irrelevant to process later request\n        scroll_ttl_secs: None,\n        search_after: None,\n        // request is simplified after initial query, and we cache the hit count, so we don't need\n        // to recompute it afterward.\n        count_hits: quickwit_proto::search::CountHits::Underestimate as i32,\n    })\n}\n\n/// Validates sort fields and search after values.\n/// - validate sort fields length.\n/// - search after values must be set for all sort fields.\nfn validate_sort_by_fields_and_search_after(\n    sort_fields: &[SortField],\n    search_after: &Option<PartialHit>,\n) -> crate::Result<()> {\n    if sort_fields.is_empty() {\n        return Ok(());\n    }\n    if sort_fields.len() > 2 {\n        return Err(SearchError::InvalidArgument(format!(\n            \"sort by field must be up to 2 fields, got {}\",\n            sort_fields.len()\n        )));\n    }\n    let Some(search_after_partial_hit) = search_after.as_ref() else {\n        return Ok(());\n    };\n\n    let sort_fields_without_doc_count = sort_fields\n        .iter()\n        .filter(|sort_field| !SORT_DOC_FIELD_NAMES.contains(&sort_field.field_name.as_str()))\n        .count();\n    let has_doc_sort_field = sort_fields_without_doc_count != sort_fields.len();\n    if has_doc_sort_field && search_after_partial_hit.split_id.is_empty() {\n        return Err(SearchError::InvalidArgument(\n            \"search_after with a sort field `_doc` must define a split ID, segment ID and doc ID \\\n             values\"\n                .to_string(),\n        ));\n    }\n\n    let mut search_after_sort_value_count = 0;\n    // TODO: we could validate if the search after sort value types of consistent with the sort\n    // field types.\n    if let Some(sort_by_value) = search_after_partial_hit.sort_value.as_ref() {\n        sort_by_value.sort_value.context(\"sort value must be set\")?;\n        search_after_sort_value_count += 1;\n    }\n    if let Some(sort_by_value_2) = search_after_partial_hit.sort_value2.as_ref() {\n        sort_by_value_2\n            .sort_value\n            .context(\"sort value must be set\")?;\n        search_after_sort_value_count += 1;\n    }\n    if search_after_sort_value_count != sort_fields_without_doc_count {\n        return Err(SearchError::InvalidArgument(format!(\n            \"`search_after` must have the same number of sort values as sort by fields {:?}\",\n            sort_fields\n                .iter()\n                .map(|sort_field| &sort_field.field_name)\n                .collect_vec()\n        )));\n    }\n    Ok(())\n}\n\nfn get_sort_by_field_entry<'a>(\n    field_name: &str,\n    schema: &'a Schema,\n) -> crate::Result<Option<&'a FieldEntry>> {\n    if \"_score\" == field_name || SORT_DOC_FIELD_NAMES.contains(&field_name) {\n        return Ok(None);\n    }\n    let dynamic_field_opt = schema.get_field(DYNAMIC_FIELD_NAME).ok();\n    let (sort_by_field, _json_path) = schema\n        .find_field_with_default(field_name, dynamic_field_opt)\n        .ok_or_else(|| {\n            SearchError::InvalidArgument(format!(\"unknown field used in `sort by`: {field_name}\"))\n        })?;\n    let sort_by_field_entry = schema.get_field_entry(sort_by_field);\n    Ok(Some(sort_by_field_entry))\n}\n\n/// Validates sort field type.\nfn validate_sort_by_field_type(\n    sort_by_field_entry: &FieldEntry,\n    has_timestamp_format: bool,\n) -> crate::Result<()> {\n    let field_name = sort_by_field_entry.name();\n    if matches!(sort_by_field_entry.field_type(), FieldType::Str(_)) {\n        return Err(SearchError::InvalidArgument(format!(\n            \"sort by field on type text is currently not supported `{field_name}`\"\n        )));\n    }\n    if !sort_by_field_entry.is_fast() {\n        return Err(SearchError::InvalidArgument(format!(\n            \"sort by field must be a fast field, please add the fast property to your field \\\n             `{field_name}`\",\n        )));\n    }\n    if has_timestamp_format && !sort_by_field_entry.field_type().is_date() {\n        return Err(SearchError::InvalidArgument(format!(\n            \"sort by field with a timestamp format must be a datetime field and the field \\\n             `{field_name}` is not\",\n        )));\n    }\n    Ok(())\n}\n\nfn validate_request(\n    schema: &Schema,\n    timestamp_field_name: &Option<&str>,\n    search_request: &SearchRequest,\n) -> crate::Result<()> {\n    if timestamp_field_name.is_none()\n        && (search_request.start_timestamp.is_some() || search_request.end_timestamp.is_some())\n    {\n        return Err(SearchError::InvalidQuery(format!(\n            \"the timestamp field is not set in index: {:?} definition but start-timestamp or \\\n             end-timestamp are set in the query\",\n            search_request.index_id_patterns\n        )));\n    }\n\n    validate_requested_snippet_fields(schema, &search_request.snippet_fields)?;\n\n    if let Some(agg) = search_request.aggregation_request.as_ref() {\n        let _aggs: QuickwitAggregations = serde_json::from_str(agg).map_err(|_err| {\n            let err = serde_json::from_str::<tantivy::aggregation::agg_req::Aggregations>(agg)\n                .unwrap_err();\n            SearchError::InvalidAggregationRequest(err.to_string())\n        })?;\n    };\n\n    if search_request.start_offset > 10_000 {\n        return Err(SearchError::InvalidArgument(format!(\n            \"max value for start_offset is 10_000, but got {}\",\n            search_request.start_offset\n        )));\n    }\n\n    if search_request.max_hits > 10_000 {\n        return Err(SearchError::InvalidArgument(format!(\n            \"max value for max_hits is 10_000, but got {}\",\n            search_request.max_hits\n        )));\n    }\n\n    Ok(())\n}\n\nfn get_scroll_ttl_duration(search_request: &SearchRequest) -> crate::Result<Option<Duration>> {\n    let Some(scroll_ttl_secs) = search_request.scroll_ttl_secs else {\n        return Ok(None);\n    };\n    let scroll_ttl: Duration = Duration::from_secs(scroll_ttl_secs as u64);\n    let max_scroll_ttl = max_scroll_ttl();\n    if scroll_ttl > max_scroll_ttl {\n        return Err(SearchError::InvalidArgument(format!(\n            \"Quickwit only supports scroll TTL period up to {} secs\",\n            max_scroll_ttl.as_secs()\n        )));\n    }\n    Ok(Some(scroll_ttl))\n}\n\n#[instrument(level = \"debug\", skip_all)]\nasync fn search_partial_hits_phase_with_scroll(\n    searcher_context: &SearcherContext,\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    mut search_request: SearchRequest,\n    split_metadatas: &[SplitMetadata],\n    cluster_client: &ClusterClient,\n) -> crate::Result<(LeafSearchResponse, Option<ScrollKeyAndStartOffset>)> {\n    let scroll_ttl_opt = get_scroll_ttl_duration(&search_request)?;\n\n    if let Some(scroll_ttl) = scroll_ttl_opt {\n        let max_hits = search_request.max_hits;\n        // This is a scroll request.\n        //\n        // We increase max hits to add populate the scroll cache.\n        search_request.max_hits = search_request\n            .max_hits\n            .max(shared_consts::SCROLL_BATCH_LEN as u64);\n        search_request.scroll_ttl_secs = None;\n        let mut leaf_search_resp = search_partial_hits_phase(\n            searcher_context,\n            indexes_metas_for_leaf_search,\n            &search_request,\n            split_metadatas,\n            cluster_client,\n        )\n        .await?;\n        let cached_partial_hits = leaf_search_resp.partial_hits.clone();\n        leaf_search_resp.partial_hits.truncate(max_hits as usize);\n        let last_hit = leaf_search_resp\n            .partial_hits\n            .last()\n            .cloned()\n            .unwrap_or_default();\n\n        let scroll_context_search_request =\n            simplify_search_request_for_scroll_api(&search_request)?;\n        let mut scroll_ctx = ScrollContext {\n            indexes_metas_for_leaf_search: indexes_metas_for_leaf_search.clone(),\n            split_metadatas: split_metadatas.to_vec(),\n            search_request: scroll_context_search_request,\n            total_num_hits: leaf_search_resp.num_hits,\n            max_hits_per_page: max_hits,\n            cached_partial_hits_start_offset: search_request.start_offset,\n            cached_partial_hits,\n        };\n        let scroll_key_and_start_offset: ScrollKeyAndStartOffset =\n            ScrollKeyAndStartOffset::new_with_start_offset(\n                scroll_ctx.search_request.start_offset,\n                max_hits as u32,\n                last_hit.clone(),\n            )\n            .next_page(leaf_search_resp.partial_hits.len() as u64, last_hit);\n\n        scroll_ctx.clear_cache_if_unneeded();\n        let payload: Vec<u8> = scroll_ctx.serialize();\n        let scroll_key = scroll_key_and_start_offset.scroll_key();\n        cluster_client\n            .put_kv(&scroll_key, &payload, scroll_ttl)\n            .await;\n        Ok((leaf_search_resp, Some(scroll_key_and_start_offset)))\n    } else {\n        let leaf_search_resp = search_partial_hits_phase(\n            searcher_context,\n            indexes_metas_for_leaf_search,\n            &search_request,\n            split_metadatas,\n            cluster_client,\n        )\n        .await?;\n        Ok((leaf_search_resp, None))\n    }\n}\n\n/// Check if the request is a count request without any filters, so we can just return the split\n/// metadata count.\n///\n/// This is done by exclusion, so we will need to keep it up to date if fields are added.\npub fn is_metadata_count_request(request: &SearchRequest) -> bool {\n    let query_ast: QueryAst = serde_json::from_str(&request.query_ast).unwrap();\n    is_metadata_count_request_with_ast(&query_ast, request)\n}\n\n/// Check if the request is a count request without any filters, so we can just return the split\n/// metadata count.\n///\n/// This is done by exclusion, so we will need to keep it up to date if fields are added.\n///\n/// The passed query_ast should match the serialized on in request.\npub fn is_metadata_count_request_with_ast(query_ast: &QueryAst, request: &SearchRequest) -> bool {\n    if query_ast != &QueryAst::MatchAll {\n        return false;\n    }\n    if request.max_hits != 0 {\n        return false;\n    }\n\n    // If the start and end timestamp encompass the whole split, it is still a count query.\n    // We remove this currently on the leaf level, but not yet on the root level.\n    // There's a small advantage when we would do this on the root level, since we have the\n    // counts available on the split. On the leaf it is currently required to open the split\n    // to get the count.\n    if request.start_timestamp.is_some() || request.end_timestamp.is_some() {\n        return false;\n    }\n    if request.aggregation_request.is_some() || !request.snippet_fields.is_empty() {\n        return false;\n    }\n    true\n}\n\n/// Get a leaf search response that returns the num_docs of the split\npub fn get_count_from_metadata(split_metadatas: &[SplitMetadata]) -> Vec<LeafSearchResponse> {\n    split_metadatas\n        .iter()\n        .map(|metadata| LeafSearchResponse {\n            num_hits: metadata.num_docs as u64,\n            partial_hits: Vec::new(),\n            failed_splits: Vec::new(),\n            num_attempted_splits: 1,\n            intermediate_aggregation_result: None,\n        })\n        .collect()\n}\n\n#[instrument(level = \"debug\", skip_all)]\npub(crate) async fn search_partial_hits_phase(\n    searcher_context: &SearcherContext,\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    search_request: &SearchRequest,\n    split_metadatas: &[SplitMetadata],\n    cluster_client: &ClusterClient,\n) -> crate::Result<LeafSearchResponse> {\n    let leaf_search_responses: Vec<LeafSearchResponse> =\n        if is_metadata_count_request(search_request) {\n            get_count_from_metadata(split_metadatas)\n        } else {\n            let jobs: Vec<SearchJob> = split_metadatas.iter().map(SearchJob::from).collect();\n            let assigned_leaf_search_jobs = cluster_client\n                .search_job_placer\n                .assign_jobs(jobs, &HashSet::default())\n                .await?;\n            let mut leaf_request_tasks = Vec::new();\n            for (client, client_jobs) in assigned_leaf_search_jobs {\n                let leaf_request = jobs_to_leaf_request(\n                    search_request,\n                    indexes_metas_for_leaf_search,\n                    client_jobs,\n                )?;\n                leaf_request_tasks.push(cluster_client.leaf_search(leaf_request, client.clone()));\n            }\n            try_join_all(leaf_request_tasks).await?\n        };\n\n    // Creates a collector which merges responses into one\n    let merge_collector =\n        make_merge_collector(search_request, &searcher_context.get_aggregation_limits())?;\n\n    // Merging is a cpu-bound task.\n    // It should be executed by Tokio's blocking threads.\n\n    // Wrap into result for merge_fruits\n    let leaf_search_responses: Vec<tantivy::Result<LeafSearchResponse>> =\n        leaf_search_responses.into_iter().map(Ok).collect_vec();\n    let span = info_span!(\"merge_fruits\");\n    let leaf_search_response = crate::search_thread_pool()\n        .run_cpu_intensive(move || {\n            let _span_guard = span.enter();\n            merge_collector.merge_fruits(leaf_search_responses)\n        })\n        .await\n        .context(\"failed to merge leaf search responses\")?\n        .map_err(|error: TantivyError| crate::SearchError::Internal(error.to_string()))?;\n    debug!(\n        num_hits = leaf_search_response.num_hits,\n        failed_splits = ?leaf_search_response.failed_splits,\n        num_attempted_splits = leaf_search_response.num_attempted_splits,\n        has_intermediate_aggregation_result = leaf_search_response.intermediate_aggregation_result.is_some(),\n        \"Merged leaf search response.\"\n    );\n    if !leaf_search_response.failed_splits.is_empty() {\n        error!(failed_splits = ?leaf_search_response.failed_splits, \"leaf search response contains at least one failed split\");\n        let errors: String = leaf_search_response.failed_splits.iter().join(\", \");\n        return Err(SearchError::Internal(errors));\n    }\n    Ok(leaf_search_response)\n}\n\npub(crate) fn get_snippet_request(search_request: &SearchRequest) -> Option<SnippetRequest> {\n    if search_request.snippet_fields.is_empty() {\n        return None;\n    }\n    Some(SnippetRequest {\n        snippet_fields: search_request.snippet_fields.clone(),\n        query_ast_resolved: search_request.query_ast.clone(),\n    })\n}\n\n#[instrument(skip_all, fields(partial_hits_num=partial_hits.len()))]\npub(crate) async fn fetch_docs_phase(\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    partial_hits: &[PartialHit],\n    split_metadatas: &[SplitMetadata],\n    search_request: &SearchRequest,\n    cluster_client: &ClusterClient,\n) -> crate::Result<Vec<Hit>> {\n    let snippet_request: Option<SnippetRequest> = get_snippet_request(search_request);\n    let hit_order: HashMap<(String, u32, u32), usize> = partial_hits\n        .iter()\n        .enumerate()\n        .map(|(position, partial_hit)| {\n            let key = (\n                partial_hit.split_id.clone(),\n                partial_hit.segment_ord,\n                partial_hit.doc_id,\n            );\n            (key, position)\n        })\n        .collect();\n\n    let assigned_fetch_docs_jobs = assign_client_fetch_docs_jobs(\n        partial_hits,\n        split_metadatas,\n        &cluster_client.search_job_placer,\n    )\n    .await?;\n\n    let mut fetch_docs_tasks = Vec::new();\n    for (client, client_jobs) in assigned_fetch_docs_jobs {\n        let fetch_jobs_requests = jobs_to_fetch_docs_requests(\n            snippet_request.clone(),\n            indexes_metas_for_leaf_search,\n            client_jobs,\n        )?;\n        for fetch_docs_request in fetch_jobs_requests {\n            fetch_docs_tasks.push(cluster_client.fetch_docs(fetch_docs_request, client.clone()));\n        }\n    }\n    let fetch_docs_responses: Vec<FetchDocsResponse> = try_join_all(fetch_docs_tasks).await?;\n\n    // Merge the fetched docs.\n    let leaf_hits = fetch_docs_responses\n        .into_iter()\n        .flat_map(|response| response.hits.into_iter());\n\n    // Build map of Split ID > index ID to add the index ID to the hits.\n    // Used for ES compatibility.\n    let split_id_to_index_id_map: HashMap<&SplitId, &str> = split_metadatas\n        .iter()\n        .map(|split_metadata| {\n            (\n                &split_metadata.split_id,\n                split_metadata.index_uid.index_id.as_str(),\n            )\n        })\n        .collect();\n    let mut sort_field_iter = search_request.sort_fields.iter();\n    let sort_field_1_datetime_format_opt: Option<SortDatetimeFormat> =\n        get_sort_field_datetime_format(sort_field_iter.next())?;\n    let sort_field_2_datetime_format_opt: Option<SortDatetimeFormat> =\n        get_sort_field_datetime_format(sort_field_iter.next())?;\n    let mut hits_with_position: Vec<(usize, Hit)> = leaf_hits\n        .map(|leaf_hit| {\n            build_hit_with_position(\n                leaf_hit,\n                &split_id_to_index_id_map,\n                &hit_order,\n                &sort_field_1_datetime_format_opt,\n                &sort_field_2_datetime_format_opt,\n            )\n        })\n        .try_collect()?;\n\n    hits_with_position.sort_by_key(|(position, _)| *position);\n    let hits: Vec<Hit> = hits_with_position\n        .into_iter()\n        .map(|(_position, hit)| hit)\n        .collect();\n\n    Ok(hits)\n}\n\nfn build_hit_with_position(\n    mut leaf_hit: LeafHit,\n    split_id_to_index_id_map: &HashMap<&SplitId, &str>,\n    hit_order: &HashMap<(String, u32, u32), usize>,\n    sort_field_1_datetime_format_opt: &Option<SortDatetimeFormat>,\n    sort_field_2_datetime_format_opt: &Option<SortDatetimeFormat>,\n) -> crate::Result<(usize, Hit)> {\n    let partial_hit_ref = leaf_hit\n        .partial_hit\n        .as_mut()\n        .expect(\"partial hit must be present\");\n    let key = (\n        partial_hit_ref.split_id.clone(),\n        partial_hit_ref.segment_ord,\n        partial_hit_ref.doc_id,\n    );\n    let sort_value_opt = partial_hit_ref\n        .sort_value\n        .as_mut()\n        .and_then(|sort_field| sort_field.sort_value.as_mut());\n    if let Some(sort_by_value) = sort_value_opt {\n        if let Some(output_datetime_format) = &sort_field_1_datetime_format_opt {\n            convert_sort_datetime_value(sort_by_value, *output_datetime_format)?;\n        }\n    }\n    let sort_value_2_opt = partial_hit_ref\n        .sort_value2\n        .as_mut()\n        .and_then(|sort_field| sort_field.sort_value.as_mut());\n    if let Some(sort_by_value) = sort_value_2_opt {\n        if let Some(output_datetime_format) = &sort_field_2_datetime_format_opt {\n            convert_sort_datetime_value(sort_by_value, *output_datetime_format)?;\n        }\n    }\n    let position = *hit_order.get(&key).expect(\"hit order must be present\");\n    let index_id = split_id_to_index_id_map\n        .get(&partial_hit_ref.split_id)\n        .map(|split_id| split_id.to_string())\n        .unwrap_or_default();\n\n    Result::<(usize, Hit), SearchError>::Ok((\n        position,\n        Hit {\n            json: leaf_hit.leaf_json,\n            partial_hit: leaf_hit.partial_hit,\n            snippet: leaf_hit.leaf_snippet_json,\n            index_id,\n        },\n    ))\n}\n\nfn get_sort_field_datetime_format(\n    sort_field: Option<&SortField>,\n) -> crate::Result<Option<SortDatetimeFormat>> {\n    if let Some(sort_field) = sort_field {\n        if let Some(sort_field_datetime_format_int) = &sort_field.sort_datetime_format {\n            let sort_field_datetime_format =\n                SortDatetimeFormat::from_i32(*sort_field_datetime_format_int)\n                    .context(\"invalid sort datetime format\")?;\n            return Ok(Some(sort_field_datetime_format));\n        }\n    }\n    Ok(None)\n}\n\n/// Performs a distributed search.\n/// 1. Sends leaf request over gRPC to multiple leaf nodes.\n/// 2. Merges the search results.\n/// 3. Sends fetch docs requests to multiple leaf nodes.\n/// 4. Builds the response with docs and returns.\n#[instrument(skip_all, fields(num_splits=%split_metadatas.len()))]\nasync fn root_search_aux(\n    searcher_context: &SearcherContext,\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    search_request: SearchRequest,\n    split_metadatas: Vec<SplitMetadata>,\n    cluster_client: &ClusterClient,\n) -> crate::Result<SearchResponse> {\n    debug!(split_metadatas = ?PrettySample::new(&split_metadatas, 5));\n    let (first_phase_result, scroll_key_and_start_offset_opt): (\n        LeafSearchResponse,\n        Option<ScrollKeyAndStartOffset>,\n    ) = search_partial_hits_phase_with_scroll(\n        searcher_context,\n        indexes_metas_for_leaf_search,\n        search_request.clone(),\n        &split_metadatas[..],\n        cluster_client,\n    )\n    .await?;\n\n    let hits = fetch_docs_phase(\n        indexes_metas_for_leaf_search,\n        &first_phase_result.partial_hits,\n        &split_metadatas[..],\n        &search_request,\n        cluster_client,\n    )\n    .await?;\n\n    let mut aggregation_result_json_opt = finalize_aggregation_if_any(\n        &search_request,\n        first_phase_result.intermediate_aggregation_result,\n        searcher_context,\n    )?;\n    // In case there is no index, we don't want the response to contain any aggregation structure\n    if indexes_metas_for_leaf_search.is_empty() {\n        aggregation_result_json_opt = None;\n    }\n\n    Ok(SearchResponse {\n        aggregation: aggregation_result_json_opt,\n        num_hits: first_phase_result.num_hits,\n        hits,\n        elapsed_time_micros: 0u64,\n        errors: Vec::new(),\n        scroll_id: scroll_key_and_start_offset_opt\n            .as_ref()\n            .map(ToString::to_string),\n    })\n}\n\nfn finalize_aggregation(\n    intermediate_aggregation_result_bytes_opt: Option<Vec<u8>>,\n    aggregations: QuickwitAggregations,\n    searcher_context: &SearcherContext,\n) -> crate::Result<Option<String>> {\n    let merge_aggregation_result = match aggregations {\n        QuickwitAggregations::FindTraceIdsAggregation(_) => {\n            let Some(intermediate_aggregation_result_bytes) =\n                intermediate_aggregation_result_bytes_opt\n            else {\n                return Ok(None);\n            };\n            // The merge collector has already merged the intermediate results.\n            let aggs: Vec<Span> = postcard::from_bytes(&intermediate_aggregation_result_bytes)?;\n            serde_json::to_string(&aggs)?\n        }\n        QuickwitAggregations::TantivyAggregations(aggregations) => {\n            let intermediate_aggregation_results =\n                if let Some(intermediate_aggregation_result_bytes) =\n                    intermediate_aggregation_result_bytes_opt\n                {\n                    let intermediate_aggregation_results: IntermediateAggregationResults =\n                        postcard::from_bytes(&intermediate_aggregation_result_bytes)?;\n                    intermediate_aggregation_results\n                } else {\n                    // Default, to return correct structure\n                    Default::default()\n                };\n            let final_aggregation_results: AggregationResults = intermediate_aggregation_results\n                .into_final_result(aggregations, &searcher_context.get_aggregation_limits())?;\n            serde_json::to_string(&final_aggregation_results)?\n        }\n    };\n    Ok(Some(merge_aggregation_result))\n}\n\nfn finalize_aggregation_if_any(\n    search_request: &SearchRequest,\n    intermediate_aggregation_result_bytes_opt: Option<Vec<u8>>,\n    searcher_context: &SearcherContext,\n) -> crate::Result<Option<String>> {\n    let Some(aggregations_json) = search_request.aggregation_request.as_ref() else {\n        return Ok(None);\n    };\n    let aggregations: QuickwitAggregations = serde_json::from_str(aggregations_json)?;\n    let aggregation_result_json = finalize_aggregation(\n        intermediate_aggregation_result_bytes_opt,\n        aggregations,\n        searcher_context,\n    )?;\n    Ok(aggregation_result_json)\n}\n\n/// Checks that all of the index researched as found.\n///\n/// An index pattern (= containing a wildcard) not matching is not an error.\n/// A specific index id however must be found.\n///\n/// We put this check here and not in the metastore to make sure the logic is independent\n/// of the metastore implementation, and some different use cases could require different\n/// behaviors. This specification was principally motivated by #4042.\npub fn check_all_index_metadata_found(\n    index_metadatas: &[IndexMetadata],\n    index_id_patterns: &[String],\n) -> crate::Result<()> {\n    let mut index_ids: HashSet<&str> = index_id_patterns\n        .iter()\n        .map(|index_ptn| index_ptn.as_str())\n        .filter(|index_ptn| !index_ptn.contains('*') && !index_ptn.starts_with('-'))\n        .collect();\n\n    if index_ids.is_empty() {\n        // All of the patterns are wildcard patterns.\n        return Ok(());\n    }\n\n    for index_metadata in index_metadatas {\n        index_ids.remove(index_metadata.index_uid.index_id.as_str());\n    }\n\n    if !index_ids.is_empty() {\n        let missing_index_ids = index_ids\n            .into_iter()\n            .map(|missing_index_id| missing_index_id.to_string())\n            .collect();\n        return Err(SearchError::IndexesNotFound {\n            index_ids: missing_index_ids,\n        });\n    }\n\n    Ok(())\n}\n\n/// This function takes in the index metadatas and lists the relevant splits for the search request.\nasync fn refine_and_list_matches(\n    metastore: &mut MetastoreServiceClient,\n    search_request: &mut SearchRequest,\n    indexes_metadata: Vec<IndexMetadata>,\n    query_ast_resolved: QueryAst,\n    sort_fields_is_datetime: HashMap<String, bool>,\n    timestamp_field_opt: Option<String>,\n) -> crate::Result<Vec<SplitMetadata>> {\n    let index_uids = indexes_metadata\n        .iter()\n        .map(|index_metadata| index_metadata.index_uid.clone())\n        .collect_vec();\n    search_request.query_ast = serde_json::to_string(&query_ast_resolved)?;\n\n    // convert search_after datetime values from input datetime format to nanos.\n    convert_search_after_datetime_values(search_request, &sort_fields_is_datetime)?;\n\n    // update_search_after_datetime_in_nanos(&mut search_request)?;\n    if let Some(timestamp_field) = &timestamp_field_opt {\n        refine_start_end_timestamp_from_ast(\n            &query_ast_resolved,\n            timestamp_field,\n            &mut search_request.start_timestamp,\n            &mut search_request.end_timestamp,\n        );\n    }\n    let tag_filter_ast = extract_tags_from_query(query_ast_resolved);\n\n    // TODO if search after is set, we sort by timestamp and we don't want to count all results,\n    // we can refine more here. Same if we sort by _shard_doc\n    let split_metadatas: Vec<SplitMetadata> = list_relevant_splits(\n        index_uids,\n        search_request.start_timestamp,\n        search_request.end_timestamp,\n        tag_filter_ast,\n        metastore,\n    )\n    .await?;\n    Ok(split_metadatas)\n}\n\n/// Performs a distributed search.\n/// 1. Sends leaf request over gRPC to multiple leaf nodes.\n/// 2. Merges the search results.\n/// 3. Sends fetch docs requests to multiple leaf nodes.\n/// 4. Builds the response with docs and returns.\n#[instrument(skip_all)]\npub async fn root_search(\n    // contains split footer cache\n    searcher_context: &SearcherContext,\n    // search request will contains timestamps and tags to prune splits\n    mut search_request: SearchRequest,\n    // metastore client\n    mut metastore: MetastoreServiceClient,\n    // cluster client to communicate between nodes\n    cluster_client: &ClusterClient,\n) -> crate::Result<SearchResponse> {\n    info!(searcher_context = ?searcher_context, search_request = ?search_request);\n    let start_instant = tokio::time::Instant::now();\n    let list_indexes_metadatas_request = ListIndexesMetadataRequest {\n        index_id_patterns: search_request.index_id_patterns.clone(),\n    };\n    let indexes_metadata: Vec<IndexMetadata> = metastore\n        // codegen will generate the correct method call\n        // this will fetch the index metadata from the metastore\n        .list_indexes_metadata(list_indexes_metadatas_request)\n        .await?\n        .deserialize_indexes_metadata()\n        .await?;\n\n    check_all_index_metadata_found(&indexes_metadata[..], &search_request.index_id_patterns[..])?;\n\n    if indexes_metadata.is_empty() {\n        // We go through root_search_aux instead of directly\n        // returning an empty response to make sure we generate\n        // a (pretty useless) scroll id if requested.\n        let mut search_response = root_search_aux(\n            searcher_context,\n            &HashMap::default(),\n            search_request,\n            Vec::new(),\n            cluster_client,\n        )\n        .await?;\n        search_response.elapsed_time_micros = start_instant.elapsed().as_micros() as u64;\n        return Ok(search_response);\n    }\n\n    let request_metadata = validate_request_and_build_metadata(&indexes_metadata, &search_request)?;\n    let split_metadatas = refine_and_list_matches(\n        &mut metastore,\n        &mut search_request,\n        indexes_metadata,\n        request_metadata.query_ast_resolved,\n        request_metadata.sort_fields_is_datetime,\n        request_metadata.timestamp_field_opt,\n    )\n    .await?;\n\n    let mut search_response = root_search_aux(\n        searcher_context,\n        &request_metadata.indexes_meta_for_leaf_search,\n        search_request,\n        split_metadatas,\n        cluster_client,\n    )\n    .await?;\n\n    search_response.elapsed_time_micros = start_instant.elapsed().as_micros() as u64;\n    Ok(search_response)\n}\n\n/// Returns details on how a query would be executed\npub async fn search_plan(\n    mut search_request: SearchRequest,\n    mut metastore: MetastoreServiceClient,\n) -> crate::Result<SearchPlanResponse> {\n    let list_indexes_metadatas_request = ListIndexesMetadataRequest {\n        index_id_patterns: search_request.index_id_patterns.clone(),\n    };\n    let indexes_metadata: Vec<IndexMetadata> = metastore\n        .list_indexes_metadata(list_indexes_metadatas_request)\n        .await?\n        .deserialize_indexes_metadata()\n        .await?;\n\n    check_all_index_metadata_found(&indexes_metadata[..], &search_request.index_id_patterns[..])?;\n    if indexes_metadata.is_empty() {\n        return Ok(SearchPlanResponse {\n            result: serde_json::to_string(&SearchPlanResponseRest {\n                quickwit_ast: QueryAst::MatchAll,\n                tantivy_ast: String::new(),\n                searched_splits: Vec::new(),\n                storage_requests: StorageRequestCount::default(),\n            })?,\n        });\n    }\n    let doc_mapper = build_doc_mapper(\n        &indexes_metadata[0].index_config.doc_mapping,\n        &indexes_metadata[0].index_config.search_settings,\n    )\n    .map_err(|err| SearchError::Internal(format!(\"failed to build doc mapper. cause: {err}\")))?;\n\n    let request_metadata = validate_request_and_build_metadata(&indexes_metadata, &search_request)?;\n    let split_metadatas = refine_and_list_matches(\n        &mut metastore,\n        &mut search_request,\n        indexes_metadata,\n        request_metadata.query_ast_resolved.clone(),\n        request_metadata.sort_fields_is_datetime,\n        request_metadata.timestamp_field_opt,\n    )\n    .await?;\n\n    let (query, mut warmup_info) = doc_mapper.query(\n        doc_mapper.schema(),\n        &request_metadata.query_ast_resolved,\n        true,\n    )?;\n    let merge_collector = make_merge_collector(&search_request, &Default::default())?;\n    warmup_info.merge(merge_collector.warmup_info());\n    warmup_info.simplify();\n\n    let split_ids = split_metadatas\n        .into_iter()\n        .map(|split| format!(\"{}/{}\", split.index_uid.index_id, split.split_id))\n        .collect();\n    // this is an upper bound, we'd need access to a hotdir for more precise results\n    let fieldnorm_query_count = if warmup_info.field_norms {\n        doc_mapper\n            .schema()\n            .fields()\n            .filter(|(_, entry)| entry.has_fieldnorms())\n            .count()\n    } else {\n        0\n    };\n    let sstable_query_count = warmup_info.term_dict_fields.len()\n        + warmup_info\n            .terms_grouped_by_field\n            .values()\n            .map(|terms: &HashMap<tantivy::Term, bool>| terms.len())\n            .sum::<usize>()\n        + warmup_info\n            .term_ranges_grouped_by_field\n            .values()\n            .map(|terms: &HashMap<_, bool>| terms.len())\n            .sum::<usize>();\n    let position_query_count = warmup_info\n        .terms_grouped_by_field\n        .values()\n        .map(|terms: &HashMap<tantivy::Term, bool>| {\n            terms\n                .values()\n                .filter(|load_position| **load_position)\n                .count()\n        })\n        .sum::<usize>()\n        + warmup_info\n            .term_ranges_grouped_by_field\n            .values()\n            .map(|terms: &HashMap<_, bool>| {\n                terms\n                    .values()\n                    .filter(|load_position| **load_position)\n                    .count()\n            })\n            .sum::<usize>();\n    Ok(SearchPlanResponse {\n        result: serde_json::to_string(&SearchPlanResponseRest {\n            quickwit_ast: request_metadata.query_ast_resolved,\n            tantivy_ast: format!(\"{query:#?}\"),\n            searched_splits: split_ids,\n            storage_requests: StorageRequestCount {\n                footer: 1,\n                fastfield: warmup_info.fast_field_names.len(),\n                fieldnorm: fieldnorm_query_count,\n                sstable: sstable_query_count,\n                posting: sstable_query_count,\n                position: position_query_count,\n            },\n        })?,\n    })\n}\n\n/// Converts search after with datetime format to nanoseconds (representation in tantivy).\n/// If the sort field is a datetime field and no datetime format is set, the default format is\n/// milliseconds.\n/// `sort_fields_are_datetime_opt` must be of the same length as `search_request.sort_fields`.\nfn convert_search_after_datetime_values(\n    search_request: &mut SearchRequest,\n    sort_fields_is_datetime: &HashMap<String, bool>,\n) -> crate::Result<()> {\n    for sort_field in search_request.sort_fields.iter_mut() {\n        if *sort_fields_is_datetime\n            .get(&sort_field.field_name)\n            .unwrap_or(&false)\n            && sort_field.sort_datetime_format.is_none()\n        {\n            sort_field.sort_datetime_format = Some(SortDatetimeFormat::UnixTimestampMillis as i32);\n        }\n    }\n    if let Some(partial_hit) = search_request.search_after.as_mut() {\n        let search_after_values = [\n            partial_hit.sort_value.as_mut(),\n            partial_hit.sort_value2.as_mut(),\n        ];\n        for (sort_field, search_after_value_opt) in\n            search_request.sort_fields.iter().zip(search_after_values)\n        {\n            let Some(search_after_sort_by_value) = search_after_value_opt else {\n                continue;\n            };\n            let Some(search_after_sort_value) = search_after_sort_by_value.sort_value.as_mut()\n            else {\n                continue;\n            };\n            let Some(datetime_format_int) = sort_field.sort_datetime_format else {\n                continue;\n            };\n            let input_datetime_format = SortDatetimeFormat::from_i32(datetime_format_int)\n                .context(\"invalid sort datetime format\")?;\n            convert_sort_datetime_value_into_nanos(search_after_sort_value, input_datetime_format)?;\n        }\n    }\n    Ok(())\n}\n\n/// Convert sort values from input datetime format into nanoseconds.\n/// The conversion is done only for U64 and I64 sort values, an error is returned for other types.\nfn convert_sort_datetime_value_into_nanos(\n    sort_value: &mut SortValue,\n    input_format: SortDatetimeFormat,\n) -> crate::Result<()> {\n    match sort_value {\n        SortValue::U64(value) => match input_format {\n            SortDatetimeFormat::UnixTimestampMillis => {\n                *value = value.checked_mul(1_000_000).ok_or_else(|| {\n                    SearchError::Internal(format!(\n                        \"sort value defined in milliseconds is too large and cannot be converted \\\n                         into nanoseconds: {}\",\n                        value\n                    ))\n                })?;\n            }\n            SortDatetimeFormat::UnixTimestampNanos => {\n                // Nothing to do as the internal format is nanos.\n            }\n        },\n        SortValue::I64(value) => match input_format {\n            SortDatetimeFormat::UnixTimestampMillis => {\n                *value = value.checked_mul(1_000_000).ok_or_else(|| {\n                    SearchError::Internal(format!(\n                        \"sort value defined in milliseconds is too large and cannot be converted \\\n                         into nanoseconds: {}\",\n                        value\n                    ))\n                })?;\n            }\n            SortDatetimeFormat::UnixTimestampNanos => {\n                // Nothing to do as the internal format is nanos.\n            }\n        },\n        _ => {\n            return Err(SearchError::Internal(format!(\n                \"datetime conversion are only support for u64 and i64 sort values, not `{:?}`\",\n                sort_value\n            )));\n        }\n    }\n    Ok(())\n}\n\n/// Convert sort values from nanoseconds to the requested output format.\n/// The conversion is done only for U64 and I64 sort values, an error is returned for other types.\nfn convert_sort_datetime_value(\n    sort_value: &mut SortValue,\n    output_format: SortDatetimeFormat,\n) -> crate::Result<()> {\n    match sort_value {\n        SortValue::U64(value) => match output_format {\n            SortDatetimeFormat::UnixTimestampMillis => {\n                *value /= 1_000_000;\n            }\n            SortDatetimeFormat::UnixTimestampNanos => {\n                // Nothing todo as the internal format is in nanos.\n            }\n        },\n        SortValue::I64(value) => match output_format {\n            SortDatetimeFormat::UnixTimestampMillis => {\n                *value /= 1_000_000;\n            }\n            SortDatetimeFormat::UnixTimestampNanos => {\n                // Nothing todo as the internal format is in nanos.\n            }\n        },\n        _ => {\n            return Err(SearchError::Internal(format!(\n                \"datetime conversion are only support for u64 and i64 sort values, not `{:?}`\",\n                sort_value\n            )));\n        }\n    }\n    Ok(())\n}\n\npub(crate) fn refine_start_end_timestamp_from_ast(\n    query_ast: &QueryAst,\n    timestamp_field: &str,\n    start_timestamp: &mut Option<i64>,\n    end_timestamp: &mut Option<i64>,\n) {\n    let mut timestamp_range_extractor = ExtractTimestampRange {\n        timestamp_field,\n        start_timestamp: *start_timestamp,\n        end_timestamp: *end_timestamp,\n    };\n    timestamp_range_extractor\n        .visit(query_ast)\n        .expect(\"can't fail unwrapping Infallible\");\n    *start_timestamp = timestamp_range_extractor.start_timestamp;\n    *end_timestamp = timestamp_range_extractor.end_timestamp;\n}\n\n/// Boundaries identified as being implied by the QueryAst.\n///\n/// `start_timestamp` is to be interpreted as Inclusive (or Unbounded)\n/// `end_timestamp` is to be interpreted as Exclusive (or Unbounded)\n/// In other word, this is a `[start_timestamp..end_timestamp)` interval.\nstruct ExtractTimestampRange<'a> {\n    timestamp_field: &'a str,\n    start_timestamp: Option<i64>,\n    end_timestamp: Option<i64>,\n}\n\nimpl<'a> ExtractTimestampRange<'a> {\n    fn update_start_timestamp(\n        &mut self,\n        lower_bound: &quickwit_query::JsonLiteral,\n        included: bool,\n    ) {\n        use quickwit_query::InterpretUserInput;\n        let Some(lower_bound) = tantivy::DateTime::interpret_json(lower_bound) else {\n            return;\n        };\n        let mut lower_bound = lower_bound.into_timestamp_secs();\n        if !included {\n            // TODO saturating isn't exactly right, we should replace the RangeQuery with\n            // a match_none, but the visitor doesn't allow mutation.\n            lower_bound = lower_bound.saturating_add(1);\n        }\n        self.start_timestamp = Some(\n            self.start_timestamp\n                .map_or(lower_bound, |current| current.max(lower_bound)),\n        );\n    }\n\n    fn update_end_timestamp(&mut self, upper_bound: &quickwit_query::JsonLiteral, included: bool) {\n        use quickwit_query::InterpretUserInput;\n        let Some(upper_bound_timestamp) = tantivy::DateTime::interpret_json(upper_bound) else {\n            return;\n        };\n        let mut upper_bound = upper_bound_timestamp.into_timestamp_secs();\n        let round_up = (upper_bound_timestamp.into_timestamp_nanos() % 1_000_000_000) != 0;\n        if included || round_up {\n            // TODO saturating isn't exactly right, we should replace the RangeQuery with\n            // a match_none, but the visitor doesn't allow mutation.\n            upper_bound = upper_bound.saturating_add(1);\n        }\n        self.end_timestamp = Some(\n            self.end_timestamp\n                .map_or(upper_bound, |current| current.min(upper_bound)),\n        );\n    }\n}\n\nimpl<'a, 'b> QueryAstVisitor<'b> for ExtractTimestampRange<'a> {\n    type Err = std::convert::Infallible;\n\n    fn visit_bool(&mut self, bool_query: &'b BoolQuery) -> Result<(), Self::Err> {\n        // we only want to visit sub-queries which are strict (positive) requirements\n        for ast in bool_query.must.iter().chain(bool_query.filter.iter()) {\n            self.visit(ast)?;\n        }\n        Ok(())\n    }\n\n    fn visit_range(&mut self, range_query: &'b RangeQuery) -> Result<(), Self::Err> {\n        use std::ops::Bound;\n\n        if range_query.field == self.timestamp_field {\n            match &range_query.lower_bound {\n                Bound::Included(lower_bound) => self.update_start_timestamp(lower_bound, true),\n                Bound::Excluded(lower_bound) => self.update_start_timestamp(lower_bound, false),\n                Bound::Unbounded => (),\n            }\n            match &range_query.upper_bound {\n                Bound::Included(upper_bound) => self.update_end_timestamp(upper_bound, true),\n                Bound::Excluded(upper_bound) => self.update_end_timestamp(upper_bound, false),\n                Bound::Unbounded => (),\n            }\n        }\n        Ok(())\n    }\n\n    // if we visit a term, limit the range to DATE..=DATE\n    fn visit_term(&mut self, term_query: &'b TermQuery) -> Result<(), Self::Err> {\n        if term_query.field == self.timestamp_field {\n            // TODO when fixing #3323, this may need to be modified to support numbers too\n            let json_term = quickwit_query::JsonLiteral::String(term_query.value.clone());\n            self.update_start_timestamp(&json_term, true);\n            self.update_end_timestamp(&json_term, true);\n        }\n        Ok(())\n    }\n\n    // if we visit a termset, limit the range to LOWEST..=HIGHEST\n    fn visit_term_set(&mut self, term_query: &'b TermSetQuery) -> Result<(), Self::Err> {\n        if let Some(term_set) = term_query.terms_per_field.get(self.timestamp_field) {\n            // rfc3339 is lexicographically ordered if YEAR <= 9999, so we can use string\n            // ordering to get the start and end quickly.\n            if let Some(first) = term_set.first() {\n                let json_term = quickwit_query::JsonLiteral::String(first.clone());\n                self.update_start_timestamp(&json_term, true);\n            }\n            if let Some(last) = term_set.last() {\n                let json_term = quickwit_query::JsonLiteral::String(last.clone());\n                self.update_end_timestamp(&json_term, true);\n            }\n        }\n        Ok(())\n    }\n}\n\nasync fn assign_client_fetch_docs_jobs(\n    partial_hits: &[PartialHit],\n    split_metadatas: &[SplitMetadata],\n    client_pool: &SearchJobPlacer,\n) -> crate::Result<impl Iterator<Item = (SearchServiceClient, Vec<FetchDocsJob>)>> {\n    let index_uids_and_split_offsets_map: HashMap<String, (IndexUid, SplitIdAndFooterOffsets)> =\n        split_metadatas\n            .iter()\n            .map(|metadata| {\n                (\n                    metadata.split_id().to_string(),\n                    (\n                        metadata.index_uid.clone(),\n                        extract_split_and_footer_offsets(metadata),\n                    ),\n                )\n            })\n            .collect();\n\n    // Group the partial hits per split\n    let mut partial_hits_map: HashMap<String, Vec<PartialHit>> = HashMap::new();\n    for partial_hit in partial_hits.iter() {\n        partial_hits_map\n            .entry(partial_hit.split_id.clone())\n            .or_default()\n            .push(partial_hit.clone());\n    }\n\n    let mut fetch_docs_req_jobs: Vec<FetchDocsJob> = Vec::new();\n    for (split_id, partial_hits) in partial_hits_map {\n        let (index_uid, offsets) = index_uids_and_split_offsets_map\n            .get(&split_id)\n            .ok_or_else(|| {\n                crate::SearchError::Internal(format!(\n                    \"received partial hit from an unknown split {split_id}\"\n                ))\n            })?\n            .clone();\n        let fetch_docs_job = FetchDocsJob {\n            index_uid: index_uid.clone(),\n            offsets,\n            partial_hits,\n        };\n        fetch_docs_req_jobs.push(fetch_docs_job);\n    }\n\n    let assigned_jobs = client_pool\n        .assign_jobs(fetch_docs_req_jobs, &HashSet::new())\n        .await?;\n\n    Ok(assigned_jobs)\n}\n\n// Measure the cost associated to searching in a given split metadata.\nfn compute_split_cost(split_metadata: &SplitMetadata) -> usize {\n    // TODO this formula could be tuned a lot more. The general idea is that there is a fixed\n    // cost to searching a split, plus a somewhat-linear cost depending on the size of the split\n    5 + split_metadata.num_docs / 100_000\n}\n\n/// Builds a LeafSearchRequest to one node, from a list of [`SearchJob`].\npub fn jobs_to_leaf_request(\n    request: &SearchRequest,\n    search_indexes_metadatas: &IndexesMetasForLeafSearch,\n    jobs: Vec<SearchJob>,\n) -> crate::Result<LeafSearchRequest> {\n    let mut search_request_for_leaf = request.clone();\n    search_request_for_leaf.start_offset = 0;\n    search_request_for_leaf.max_hits += request.start_offset;\n\n    let mut leaf_search_request = LeafSearchRequest {\n        search_request: Some(search_request_for_leaf),\n        leaf_requests: Vec::new(),\n        doc_mappers: Vec::new(),\n        index_uris: Vec::new(),\n    };\n\n    let mut added_doc_mappers: HashMap<&str, u32> = HashMap::new();\n    // Group jobs by index uid, as the split offsets are relative to the index.\n    group_jobs_by_index_id(jobs, |job_group| {\n        let index_uid = &job_group[0].index_uid;\n        let search_index_meta = search_indexes_metadatas.get(index_uid).ok_or_else(|| {\n            SearchError::Internal(format!(\n                \"received job for an unknown index {index_uid}. it should never happen\"\n            ))\n        })?;\n        let doc_mapper_ord = *added_doc_mappers\n            .entry(&search_index_meta.doc_mapper_str)\n            .or_insert_with(|| {\n                let ord = leaf_search_request.doc_mappers.len();\n                leaf_search_request\n                    .doc_mappers\n                    .push(search_index_meta.doc_mapper_str.to_string());\n                ord as u32\n            });\n        let index_uri_ord = leaf_search_request.index_uris.len() as u32;\n        leaf_search_request\n            .index_uris\n            .push(search_index_meta.index_uri.to_string());\n\n        let leaf_search_request_ref = LeafRequestRef {\n            split_offsets: job_group.into_iter().map(|job| job.offsets).collect(),\n            doc_mapper_ord,\n            index_uri_ord,\n        };\n        leaf_search_request\n            .leaf_requests\n            .push(leaf_search_request_ref);\n        Ok(())\n    })?;\n    Ok(leaf_search_request)\n}\n\n/// Builds a list of [`FetchDocsRequest`], one per index, from a list of [`FetchDocsJob`].\npub fn jobs_to_fetch_docs_requests(\n    snippet_request_opt: Option<SnippetRequest>,\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    jobs: Vec<FetchDocsJob>,\n) -> crate::Result<Vec<FetchDocsRequest>> {\n    let mut fetch_docs_requests = Vec::new();\n    // Group jobs by index uid.\n    group_by(\n        jobs,\n        |job| &job.index_uid,\n        |fetch_docs_jobs| {\n            let index_uid = &fetch_docs_jobs[0].index_uid;\n\n            let index_meta = indexes_metas_for_leaf_search\n                .get(index_uid)\n                .ok_or_else(|| {\n                    SearchError::Internal(format!(\n                        \"received search job for an unknown index {index_uid}\"\n                    ))\n                })?;\n            let partial_hits: Vec<PartialHit> = fetch_docs_jobs\n                .iter()\n                .flat_map(|fetch_doc_job| fetch_doc_job.partial_hits.iter().cloned())\n                .collect();\n            let split_offsets: Vec<SplitIdAndFooterOffsets> = fetch_docs_jobs\n                .into_iter()\n                .map(|fetch_doc_job| fetch_doc_job.into())\n                .collect();\n            let fetch_docs_req = FetchDocsRequest {\n                partial_hits,\n                split_offsets,\n                index_uri: index_meta.index_uri.to_string(),\n                snippet_request: snippet_request_opt.clone(),\n                doc_mapper: index_meta.doc_mapper_str.clone(),\n            };\n            fetch_docs_requests.push(fetch_docs_req);\n\n            Ok(())\n        },\n    )?;\n    Ok(fetch_docs_requests)\n}\n\n#[cfg(test)]\nmod tests {\n    use std::ops::Range;\n    use std::str::FromStr;\n    use std::sync::{Arc, RwLock};\n\n    use quickwit_common::shared_consts::SCROLL_BATCH_LEN;\n    use quickwit_common::ServiceStream;\n    use quickwit_config::{DocMapping, IndexConfig, IndexingSettings, SearchSettings};\n    use quickwit_indexing::MockSplitBuilder;\n    use quickwit_metastore::{IndexMetadata, ListSplitsRequestExt, ListSplitsResponseExt};\n    use quickwit_proto::metastore::{\n        ListIndexesMetadataResponse, ListSplitsResponse, MockMetastoreService,\n    };\n    use quickwit_proto::search::{\n        ScrollRequest, SortByValue, SortOrder, SortValue, SplitSearchError,\n    };\n    use quickwit_query::query_ast::{qast_helper, qast_json_helper, query_ast_from_user_text};\n    use tantivy::schema::{FAST, STORED, TEXT};\n\n    use super::*;\n    use crate::{searcher_pool_for_test, MockSearchService};\n\n    #[track_caller]\n    fn check_snippet_fields_validation(snippet_fields: &[String]) -> anyhow::Result<()> {\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_text_field(\"title\", TEXT);\n        schema_builder.add_text_field(\"desc\", TEXT | STORED);\n        schema_builder.add_ip_addr_field(\"ip\", FAST | STORED);\n        let schema = schema_builder.build();\n        validate_requested_snippet_fields(&schema, snippet_fields)\n    }\n\n    #[test]\n    fn test_validate_requested_snippet_fields() {\n        check_snippet_fields_validation(&[\"desc\".to_string()]).unwrap();\n        let field_not_stored_err =\n            check_snippet_fields_validation(&[\"title\".to_string()]).unwrap_err();\n        assert_eq!(\n            field_not_stored_err.to_string(),\n            \"the snippet field `title` must be stored\"\n        );\n        let field_doesnotexist_err =\n            check_snippet_fields_validation(&[\"doesnotexist\".to_string()]).unwrap_err();\n        assert_eq!(\n            field_doesnotexist_err.to_string(),\n            \"The field does not exist: 'doesnotexist'\"\n        );\n        let field_is_not_text_err =\n            check_snippet_fields_validation(&[\"ip\".to_string()]).unwrap_err();\n        assert_eq!(\n            field_is_not_text_err.to_string(),\n            \"the snippet field `ip` must be of type `Str`, got `IpAddr`\"\n        );\n    }\n\n    #[test]\n    fn test_get_sort_by_field_entry() {\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_text_field(\"title\", TEXT);\n        schema_builder.add_text_field(\"desc\", TEXT | STORED);\n        schema_builder.add_u64_field(\"timestamp\", FAST | STORED);\n        let schema = schema_builder.build();\n        get_sort_by_field_entry(\"timestamp\", &schema)\n            .unwrap()\n            .unwrap();\n        let sort_by_field_entry_err = get_sort_by_field_entry(\"doesnotexist\", &schema).unwrap_err();\n        assert_eq!(\n            sort_by_field_entry_err.to_string(),\n            \"Invalid argument: unknown field used in `sort by`: doesnotexist\"\n        );\n        for sort_field_name in &[\"_doc\", \"_score\", \"_shard_doc\"] {\n            assert!(get_sort_by_field_entry(sort_field_name, &schema)\n                .unwrap()\n                .is_none());\n        }\n    }\n\n    fn index_metadata_for_multi_indexes_test(index_id: &str, index_uri: &str) -> IndexMetadata {\n        let index_uri = Uri::from_str(index_uri).unwrap();\n        let doc_mapping_json = r#\"{\n            \"mode\": \"lenient\",\n            \"field_mappings\": [\n                {\n                    \"name\": \"timestamp\",\n                    \"type\": \"datetime\",\n                    \"fast\": true\n                },\n                {\n                    \"name\": \"body\",\n                    \"type\": \"text\",\n                    \"stored\": true\n                }\n            ],\n            \"timestamp_field\": \"timestamp\",\n            \"store_source\": true\n        }\"#;\n        let doc_mapping = serde_json::from_str(doc_mapping_json).unwrap();\n        let indexing_settings = IndexingSettings::default();\n        let search_settings = SearchSettings {\n            default_search_fields: vec![\"body\".to_string()],\n        };\n        IndexMetadata::new(IndexConfig {\n            index_id: index_id.to_string(),\n            index_uri,\n            doc_mapping,\n            indexing_settings,\n            search_settings,\n            retention_policy_opt: Default::default(),\n        })\n    }\n\n    #[test]\n    fn test_validate_request_and_build_metadatas_ok() {\n        let request_query_ast = qast_helper(\"body:test\", &[]);\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: serde_json::to_string(&request_query_ast).unwrap(),\n            max_hits: 10,\n            start_offset: 10,\n            sort_fields: vec![\n                SortField {\n                    field_name: \"timestamp\".to_string(),\n                    sort_order: SortOrder::Desc as i32,\n                    sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n                },\n                SortField {\n                    field_name: \"_doc\".to_string(),\n                    sort_order: SortOrder::Asc as i32,\n                    sort_datetime_format: None,\n                },\n            ],\n            ..Default::default()\n        };\n        let index_metadata = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_metadata_with_other_config =\n            index_metadata_for_multi_indexes_test(\"test-index-2\", \"ram:///test-index-2\");\n        let mut index_metadata_no_timestamp =\n            IndexMetadata::for_test(\"test-index-3\", \"ram:///test-index-3\");\n        index_metadata_no_timestamp\n            .index_config\n            .doc_mapping\n            .timestamp_field = None;\n        let request_metadata = validate_request_and_build_metadata(\n            &[\n                index_metadata,\n                index_metadata_with_other_config,\n                index_metadata_no_timestamp,\n            ],\n            &search_request,\n        )\n        .unwrap();\n        assert_eq!(\n            request_metadata.timestamp_field_opt,\n            Some(\"timestamp\".to_string())\n        );\n        assert_eq!(request_metadata.query_ast_resolved, request_query_ast);\n        assert_eq!(request_metadata.indexes_meta_for_leaf_search.len(), 3);\n        assert_eq!(request_metadata.sort_fields_is_datetime.len(), 2);\n        assert_eq!(\n            request_metadata.sort_fields_is_datetime.get(\"timestamp\"),\n            Some(&true)\n        );\n        assert_eq!(\n            request_metadata.sort_fields_is_datetime.get(\"_doc\"),\n            Some(&false)\n        );\n    }\n\n    #[test]\n    fn test_validate_request_and_build_metadatas_fail_with_different_timestamps() {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            start_offset: 10,\n            ..Default::default()\n        };\n        let index_metadata_1 = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let mut index_metadata_2 = IndexMetadata::for_test(\"test-index-2\", \"ram:///test-index-2\");\n        let doc_mapping_json_2 = r#\"{\n            \"mode\": \"lenient\",\n            \"field_mappings\": [\n                {\n                    \"name\": \"timestamp-2\",\n                    \"type\": \"datetime\",\n                    \"fast\": true\n                },\n                {\n                    \"name\": \"body\",\n                    \"type\": \"text\"\n                }\n            ],\n            \"timestamp_field\": \"timestamp-2\",\n            \"store_source\": true\n        }\"#;\n        let doc_mapping_2: DocMapping = serde_json::from_str(doc_mapping_json_2).unwrap();\n        index_metadata_2.index_config.doc_mapping = doc_mapping_2;\n        index_metadata_2\n            .index_config\n            .search_settings\n            .default_search_fields = Vec::new();\n        let timestamp_field_different = validate_request_and_build_metadata(\n            &[index_metadata_1, index_metadata_2],\n            &search_request,\n        )\n        .unwrap_err();\n        assert_eq!(\n            timestamp_field_different.to_string(),\n            \"the timestamp field (if present) must be the same for all indexes\"\n        );\n    }\n\n    #[test]\n    fn test_validate_request_and_build_metadatas_fail_with_different_resolved_qast() {\n        let qast = query_ast_from_user_text(\"test\", None);\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: serde_json::to_string(&qast).unwrap(),\n            max_hits: 10,\n            start_offset: 10,\n            ..Default::default()\n        };\n        let index_metadata_1 = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let mut index_metadata_2 = IndexMetadata::for_test(\"test-index-2\", \"ram:///test-index-2\");\n        index_metadata_2\n            .index_config\n            .search_settings\n            .default_search_fields = vec![\"owner\".to_string()];\n        let timestamp_field_different = validate_request_and_build_metadata(\n            &[index_metadata_1, index_metadata_2],\n            &search_request,\n        )\n        .unwrap_err();\n        assert_eq!(\n            timestamp_field_different.to_string(),\n            \"resolved query ASTs must be the same across indexes. resolving queries with \\\n             different default fields are different between indexes is not supported\"\n        );\n    }\n\n    fn index_metadata_for_multi_indexes_test_with_incompatible_sort_type(\n        index_id: &str,\n        index_uri: &str,\n    ) -> IndexMetadata {\n        let index_uri = Uri::from_str(index_uri).unwrap();\n        let doc_mapping_json = r#\"{\n            \"mode\": \"lenient\",\n            \"field_mappings\": [\n                {\n                    \"name\": \"timestamp\",\n                    \"type\": \"datetime\",\n                    \"fast\": true\n                },\n                {\n                    \"name\": \"body\",\n                    \"type\": \"text\",\n                    \"stored\": true\n                },\n                {\n                    \"name\": \"response_date\",\n                    \"type\": \"i64\",\n                    \"stored\": true,\n                    \"fast\": true\n                }\n            ],\n            \"timestamp_field\": \"timestamp\",\n            \"store_source\": true\n        }\"#;\n        let doc_mapping = serde_json::from_str(doc_mapping_json).unwrap();\n        let indexing_settings = IndexingSettings::default();\n        let search_settings = SearchSettings {\n            default_search_fields: vec![\"body\".to_string()],\n        };\n        IndexMetadata::new(IndexConfig {\n            index_id: index_id.to_string(),\n            index_uri,\n            doc_mapping,\n            indexing_settings,\n            search_settings,\n            retention_policy_opt: Default::default(),\n        })\n    }\n\n    #[test]\n    fn test_validate_request_and_build_metadatas_fail_with_incompatible_sort_field_types() {\n        let request_query_ast = qast_helper(\"body:test\", &[]);\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: serde_json::to_string(&request_query_ast).unwrap(),\n            max_hits: 10,\n            start_offset: 10,\n            sort_fields: vec![SortField {\n                field_name: \"response_date\".to_string(),\n                sort_order: SortOrder::Desc as i32,\n                sort_datetime_format: None,\n            }],\n            ..Default::default()\n        };\n        let index_metadata = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_metadata_with_other_config =\n            index_metadata_for_multi_indexes_test_with_incompatible_sort_type(\n                \"test-index-2\",\n                \"ram:///test-index-2\",\n            );\n        let search_error = validate_request_and_build_metadata(\n            &[index_metadata, index_metadata_with_other_config],\n            &search_request,\n        )\n        .unwrap_err();\n        assert_eq!(\n            search_error.to_string(),\n            \"sort datetime field `response_date` must be of type datetime on all indexes\"\n        );\n    }\n\n    #[test]\n    fn test_convert_sort_datetime_value() {\n        let mut sort_value = SortValue::U64(1617000000000000000);\n        convert_sort_datetime_value(&mut sort_value, SortDatetimeFormat::UnixTimestampMillis)\n            .unwrap();\n        assert_eq!(sort_value, SortValue::U64(1617000000000));\n        let mut sort_value = SortValue::I64(1617000000000000000);\n        convert_sort_datetime_value(&mut sort_value, SortDatetimeFormat::UnixTimestampMillis)\n            .unwrap();\n        assert_eq!(sort_value, SortValue::I64(1617000000000));\n\n        // conversion with float values should fail.\n        let mut sort_value = SortValue::F64(1617000000000000000.0);\n        let error =\n            convert_sort_datetime_value(&mut sort_value, SortDatetimeFormat::UnixTimestampMillis)\n                .unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"internal error: `datetime conversion are only support for u64 and i64 sort values, \\\n             not `F64(1.617e18)``\"\n        );\n    }\n\n    #[test]\n    fn test_convert_sort_datetime_value_into_nanos() {\n        let mut sort_value = SortValue::U64(1617000000000);\n        convert_sort_datetime_value_into_nanos(\n            &mut sort_value,\n            SortDatetimeFormat::UnixTimestampMillis,\n        )\n        .unwrap();\n        assert_eq!(sort_value, SortValue::U64(1617000000000000000));\n        let mut sort_value = SortValue::I64(1617000000000);\n        convert_sort_datetime_value_into_nanos(\n            &mut sort_value,\n            SortDatetimeFormat::UnixTimestampMillis,\n        )\n        .unwrap();\n        assert_eq!(sort_value, SortValue::I64(1617000000000000000));\n\n        // conversion with a too large millisecond value should fail.\n        let mut sort_value = SortValue::I64(1617000000000000);\n        let error = convert_sort_datetime_value_into_nanos(\n            &mut sort_value,\n            SortDatetimeFormat::UnixTimestampMillis,\n        )\n        .unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"internal error: `sort value defined in milliseconds is too large and cannot be \\\n             converted into nanoseconds: 1617000000000000`\"\n        );\n        // conversion with float values should fail.\n        let mut sort_value = SortValue::F64(1617000000000000.0);\n        let error = convert_sort_datetime_value_into_nanos(\n            &mut sort_value,\n            SortDatetimeFormat::UnixTimestampMillis,\n        )\n        .unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"internal error: `datetime conversion are only support for u64 and i64 sort values, \\\n             not `F64(1617000000000000.0)``\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_field_types_with_doc_and_shard_doc() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"_doc\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n            SortField {\n                field_name: \"_shard_doc\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_date_field(\"timestamp\", FAST);\n        schema_builder.add_u64_field(\"id\", FAST);\n        let schema = schema_builder.build();\n        let mut sort_field_are_datetime = HashMap::new();\n        validate_sort_field_types(&schema, &sort_fields, &mut sort_field_are_datetime).unwrap();\n        assert_eq!(sort_field_are_datetime.get(\"_doc\"), Some(&false));\n        assert_eq!(sort_field_are_datetime.get(\"_shard_doc\"), Some(&false));\n    }\n\n    #[test]\n    fn test_validate_sort_field_types_valid() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_date_field(\"timestamp\", FAST);\n        schema_builder.add_u64_field(\"id\", FAST);\n        let schema = schema_builder.build();\n        let mut sort_field_are_datetime = HashMap::new();\n        validate_sort_field_types(&schema, &sort_fields, &mut sort_field_are_datetime).unwrap();\n        assert_eq!(sort_field_are_datetime.get(\"timestamp\"), Some(&true));\n        assert_eq!(sort_field_are_datetime.get(\"id\"), Some(&false));\n    }\n\n    #[test]\n    fn test_validate_sort_field_types_with_inconsistent_datetime_type() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_date_field(\"timestamp\", FAST);\n        schema_builder.add_u64_field(\"id\", FAST);\n        let schema = schema_builder.build();\n        {\n            let mut sort_field_are_datetime = HashMap::new();\n            sort_field_are_datetime.insert(\"timestamp\".to_string(), false);\n            sort_field_are_datetime.insert(\"id\".to_string(), false);\n            let error =\n                validate_sort_field_types(&schema, &sort_fields, &mut sort_field_are_datetime)\n                    .unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"sort datetime field `timestamp` must be of type datetime on all indexes\"\n            );\n        }\n        {\n            let mut sort_field_are_datetime = HashMap::new();\n            sort_field_are_datetime.insert(\"id\".to_string(), true);\n            let error =\n                validate_sort_field_types(&schema, &sort_fields, &mut sort_field_are_datetime)\n                    .unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"sort datetime field `id` must be of type datetime on all indexes\"\n            );\n        }\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_with_datetime_format_ok() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        validate_sort_by_fields_and_search_after(&sort_fields, &None).unwrap();\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_ok() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: Some(SortByValue {\n                sort_value: Some(SortValue::U64(2)),\n            }),\n            split_id: \"\".to_string(),\n            segment_ord: 0,\n            doc_id: 0,\n        };\n        validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap();\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_ok_with_doc_sort_field() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"_doc\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: None,\n            split_id: \"split1\".to_string(),\n            segment_ord: 1,\n            doc_id: 1,\n        };\n        validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap();\n    }\n\n    #[test]\n    fn test_validate_sort_by_field_type() {\n        let mut schema_builder = Schema::builder();\n        let timestamp_field = schema_builder.add_date_field(\"timestamp\", FAST);\n        let id_field = schema_builder.add_u64_field(\"id\", FAST);\n        let no_fast_field = schema_builder.add_u64_field(\"no_fast\", STORED);\n        let text_field = schema_builder.add_text_field(\"text\", STORED);\n        let schema = schema_builder.build();\n        {\n            let sort_by_field_entry = schema.get_field_entry(timestamp_field);\n            validate_sort_by_field_type(sort_by_field_entry, false).unwrap();\n            validate_sort_by_field_type(sort_by_field_entry, true).unwrap();\n        }\n        {\n            let sort_by_field_entry = schema.get_field_entry(id_field);\n            validate_sort_by_field_type(sort_by_field_entry, false).unwrap();\n            let error = validate_sort_by_field_type(sort_by_field_entry, true).unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"Invalid argument: sort by field with a timestamp format must be a datetime field \\\n                 and the field `id` is not\"\n            );\n        }\n        {\n            let sort_by_field_entry = schema.get_field_entry(no_fast_field);\n            let error = validate_sort_by_field_type(sort_by_field_entry, true).unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"Invalid argument: sort by field must be a fast field, please add the fast \\\n                 property to your field `no_fast`\"\n            );\n        }\n        {\n            let sort_by_field_entry = schema.get_field_entry(text_field);\n            let error = validate_sort_by_field_type(sort_by_field_entry, true).unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"Invalid argument: sort by field on type text is currently not supported `text`\"\n            );\n        }\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_invalid_1() {\n        // 2 sort fields + search after with only one sort value is invalid.\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: None,\n            split_id: \"split1\".to_string(),\n            segment_ord: 1,\n            doc_id: 1,\n        };\n        let error =\n            validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: `search_after` must have the same number of sort values as sort by \\\n             fields [\\\"timestamp\\\", \\\"id\\\"]\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_invalid_with_missing_split_id() {\n        // 2 sort fields + search after with only one sort value is invalid.\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"_doc\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: None,\n            split_id: \"\".to_string(),\n            segment_ord: 1,\n            doc_id: 1,\n        };\n        let error =\n            validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: search_after with a sort field `_doc` must define a split ID, \\\n             segment ID and doc ID values\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_valid_1() {\n        // 2 sort fields + search after with only one sort value is invalid.\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: None,\n            split_id: \"split1\".to_string(),\n            segment_ord: 1,\n            doc_id: 1,\n        };\n        let error =\n            validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: `search_after` must have the same number of sort values as sort by \\\n             fields [\\\"timestamp\\\", \\\"id\\\"]\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_by_field_type_invalid() {\n        // sort non-datetime field with a datetime format is invalid.\n        let mut schema_builder = Schema::builder();\n        let field = schema_builder.add_u64_field(\"timestamp\", FAST);\n        let schema = schema_builder.build();\n        let field_entry = schema.get_field_entry(field);\n        let error = validate_sort_by_field_type(field_entry, true).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: sort by field with a timestamp format must be a datetime field and \\\n             the field `timestamp` is not\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_invalid_3() {\n        // 3 sort fields is not possible.\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n        ];\n        let error = validate_sort_by_fields_and_search_after(&sort_fields, &None).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: sort by field must be up to 2 fields, got 3\"\n        );\n    }\n\n    fn mock_partial_hit(\n        split_id: &str,\n        sort_value: u64,\n        doc_id: u32,\n    ) -> quickwit_proto::search::PartialHit {\n        quickwit_proto::search::PartialHit {\n            sort_value: Some(SortValue::U64(sort_value).into()),\n            sort_value2: None,\n            split_id: split_id.to_string(),\n            segment_ord: 1,\n            doc_id,\n        }\n    }\n\n    fn mock_partial_hit_opt_sort_value(\n        split_id: &str,\n        sort_value: Option<u64>,\n        doc_id: u32,\n    ) -> quickwit_proto::search::PartialHit {\n        quickwit_proto::search::PartialHit {\n            sort_value: sort_value.map(|sort_value| SortValue::U64(sort_value).into()),\n            sort_value2: None,\n            split_id: split_id.to_string(),\n            segment_ord: 1,\n            doc_id,\n        }\n    }\n\n    fn get_doc_for_fetch_req(\n        fetch_docs_req: quickwit_proto::search::FetchDocsRequest,\n    ) -> Vec<quickwit_proto::search::LeafHit> {\n        fetch_docs_req\n            .partial_hits\n            .into_iter()\n            .map(|req| quickwit_proto::search::LeafHit {\n                leaf_json: serde_json::to_string_pretty(&serde_json::json!({\n                    \"title\": [req.doc_id.to_string()],\n                    \"body\": [\"test 1\"],\n                    \"url\": [\"http://127.0.0.1/1\"]\n                }))\n                .expect(\"Json serialization should not fail\"),\n                partial_hit: Some(req),\n                leaf_snippet_json: None,\n            })\n            .collect()\n    }\n\n    #[tokio::test]\n    async fn test_root_search_offset_out_of_bounds_1085() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            start_offset: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_indexes_metadata_request| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 3,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split1\", 3, 1),\n                        mock_partial_hit(\"split1\", 2, 2),\n                        mock_partial_hit(\"split1\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split2\", 3, 1),\n                        mock_partial_hit(\"split2\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 5);\n        assert_eq!(search_response.hits.len(), 0);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_single_split() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_list_splits_request| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service = MockSearchService::new();\n        mock_search_service.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 3,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split1\", 3, 1),\n                        mock_partial_hit(\"split1\", 2, 2),\n                        mock_partial_hit(\"split1\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n\n        let searcher_context = SearcherContext::for_test();\n        let search_response = root_search(\n            &searcher_context,\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split1\", 3, 1),\n                        mock_partial_hit(\"split1\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 1,\n                    partial_hits: vec![mock_partial_hit(\"split2\", 2, 2)],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_with_failure() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 2,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                if leaf_search_req.leaf_requests[0].split_offsets.len() == 2 {\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: 2,\n                        partial_hits: vec![\n                            mock_partial_hit(\"split1\", 3, 1),\n                            mock_partial_hit(\"split1\", 1, 3),\n                        ],\n                        failed_splits: vec![SplitSearchError {\n                            error: \"some error\".to_string(),\n                            split_id: \"split2\".to_string(),\n                            retryable_error: true,\n                        }],\n                        num_attempted_splits: 2,\n                        ..Default::default()\n                    })\n                } else {\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: 1,\n                        partial_hits: vec![mock_partial_hit(\"split2\", 2, 2)],\n                        failed_splits: Vec::new(),\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                }\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service_1)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 2);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_sort_heteregeneous_field_ascending(\n    ) -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            sort_fields: vec![SortField {\n                field_name: \"response_date\".to_string(),\n                sort_order: SortOrder::Asc.into(),\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampNanos as i32),\n            }],\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::U64(2u64).into()),\n                            sort_value2: None,\n                            split_id: \"split1\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 0,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: None,\n                            sort_value2: None,\n                            split_id: \"split1\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 1,\n                        },\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 3,\n                    partial_hits: vec![\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::I64(-1i64).into()),\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 1,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::I64(1i64).into()),\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 0,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: None,\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 2,\n                        },\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request.clone(),\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await?;\n\n        assert_eq!(search_response.num_hits, 5);\n        assert_eq!(search_response.hits.len(), 5);\n        assert_eq!(\n            search_response.hits[0].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 1,\n                sort_value: Some(SortValue::I64(-1i64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[1].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 0,\n                sort_value: Some(SortValue::I64(1i64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[2].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split1\".to_string(),\n                segment_ord: 0,\n                doc_id: 0,\n                sort_value: Some(SortValue::U64(2u64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[3].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split1\".to_string(),\n                segment_ord: 0,\n                doc_id: 1,\n                sort_value: None,\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[4].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 2,\n                sort_value: None,\n                sort_value2: None,\n            }\n        );\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_sort_heteregeneous_field_descending(\n    ) -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            sort_fields: vec![SortField {\n                field_name: \"response_date\".to_string(),\n                sort_order: SortOrder::Desc.into(),\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampNanos as i32),\n            }],\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::U64(2u64).into()),\n                            sort_value2: None,\n                            split_id: \"split1\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 0,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: None,\n                            sort_value2: None,\n                            split_id: \"split1\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 1,\n                        },\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 3,\n                    partial_hits: vec![\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::I64(1i64).into()),\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 0,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::I64(-1i64).into()),\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 1,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: None,\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 2,\n                        },\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request.clone(),\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await?;\n\n        assert_eq!(search_response.num_hits, 5);\n        assert_eq!(search_response.hits.len(), 5);\n        assert_eq!(\n            search_response.hits[0].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split1\".to_string(),\n                segment_ord: 0,\n                doc_id: 0,\n                sort_value: Some(SortValue::U64(2u64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[1].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 0,\n                sort_value: Some(SortValue::I64(1i64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[2].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 1,\n                sort_value: Some(SortValue::I64(-1i64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[3].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 2,\n                sort_value: None,\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[4].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split1\".to_string(),\n                segment_ord: 0,\n                doc_id: 1,\n                sort_value: None,\n                sort_value2: None,\n            }\n        );\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_retry_on_other_node() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1\n            .expect_leaf_search()\n            .times(2)\n            .returning(\n                |leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                    let split_ids: Vec<&str> = leaf_search_req.leaf_requests[0]\n                        .split_offsets\n                        .iter()\n                        .map(|metadata| metadata.split_id.as_str())\n                        .collect();\n                    if split_ids == [\"split1\"] {\n                        Ok(quickwit_proto::search::LeafSearchResponse {\n                            num_hits: 2,\n                            partial_hits: vec![\n                                mock_partial_hit(\"split1\", 3, 1),\n                                mock_partial_hit(\"split1\", 1, 3),\n                            ],\n                            failed_splits: Vec::new(),\n                            num_attempted_splits: 1,\n                            ..Default::default()\n                        })\n                    } else if split_ids == [\"split2\"] {\n                        // RETRY REQUEST!\n                        Ok(quickwit_proto::search::LeafSearchResponse {\n                            num_hits: 1,\n                            partial_hits: vec![mock_partial_hit(\"split2\", 2, 2)],\n                            failed_splits: Vec::new(),\n                            num_attempted_splits: 1,\n                            ..Default::default()\n                        })\n                    } else {\n                        panic!(\"unexpected request in test {split_ids:?}\");\n                    }\n                },\n            );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2\n            .expect_leaf_search()\n            .times(1)\n            .returning(\n                |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        // requests from split 2 arrive here - simulate failure\n                        num_hits: 0,\n                        partial_hits: Vec::new(),\n                        failed_splits: vec![SplitSearchError {\n                            error: \"mock_error\".to_string(),\n                            split_id: \"split2\".to_string(),\n                            retryable_error: true,\n                        }],\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                },\n            );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_retry_on_all_nodes() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_indexes_metadata_request| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1\n            .expect_leaf_search()\n            .withf(|leaf_search_req| {\n                leaf_search_req.leaf_requests[0].split_offsets[0].split_id == \"split2\"\n            })\n            .return_once(|_| {\n                // requests from split 2 arrive here - simulate failure.\n                // a retry will be made on the second service.\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 0,\n                    partial_hits: Vec::new(),\n                    failed_splits: vec![SplitSearchError {\n                        error: \"mock_error\".to_string(),\n                        split_id: \"split2\".to_string(),\n                        retryable_error: true,\n                    }],\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            });\n        mock_search_service_1\n            .expect_leaf_search()\n            .withf(|leaf_search_req| {\n                leaf_search_req.leaf_requests[0].split_offsets[0].split_id == \"split1\"\n            })\n            .return_once(|_| {\n                // RETRY REQUEST from split1\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split1\", 3, 1),\n                        mock_partial_hit(\"split1\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            });\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2\n            .expect_leaf_search()\n            .withf(|leaf_search_req| {\n                leaf_search_req.leaf_requests[0].split_offsets[0].split_id == \"split2\"\n            })\n            .return_once(|_| {\n                // retry for split 2 arrive here, simulate success.\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 1,\n                    partial_hits: vec![mock_partial_hit(\"split2\", 2, 2)],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            });\n        mock_search_service_2\n            .expect_leaf_search()\n            .withf(|leaf_search_req| {\n                leaf_search_req.leaf_requests[0].split_offsets[0].split_id == \"split1\"\n            })\n            .return_once(|_| {\n                // requests from split 1 arrive here - simulate failure, then success.\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    // requests from split 2 arrive here - simulate failure\n                    num_hits: 0,\n                    partial_hits: Vec::new(),\n                    failed_splits: vec![SplitSearchError {\n                        error: \"mock_error\".to_string(),\n                        split_id: \"split1\".to_string(),\n                        retryable_error: true,\n                    }],\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            });\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_single_split_retry_single_node() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_list_splits_request| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut first_call = true;\n        let mut mock_search_service = MockSearchService::new();\n        mock_search_service.expect_leaf_search().times(2).returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                // requests from split 2 arrive here - simulate failure, then success\n                if first_call {\n                    first_call = false;\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: 0,\n                        partial_hits: Vec::new(),\n                        failed_splits: vec![SplitSearchError {\n                            error: \"mock_error\".to_string(),\n                            split_id: \"split1\".to_string(),\n                            retryable_error: true,\n                        }],\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                } else {\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: 1,\n                        partial_hits: vec![mock_partial_hit(\"split1\", 2, 2)],\n                        failed_splits: Vec::new(),\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                }\n            },\n        );\n        mock_search_service.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 1);\n        assert_eq!(search_response.hits.len(), 1);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_single_split_retry_single_node_fails() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n\n        let mut mock_search_service = MockSearchService::new();\n        mock_search_service.expect_leaf_search().times(2).returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 0,\n                    partial_hits: Vec::new(),\n                    failed_splits: vec![SplitSearchError {\n                        error: \"mock_error\".to_string(),\n                        split_id: \"split1\".to_string(),\n                        retryable_error: true,\n                    }],\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service.expect_fetch_docs().returning(\n            |_fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Err(SearchError::Internal(\"mockerr docs\".to_string()))\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await;\n        assert!(search_response.is_err());\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_one_splits_two_nodes_but_one_is_failing_for_split(\n    ) -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        // Service1 - broken node.\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                // retry requests from split 1 arrive here\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 1,\n                    partial_hits: vec![mock_partial_hit(\"split1\", 2, 2)],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        // Service2 - working node.\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 0,\n                    partial_hits: Vec::new(),\n                    failed_splits: vec![SplitSearchError {\n                        error: \"mock_error\".to_string(),\n                        split_id: \"split1\".to_string(),\n                        retryable_error: true,\n                    }],\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |_fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Err(SearchError::Internal(\"mockerr docs\".to_string()))\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 1);\n        assert_eq!(search_response.hits.len(), 1);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_one_splits_two_nodes_but_one_is_failing_completely(\n    ) -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n\n        // Service1 - working node.\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 1,\n                    partial_hits: vec![mock_partial_hit(\"split1\", 2, 2)],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        // Service2 - broken node.\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Err(SearchError::Internal(\"mockerr search\".to_string()))\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |_fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Err(SearchError::Internal(\"mockerr docs\".to_string()))\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 1);\n        assert_eq!(search_response.hits.len(), 1);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_invalid_queries() -> anyhow::Result<()> {\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", MockSearchService::new())]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let searcher_context = SearcherContext::for_test();\n        let metastore = MetastoreServiceClient::from_mock(mock_metastore);\n\n        assert!(root_search(\n            &searcher_context,\n            quickwit_proto::search::SearchRequest {\n                index_id_patterns: vec![\"test-index\".to_string()],\n                query_ast: qast_json_helper(\"invalid_field:\\\"test\\\"\", &[\"body\"]),\n                max_hits: 10,\n                ..Default::default()\n            },\n            metastore.clone(),\n            &cluster_client,\n        )\n        .await\n        .is_err());\n\n        assert!(root_search(\n            &searcher_context,\n            quickwit_proto::search::SearchRequest {\n                index_id_patterns: vec![\"test-index\".to_string()],\n                query_ast: qast_json_helper(\"test\", &[\"invalid_field\"]),\n                max_hits: 10,\n                ..Default::default()\n            },\n            metastore,\n            &cluster_client,\n        )\n        .await\n        .is_err());\n\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_invalid_aggregation() -> anyhow::Result<()> {\n        let agg_req = r#\"\n            {\n                \"expensive_colors\": {\n                    \"termss\": {\n                        \"field\": \"color\",\n                        \"order\": {\n                            \"price_stats.max\": \"desc\"\n                        }\n                    },\n                    \"aggs\": {\n                        \"price_stats\" : {\n                            \"stats\": {\n                                \"field\": \"price\"\n                            }\n                        }\n                    }\n                }\n            }\"#;\n\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            aggregation_request: Some(agg_req.to_string()),\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", MockSearchService::new())]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await;\n        assert!(search_response.is_err());\n        assert!(search_response\n            .unwrap_err()\n            .to_string()\n            .starts_with(\"invalid aggregation request: unknown variant `termss`, expected one of\"));\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_invalid_request() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            start_offset: 20_000,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", MockSearchService::new())]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let metastore = MetastoreServiceClient::from_mock(mock_metastore);\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            metastore.clone(),\n            &cluster_client,\n        )\n        .await;\n        assert!(search_response.is_err());\n        assert_eq!(\n            search_response.unwrap_err().to_string(),\n            \"Invalid argument: max value for start_offset is 10_000, but got 20000\",\n        );\n\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 20_000,\n            ..Default::default()\n        };\n\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            metastore,\n            &cluster_client,\n        )\n        .await;\n        assert!(search_response.is_err());\n        assert_eq!(\n            search_response.unwrap_err().to_string(),\n            \"Invalid argument: max value for max_hits is 10_000, but got 20000\",\n        );\n\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_search_plan_multiple_splits() -> anyhow::Result<()> {\n        use quickwit_query::query_ast::{FullTextMode, FullTextParams, FullTextQuery};\n        use quickwit_query::MatchAllOrNone;\n\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test-query\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let search_response = search_plan(\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n        )\n        .await\n        .unwrap();\n        let response: SearchPlanResponseRest =\n            serde_json::from_str(&search_response.result).unwrap();\n        assert_eq!(\n            response,\n            SearchPlanResponseRest {\n                quickwit_ast: QueryAst::FullText(FullTextQuery {\n                    field: \"body\".to_string(),\n                    text: \"test-query\".to_string(),\n                    params: FullTextParams {\n                        tokenizer: None,\n                        mode: FullTextMode::PhraseFallbackToIntersection,\n                        zero_terms_query: MatchAllOrNone::MatchNone,\n                    },\n                    lenient: false,\n                },),\n                tantivy_ast: r#\"BooleanQuery {\n    subqueries: [\n        (\n            Must,\n            TermQuery(Term(field=3, type=Str, \"test\")),\n        ),\n        (\n            Must,\n            TermQuery(Term(field=3, type=Str, \"query\")),\n        ),\n    ],\n    minimum_number_should_match: 0,\n}\"#\n                .to_string(),\n                searched_splits: vec![\n                    \"test-index/split1\".to_string(),\n                    \"test-index/split2\".to_string()\n                ],\n                storage_requests: StorageRequestCount {\n                    footer: 1,\n                    fastfield: 0,\n                    fieldnorm: 0,\n                    sstable: 2,\n                    posting: 2,\n                    position: 0,\n                },\n            }\n        );\n        Ok(())\n    }\n\n    #[test]\n    fn test_extract_timestamp_range_from_ast() {\n        use std::ops::Bound;\n\n        use quickwit_query::JsonLiteral;\n\n        let timestamp_field = \"timestamp\";\n\n        let simple_range = quickwit_query::query_ast::RangeQuery {\n            field: timestamp_field.to_string(),\n            lower_bound: Bound::Included(JsonLiteral::String(\"2021-04-13T22:45:41Z\".to_owned())),\n            upper_bound: Bound::Excluded(JsonLiteral::String(\"2021-05-06T06:51:19Z\".to_owned())),\n        }\n        .into();\n\n        // direct range\n        let mut timestamp_range_extractor = ExtractTimestampRange {\n            timestamp_field,\n            start_timestamp: None,\n            end_timestamp: None,\n        };\n        timestamp_range_extractor.visit(&simple_range).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353941));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283879));\n\n        // range inside a must bool query\n        let bool_query_must = quickwit_query::query_ast::BoolQuery {\n            must: vec![simple_range.clone()],\n            ..Default::default()\n        };\n        timestamp_range_extractor.start_timestamp = None;\n        timestamp_range_extractor.end_timestamp = None;\n        timestamp_range_extractor\n            .visit(&bool_query_must.into())\n            .unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353941));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283879));\n\n        // range inside a should bool query\n        let bool_query_should = quickwit_query::query_ast::BoolQuery {\n            should: vec![simple_range.clone()],\n            ..Default::default()\n        };\n        timestamp_range_extractor.start_timestamp = Some(123);\n        timestamp_range_extractor.end_timestamp = None;\n        timestamp_range_extractor\n            .visit(&bool_query_should.into())\n            .unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(123));\n        assert_eq!(timestamp_range_extractor.end_timestamp, None);\n\n        // start bound was already more restrictive\n        timestamp_range_extractor.start_timestamp = Some(1618601297);\n        timestamp_range_extractor.end_timestamp = Some(i64::MAX);\n        timestamp_range_extractor.visit(&simple_range).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618601297));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283879));\n\n        // end bound was already more restrictive\n        timestamp_range_extractor.start_timestamp = Some(1);\n        timestamp_range_extractor.end_timestamp = Some(1618601297);\n        timestamp_range_extractor.visit(&simple_range).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353941));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1618601297));\n\n        // bounds are (start..end] instead of [start..end)\n        let unusual_bounds = quickwit_query::query_ast::RangeQuery {\n            field: timestamp_field.to_string(),\n            lower_bound: Bound::Excluded(JsonLiteral::String(\"2021-04-13T22:45:41Z\".to_owned())),\n            upper_bound: Bound::Included(JsonLiteral::String(\"2021-05-06T06:51:19Z\".to_owned())),\n        }\n        .into();\n        timestamp_range_extractor.start_timestamp = None;\n        timestamp_range_extractor.end_timestamp = None;\n        timestamp_range_extractor.visit(&unusual_bounds).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353942));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283880));\n\n        let wrong_field = quickwit_query::query_ast::RangeQuery {\n            field: \"other_field\".to_string(),\n            lower_bound: Bound::Included(JsonLiteral::String(\"2021-04-13T22:45:41Z\".to_owned())),\n            upper_bound: Bound::Excluded(JsonLiteral::String(\"2021-05-06T06:51:19Z\".to_owned())),\n        }\n        .into();\n        timestamp_range_extractor.start_timestamp = None;\n        timestamp_range_extractor.end_timestamp = None;\n        timestamp_range_extractor.visit(&wrong_field).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, None);\n        assert_eq!(timestamp_range_extractor.end_timestamp, None);\n\n        let high_precision = quickwit_query::query_ast::RangeQuery {\n            field: timestamp_field.to_string(),\n            lower_bound: Bound::Included(JsonLiteral::String(\n                \"2021-04-13T22:45:41.001Z\".to_owned(),\n            )),\n            upper_bound: Bound::Excluded(JsonLiteral::String(\n                \"2021-05-06T06:51:19.001Z\".to_owned(),\n            )),\n        }\n        .into();\n\n        // the upper bound should be rounded up as to includes documents from X.000 to X.001\n        let mut timestamp_range_extractor = ExtractTimestampRange {\n            timestamp_field,\n            start_timestamp: None,\n            end_timestamp: None,\n        };\n        timestamp_range_extractor.visit(&high_precision).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353941));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283880));\n    }\n\n    fn create_search_resp(\n        index_uri: &str,\n        hit_range: Range<usize>,\n        search_after: Option<PartialHit>,\n    ) -> LeafSearchResponse {\n        let (num_total_hits, split_id) = match index_uri {\n            \"ram:///test-index-1\" => (TOTAL_NUM_HITS_INDEX_1, \"split1\"),\n            \"ram:///test-index-2\" => (TOTAL_NUM_HITS_INDEX_2, \"split2\"),\n            _ => panic!(\"unexpected index uri\"),\n        };\n\n        let doc_ids = (0..num_total_hits)\n            .rev()\n            .filter(|elem| {\n                if let Some(search_after) = &search_after {\n                    if split_id == search_after.split_id {\n                        *elem < (search_after.doc_id as usize)\n                    } else {\n                        split_id < search_after.split_id.as_str()\n                    }\n                } else {\n                    true\n                }\n            })\n            .skip(hit_range.start)\n            .take(hit_range.end - hit_range.start);\n        quickwit_proto::search::LeafSearchResponse {\n            num_hits: num_total_hits as u64,\n            partial_hits: doc_ids\n                .map(|doc_id| mock_partial_hit_opt_sort_value(split_id, None, doc_id as u32))\n                .collect(),\n            num_attempted_splits: 1,\n            ..Default::default()\n        }\n    }\n\n    const TOTAL_NUM_HITS_INDEX_1: usize = 2_005;\n    const TOTAL_NUM_HITS_INDEX_2: usize = 10;\n    const MAX_HITS_PER_PAGE: usize = 93;\n    const MAX_HITS_PER_PAGE_LARGE: usize = 1_005;\n\n    #[tokio::test]\n    async fn test_root_search_with_scroll() {\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_uid = index_metadata.index_uid.clone();\n        let index_metadata_2 = IndexMetadata::for_test(\"test-index-2\", \"ram:///test-index-2\");\n        let index_uid_2 = index_metadata_2.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                let indexes_metadata = vec![index_metadata.clone(), index_metadata_2.clone()];\n                Ok(ListIndexesMetadataResponse::for_test(indexes_metadata))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid_2)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        // We add two mock_search_service to simulate a multi node environment, where the requests\n        // are forwarded two node.\n        let mut mock_search_service1 = MockSearchService::new();\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_none());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n\n        let mut mock_search_service2 = MockSearchService::new();\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_none());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n\n        let kv: Arc<RwLock<HashMap<Vec<u8>, Vec<u8>>>> = Default::default();\n        let kv_clone = kv.clone();\n        mock_search_service1\n            .expect_put_kv()\n            .returning(move |put_kv_req| {\n                kv_clone\n                    .write()\n                    .unwrap()\n                    .insert(put_kv_req.key, put_kv_req.payload);\n            });\n        mock_search_service1\n            .expect_get_kv()\n            .returning(move |get_kv_req| kv.read().unwrap().get(&get_kv_req.key).cloned());\n\n        let kv: Arc<RwLock<HashMap<Vec<u8>, Vec<u8>>>> = Default::default();\n        let kv_clone = kv.clone();\n        mock_search_service2\n            .expect_put_kv()\n            .returning(move |put_kv_req| {\n                kv_clone\n                    .write()\n                    .unwrap()\n                    .insert(put_kv_req.key, put_kv_req.payload);\n            });\n        mock_search_service2\n            .expect_get_kv()\n            .returning(move |get_kv_req| kv.read().unwrap().get(&get_kv_req.key).cloned());\n\n        mock_search_service1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                assert!(fetch_docs_req.partial_hits.len() <= MAX_HITS_PER_PAGE);\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n\n        mock_search_service2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                assert!(fetch_docs_req.partial_hits.len() <= MAX_HITS_PER_PAGE);\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service1),\n            (\"127.0.0.1:1002\", mock_search_service2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let searcher_context = SearcherContext::for_test();\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n\n        let mut count_seen_hits = 0;\n\n        let mut scroll_id: String = {\n            let search_request = quickwit_proto::search::SearchRequest {\n                index_id_patterns: vec![\"test-index-*\".to_string()],\n                query_ast: qast_json_helper(\"test\", &[\"body\"]),\n                max_hits: MAX_HITS_PER_PAGE as u64,\n                scroll_ttl_secs: Some(60),\n                ..Default::default()\n            };\n            let search_response = root_search(\n                &searcher_context,\n                search_request,\n                MetastoreServiceClient::from_mock(mock_metastore),\n                &cluster_client,\n            )\n            .await\n            .unwrap();\n            assert_eq!(\n                search_response.num_hits,\n                (TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2) as u64\n            );\n            assert_eq!(search_response.hits.len(), MAX_HITS_PER_PAGE);\n            let expected = (0..TOTAL_NUM_HITS_INDEX_2)\n                .rev()\n                .zip(std::iter::repeat(\"split2\"))\n                .chain(\n                    (0..TOTAL_NUM_HITS_INDEX_1)\n                        .rev()\n                        .zip(std::iter::repeat(\"split1\")),\n                );\n            for (hit, (doc_id, split)) in search_response.hits.iter().zip(expected) {\n                assert_eq!(\n                    hit.partial_hit.as_ref().unwrap(),\n                    &mock_partial_hit_opt_sort_value(split, None, doc_id as u32)\n                );\n            }\n            count_seen_hits += search_response.hits.len();\n            search_response.scroll_id.unwrap()\n        };\n        for page in 1.. {\n            let scroll_req = ScrollRequest {\n                scroll_id,\n                scroll_ttl_secs: Some(60),\n            };\n            let scroll_resp =\n                crate::service::scroll(scroll_req, &cluster_client, &searcher_context)\n                    .await\n                    .unwrap();\n            assert_eq!(\n                scroll_resp.num_hits,\n                (TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2) as u64\n            );\n            let expected = (0..TOTAL_NUM_HITS_INDEX_2)\n                .rev()\n                .zip(std::iter::repeat(\"split2\"))\n                .chain(\n                    (0..TOTAL_NUM_HITS_INDEX_1)\n                        .rev()\n                        .zip(std::iter::repeat(\"split1\")),\n                )\n                .skip(page * MAX_HITS_PER_PAGE);\n            for (hit, (doc_id, split)) in scroll_resp.hits.iter().zip(expected) {\n                assert_eq!(\n                    hit.partial_hit.as_ref().unwrap(),\n                    &mock_partial_hit_opt_sort_value(split, None, doc_id as u32)\n                );\n            }\n            scroll_id = scroll_resp.scroll_id.unwrap();\n            count_seen_hits += scroll_resp.hits.len();\n            if scroll_resp.hits.is_empty() {\n                break;\n            }\n        }\n\n        assert_eq!(\n            count_seen_hits,\n            TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2\n        );\n    }\n\n    #[tokio::test]\n    async fn test_root_search_with_scroll_large_page() {\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_uid = index_metadata.index_uid.clone();\n        let index_metadata_2 = IndexMetadata::for_test(\"test-index-2\", \"ram:///test-index-2\");\n        let index_uid_2 = index_metadata_2.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                let indexes_metadata = vec![index_metadata.clone(), index_metadata_2.clone()];\n                Ok(ListIndexesMetadataResponse::for_test(indexes_metadata))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid_2)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        // We add two mock_search_service to simulate a multi node environment, where the requests\n        // are forwarded two nodes.\n        let mut mock_search_service1 = MockSearchService::new();\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_none());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        let kv: Arc<RwLock<HashMap<Vec<u8>, Vec<u8>>>> = Default::default();\n        let kv_clone = kv.clone();\n        mock_search_service1\n            .expect_put_kv()\n            .returning(move |put_kv_req| {\n                kv_clone\n                    .write()\n                    .unwrap()\n                    .insert(put_kv_req.key, put_kv_req.payload);\n            });\n        mock_search_service1\n            .expect_get_kv()\n            .returning(move |get_kv_req| kv.read().unwrap().get(&get_kv_req.key).cloned());\n        mock_search_service1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                assert!(fetch_docs_req.partial_hits.len() <= MAX_HITS_PER_PAGE_LARGE);\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n\n        let mut mock_search_service2 = MockSearchService::new();\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_none());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        let kv: Arc<RwLock<HashMap<Vec<u8>, Vec<u8>>>> = Default::default();\n        let kv_clone = kv.clone();\n        mock_search_service2\n            .expect_put_kv()\n            .returning(move |put_kv_req| {\n                kv_clone\n                    .write()\n                    .unwrap()\n                    .insert(put_kv_req.key, put_kv_req.payload);\n            });\n        mock_search_service2\n            .expect_get_kv()\n            .returning(move |get_kv_req| kv.read().unwrap().get(&get_kv_req.key).cloned());\n        mock_search_service2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                assert!(fetch_docs_req.partial_hits.len() <= MAX_HITS_PER_PAGE_LARGE);\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service1),\n            (\"127.0.0.1:1002\", mock_search_service2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let searcher_context = SearcherContext::for_test();\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n\n        let mut count_seen_hits = 0;\n\n        let mut scroll_id: String = {\n            let search_request = quickwit_proto::search::SearchRequest {\n                index_id_patterns: vec![\"test-index-*\".to_string()],\n                query_ast: qast_json_helper(\"test\", &[\"body\"]),\n                max_hits: MAX_HITS_PER_PAGE_LARGE as u64,\n                scroll_ttl_secs: Some(60),\n                ..Default::default()\n            };\n            let search_response = root_search(\n                &searcher_context,\n                search_request,\n                MetastoreServiceClient::from_mock(mock_metastore),\n                &cluster_client,\n            )\n            .await\n            .unwrap();\n            assert_eq!(\n                search_response.num_hits,\n                (TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2) as u64\n            );\n            assert_eq!(search_response.hits.len(), MAX_HITS_PER_PAGE_LARGE);\n            let expected = (0..TOTAL_NUM_HITS_INDEX_2)\n                .rev()\n                .zip(std::iter::repeat(\"split2\"))\n                .chain(\n                    (0..TOTAL_NUM_HITS_INDEX_1)\n                        .rev()\n                        .zip(std::iter::repeat(\"split1\")),\n                );\n            for (hit, (doc_id, split)) in search_response.hits.iter().zip(expected) {\n                assert_eq!(\n                    hit.partial_hit.as_ref().unwrap(),\n                    &mock_partial_hit_opt_sort_value(split, None, doc_id as u32)\n                );\n            }\n            count_seen_hits += search_response.hits.len();\n            search_response.scroll_id.unwrap()\n        };\n        for page in 1.. {\n            let scroll_req = ScrollRequest {\n                scroll_id,\n                scroll_ttl_secs: Some(60),\n            };\n            let scroll_resp =\n                crate::service::scroll(scroll_req, &cluster_client, &searcher_context)\n                    .await\n                    .unwrap();\n            assert_eq!(\n                scroll_resp.num_hits,\n                (TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2) as u64\n            );\n            let expected = (0..TOTAL_NUM_HITS_INDEX_2)\n                .rev()\n                .zip(std::iter::repeat(\"split2\"))\n                .chain(\n                    (0..TOTAL_NUM_HITS_INDEX_1)\n                        .rev()\n                        .zip(std::iter::repeat(\"split1\")),\n                )\n                .skip(page * MAX_HITS_PER_PAGE_LARGE);\n            for (hit, (doc_id, split)) in scroll_resp.hits.iter().zip(expected) {\n                assert_eq!(\n                    hit.partial_hit.as_ref().unwrap(),\n                    &mock_partial_hit_opt_sort_value(split, None, doc_id as u32)\n                );\n            }\n            scroll_id = scroll_resp.scroll_id.unwrap();\n            count_seen_hits += scroll_resp.hits.len();\n            if scroll_resp.hits.is_empty() {\n                break;\n            }\n        }\n\n        assert_eq!(\n            count_seen_hits,\n            TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2\n        );\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multi_indices() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index-*\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata_1 = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_uid_1 = index_metadata_1.index_uid.clone();\n        let index_metadata_2 =\n            index_metadata_for_multi_indexes_test(\"test-index-2\", \"ram:///test-index-2\");\n        let index_uid_2 = index_metadata_2.index_uid.clone();\n        let index_metadata_3 =\n            index_metadata_for_multi_indexes_test(\"test-index-3\", \"ram:///test-index-3\");\n        let index_uid_3 = index_metadata_3.index_uid.clone();\n        mock_metastore.expect_list_indexes_metadata().return_once(\n            move |list_indexes_metadata_request: ListIndexesMetadataRequest| {\n                let index_id_patterns = list_indexes_metadata_request.index_id_patterns;\n                assert_eq!(&index_id_patterns, &[\"test-index-*\".to_string()]);\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata_1,\n                    index_metadata_2,\n                    index_metadata_3,\n                ]))\n            },\n        );\n        mock_metastore\n            .expect_list_splits()\n            .return_once(move |list_splits_request| {\n                let list_splits_query =\n                    list_splits_request.deserialize_list_splits_query().unwrap();\n                assert!(\n                    list_splits_query.index_uids\n                        == vec![\n                            index_uid_1.clone(),\n                            index_uid_2.clone(),\n                            index_uid_3.clone()\n                        ]\n                );\n                let splits = vec![\n                    MockSplitBuilder::new(\"index-1-split-1\")\n                        .with_index_uid(&index_uid_1)\n                        .build(),\n                    MockSplitBuilder::new(\"index-1-split-2\")\n                        .with_index_uid(&index_uid_1)\n                        .build(),\n                    MockSplitBuilder::new(\"index-2-split-1\")\n                        .with_index_uid(&index_uid_2)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1\n            .expect_leaf_search()\n            .times(1)\n            .withf(|leaf_search_req| {\n                (&leaf_search_req.index_uris[0] == \"ram:///test-index-1\"\n                    && leaf_search_req.leaf_requests[0].split_offsets.len() == 2)\n                    || (leaf_search_req.index_uris[0] == \"ram:///test-index-2\"\n                        && leaf_search_req.leaf_requests[0].split_offsets[0].split_id\n                            == \"index-2-split-1\")\n            })\n            .returning(\n                |leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                    let mut partial_hits = leaf_search_req.leaf_requests[0]\n                        .split_offsets\n                        .iter()\n                        .map(|split_offset| mock_partial_hit(&split_offset.split_id, 3, 1))\n                        .collect_vec();\n                    let partial_hits2 = leaf_search_req.leaf_requests[1]\n                        .split_offsets\n                        .iter()\n                        .map(|split_offset| mock_partial_hit(&split_offset.split_id, 3, 1))\n                        .collect_vec();\n                    partial_hits.extend_from_slice(&partial_hits2);\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: leaf_search_req.leaf_requests[0].split_offsets.len() as u64\n                            + leaf_search_req.leaf_requests[1].split_offsets.len() as u64,\n                        partial_hits,\n                        failed_splits: Vec::new(),\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                },\n            );\n        mock_search_service_1\n            .expect_fetch_docs()\n            .times(2)\n            .withf(|fetch_docs_req: &FetchDocsRequest| {\n                (fetch_docs_req.index_uri == \"ram:///test-index-1\"\n                    && fetch_docs_req.partial_hits.len() == 2)\n                    || (fetch_docs_req.index_uri == \"ram:///test-index-2\"\n                        && fetch_docs_req.partial_hits[0].split_id == \"index-2-split-1\")\n            })\n            .returning(|fetch_docs_req| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            });\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service_1)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        assert_eq!(\n            search_response\n                .hits\n                .iter()\n                .map(|hit| &hit.index_id)\n                .collect_vec(),\n            vec![\"test-index-1\", \"test-index-1\", \"test-index-2\"]\n        );\n        Ok(())\n    }\n}\n```\nasync fn search_partial_hits_phase_with_scroll\n\n```rs quickwit/quickwit/quickwit-search/src/root.rs\n// Copyright (C) 2024 Quickwit, Inc.\n//\n// Quickwit is offered under the AGPL v3.0 and as commercial software.\n// For commercial licensing, contact us at hello@quickwit.io.\n//\n// AGPL:\n// This program is free software: you can redistribute it and/or modify\n// it under the terms of the GNU Affero General Public License as\n// published by the Free Software Foundation, either version 3 of the\n// License, or (at your option) any later version.\n//\n// This program is distributed in the hope that it will be useful,\n// but WITHOUT ANY WARRANTY; without even the implied warranty of\n// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n// GNU Affero General Public License for more details.\n//\n// You should have received a copy of the GNU Affero General Public License\n// along with this program. If not, see <http://www.gnu.org/licenses/>.\n\nuse std::collections::{HashMap, HashSet};\nuse std::sync::OnceLock;\nuse std::time::Duration;\n\nuse anyhow::Context;\nuse futures::future::try_join_all;\nuse itertools::Itertools;\nuse quickwit_common::pretty::PrettySample;\nuse quickwit_common::shared_consts;\nuse quickwit_common::uri::Uri;\nuse quickwit_config::build_doc_mapper;\nuse quickwit_doc_mapper::tag_pruning::extract_tags_from_query;\nuse quickwit_doc_mapper::DYNAMIC_FIELD_NAME;\nuse quickwit_metastore::{IndexMetadata, ListIndexesMetadataResponseExt, SplitMetadata};\nuse quickwit_proto::metastore::{\n    ListIndexesMetadataRequest, MetastoreService, MetastoreServiceClient,\n};\nuse quickwit_proto::search::{\n    FetchDocsRequest, FetchDocsResponse, Hit, LeafHit, LeafRequestRef, LeafSearchRequest,\n    LeafSearchResponse, PartialHit, SearchPlanResponse, SearchRequest, SearchResponse,\n    SnippetRequest, SortDatetimeFormat, SortField, SortValue, SplitIdAndFooterOffsets,\n};\nuse quickwit_proto::types::{IndexUid, SplitId};\nuse quickwit_query::query_ast::{\n    BoolQuery, QueryAst, QueryAstVisitor, RangeQuery, TermQuery, TermSetQuery,\n};\nuse serde::{Deserialize, Serialize};\nuse tantivy::aggregation::agg_result::AggregationResults;\nuse tantivy::aggregation::intermediate_agg_result::IntermediateAggregationResults;\nuse tantivy::collector::Collector;\nuse tantivy::schema::{FieldEntry, FieldType, Schema};\nuse tantivy::TantivyError;\nuse tracing::{debug, error, info, info_span, instrument};\n\nuse crate::cluster_client::ClusterClient;\nuse crate::collector::{make_merge_collector, QuickwitAggregations};\nuse crate::find_trace_ids_collector::Span;\nuse crate::scroll_context::{ScrollContext, ScrollKeyAndStartOffset};\nuse crate::search_job_placer::{group_by, group_jobs_by_index_id, Job};\nuse crate::search_response_rest::StorageRequestCount;\nuse crate::service::SearcherContext;\nuse crate::{\n    extract_split_and_footer_offsets, list_relevant_splits, SearchError, SearchJobPlacer,\n    SearchPlanResponseRest, SearchServiceClient,\n};\n\n/// Maximum accepted scroll TTL.\nfn max_scroll_ttl() -> Duration {\n    static MAX_SCROLL_TTL_LOCK: OnceLock<Duration> = OnceLock::new();\n    *MAX_SCROLL_TTL_LOCK.get_or_init(|| {\n        let split_deletion_grace_period = shared_consts::split_deletion_grace_period();\n        assert!(\n            split_deletion_grace_period >= shared_consts::MINIMUM_DELETION_GRACE_PERIOD,\n            \"The split deletion grace period is too short ({split_deletion_grace_period:?}). This \\\n             should not happen.\"\n        );\n        // We remove an extra margin of 2minutes from the split deletion grace period.\n        split_deletion_grace_period - Duration::from_secs(60 * 2)\n    })\n}\n\nconst SORT_DOC_FIELD_NAMES: &[&str] = &[\"_shard_doc\", \"_doc\"];\n\n/// SearchJob to be assigned to search clients by the [`SearchJobPlacer`].\n#[derive(Debug, Clone, PartialEq)]\npub struct SearchJob {\n    /// The index UID.\n    pub index_uid: IndexUid,\n    cost: usize,\n    /// The split ID and footer offsets of the split.\n    pub offsets: SplitIdAndFooterOffsets,\n}\n\nimpl SearchJob {\n    #[cfg(test)]\n    pub fn for_test(split_id: &str, cost: usize) -> SearchJob {\n        use std::str::FromStr;\n        SearchJob {\n            index_uid: IndexUid::from_str(\"test-index:00000000000000000000000000\").unwrap(),\n            cost,\n            offsets: SplitIdAndFooterOffsets {\n                split_id: split_id.to_string(),\n                ..Default::default()\n            },\n        }\n    }\n}\n\nimpl From<SearchJob> for SplitIdAndFooterOffsets {\n    fn from(search_job: SearchJob) -> Self {\n        search_job.offsets\n    }\n}\n\nimpl<'a> From<&'a SplitMetadata> for SearchJob {\n    fn from(split_metadata: &'a SplitMetadata) -> Self {\n        SearchJob {\n            index_uid: split_metadata.index_uid.clone(),\n            cost: compute_split_cost(split_metadata),\n            offsets: extract_split_and_footer_offsets(split_metadata),\n        }\n    }\n}\n\nimpl Job for SearchJob {\n    fn split_id(&self) -> &str {\n        &self.offsets.split_id\n    }\n\n    fn cost(&self) -> usize {\n        self.cost\n    }\n}\n\npub struct FetchDocsJob {\n    index_uid: IndexUid,\n    offsets: SplitIdAndFooterOffsets,\n    pub partial_hits: Vec<PartialHit>,\n}\n\nimpl Job for FetchDocsJob {\n    fn split_id(&self) -> &str {\n        &self.offsets.split_id\n    }\n\n    fn cost(&self) -> usize {\n        self.partial_hits.len()\n    }\n}\n\nimpl From<FetchDocsJob> for SplitIdAndFooterOffsets {\n    fn from(fetch_docs_job: FetchDocsJob) -> SplitIdAndFooterOffsets {\n        fetch_docs_job.offsets\n    }\n}\n\n/// Index metas needed for executing a leaf search request.\n#[derive(Serialize, Deserialize, Clone, Debug)]\npub struct IndexMetasForLeafSearch {\n    /// Index URI.\n    pub index_uri: Uri,\n    /// Doc mapper json string.\n    pub doc_mapper_str: String,\n}\n\npub(crate) type IndexesMetasForLeafSearch = HashMap<IndexUid, IndexMetasForLeafSearch>;\n\n#[derive(Debug)]\nstruct RequestMetadata {\n    timestamp_field_opt: Option<String>,\n    query_ast_resolved: QueryAst,\n    indexes_meta_for_leaf_search: IndexesMetasForLeafSearch,\n    sort_fields_is_datetime: HashMap<String, bool>,\n}\n\n/// Validates request against each index's doc mapper and ensures that:\n/// - timestamp fields (if any) are equal across indexes.\n/// - resolved query ASTs are the same across indexes.\n/// - if a sort field is of type datetime, it must be a datetime field on all indexes. This\n///   constraint come from the need to support datetime formatting on sort values.\n/// Returns the timestamp field, the resolved query AST and the indexes metadatas\n/// needed for leaf search requests.\n/// Note: the requirements on timestamp fields and resolved query ASTs can be lifted\n/// but it adds complexity that does not seem needed right now.\nfn validate_request_and_build_metadata(\n    indexes_metadata: &[IndexMetadata],\n    search_request: &SearchRequest,\n) -> crate::Result<RequestMetadata> {\n    validate_sort_by_fields_and_search_after(\n        &search_request.sort_fields,\n        &search_request.search_after,\n    )?;\n    let query_ast: QueryAst = serde_json::from_str(&search_request.query_ast)\n        .map_err(|err| SearchError::InvalidQuery(err.to_string()))?;\n    let mut indexes_meta_for_leaf_search: HashMap<IndexUid, IndexMetasForLeafSearch> =\n        HashMap::new();\n    let mut query_ast_resolved_opt: Option<QueryAst> = None;\n    let mut timestamp_field_opt: Option<String> = None;\n    let mut sort_fields_is_datetime: HashMap<String, bool> = HashMap::new();\n\n    for index_metadata in indexes_metadata {\n        let doc_mapper = build_doc_mapper(\n            &index_metadata.index_config.doc_mapping,\n            &index_metadata.index_config.search_settings,\n        )\n        .map_err(|err| {\n            SearchError::Internal(format!(\"failed to build doc mapper. cause: {err}\"))\n        })?;\n        let query_ast_resolved_for_index = query_ast\n            .clone()\n            .parse_user_query(doc_mapper.default_search_fields())\n            // We convert the error to return a 400 to the user (and not a 500).\n            .map_err(|err| SearchError::InvalidQuery(err.to_string()))?;\n\n        // Validate uniqueness of resolved query AST.\n        if let Some(query_ast_resolved) = &query_ast_resolved_opt {\n            if query_ast_resolved != &query_ast_resolved_for_index {\n                return Err(SearchError::InvalidQuery(\n                    \"resolved query ASTs must be the same across indexes. resolving queries with \\\n                     different default fields are different between indexes is not supported\"\n                        .to_string(),\n                ));\n            }\n        } else {\n            query_ast_resolved_opt = Some(query_ast_resolved_for_index.clone());\n        }\n\n        // Validate uniqueness of timestamp field if any.\n        if let Some(timestamp_field_for_index) = doc_mapper.timestamp_field_name() {\n            match timestamp_field_opt {\n                Some(timestamp_field) if timestamp_field != timestamp_field_for_index => {\n                    return Err(SearchError::InvalidQuery(\n                        \"the timestamp field (if present) must be the same for all indexes\"\n                            .to_string(),\n                    ));\n                }\n                None => {\n                    timestamp_field_opt = Some(timestamp_field_for_index.to_string());\n                }\n                _ => {}\n            }\n        }\n\n        // Validate request against the current index schema.\n        let schema = doc_mapper.schema();\n        validate_request(&schema, &doc_mapper.timestamp_field_name(), search_request)?;\n\n        validate_sort_field_types(\n            &schema,\n            &search_request.sort_fields,\n            &mut sort_fields_is_datetime,\n        )?;\n\n        // Validates the query by effectively building it against the current schema.\n        doc_mapper.query(doc_mapper.schema(), &query_ast_resolved_for_index, true)?;\n\n        let index_metadata_for_leaf_search = IndexMetasForLeafSearch {\n            index_uri: index_metadata.index_uri().clone(),\n            doc_mapper_str: serde_json::to_string(&doc_mapper).map_err(|err| {\n                SearchError::Internal(format!(\"failed to serialize doc mapper. cause: {err}\"))\n            })?,\n        };\n        indexes_meta_for_leaf_search.insert(\n            index_metadata.index_uid.clone(),\n            index_metadata_for_leaf_search,\n        );\n    }\n\n    let query_ast_resolved = query_ast_resolved_opt.ok_or_else(|| {\n        SearchError::Internal(\n            \"resolved query AST must be present. this should never happen\".to_string(),\n        )\n    })?;\n\n    Ok(RequestMetadata {\n        timestamp_field_opt,\n        query_ast_resolved,\n        indexes_meta_for_leaf_search,\n        sort_fields_is_datetime,\n    })\n}\n\n/// Validate sort field types.\nfn validate_sort_field_types(\n    schema: &Schema,\n    sort_fields: &[SortField],\n    sort_field_is_datetime: &mut HashMap<String, bool>,\n) -> crate::Result<()> {\n    for sort_field in sort_fields.iter() {\n        if let Some(sort_field_entry) = get_sort_by_field_entry(&sort_field.field_name, schema)? {\n            validate_sort_by_field_type(\n                sort_field_entry,\n                sort_field.sort_datetime_format.is_some(),\n            )?;\n            // If sort field type is a date, ensure it's true for all indexes.\n            if let Some(is_datetime) = sort_field_is_datetime.get(&sort_field.field_name) {\n                if *is_datetime != sort_field_entry.field_type().is_date() {\n                    return Err(SearchError::InvalidQuery(format!(\n                        \"sort datetime field `{}` must be of type datetime on all indexes\",\n                        sort_field_entry.name(),\n                    )));\n                }\n            } else {\n                sort_field_is_datetime.insert(\n                    sort_field.field_name.to_string(),\n                    sort_field_entry.field_type().is_date(),\n                );\n            }\n        } else {\n            sort_field_is_datetime.insert(sort_field.field_name.to_string(), false);\n        }\n    }\n    Ok(())\n}\n\nfn validate_requested_snippet_fields(\n    schema: &Schema,\n    snippet_fields: &[String],\n) -> anyhow::Result<()> {\n    for field_name in snippet_fields {\n        let field_entry = schema\n            .get_field(field_name)\n            .map(|field| schema.get_field_entry(field))?;\n        match field_entry.field_type() {\n            FieldType::Str(text_options) => {\n                if !text_options.is_stored() {\n                    return Err(anyhow::anyhow!(\n                        \"the snippet field `{}` must be stored\",\n                        field_name\n                    ));\n                }\n            }\n            other => {\n                return Err(anyhow::anyhow!(\n                    \"the snippet field `{}` must be of type `Str`, got `{}`\",\n                    field_name,\n                    other.value_type().name()\n                ))\n            }\n        }\n    }\n    Ok(())\n}\n\nfn simplify_search_request_for_scroll_api(req: &SearchRequest) -> crate::Result<SearchRequest> {\n    if req.search_after.is_some() {\n        return Err(SearchError::InvalidArgument(\n            \"search_after cannot be used in a scroll context\".to_string(),\n        ));\n    }\n\n    // We do not mutate\n    Ok(SearchRequest {\n        index_id_patterns: req.index_id_patterns.clone(),\n        query_ast: req.query_ast.clone(),\n        start_timestamp: req.start_timestamp,\n        end_timestamp: req.end_timestamp,\n        max_hits: req.max_hits,\n        start_offset: req.start_offset,\n        sort_fields: req.sort_fields.clone(),\n        // We remove all aggregation request.\n        // The aggregation will not be computed for each scroll request.\n        aggregation_request: None,\n        // We remove the snippet fields. This feature is not supported for scroll requests.\n        snippet_fields: Vec::new(),\n        // We remove the scroll ttl parameter. It is irrelevant to process later request\n        scroll_ttl_secs: None,\n        search_after: None,\n        // request is simplified after initial query, and we cache the hit count, so we don't need\n        // to recompute it afterward.\n        count_hits: quickwit_proto::search::CountHits::Underestimate as i32,\n    })\n}\n\n/// Validates sort fields and search after values.\n/// - validate sort fields length.\n/// - search after values must be set for all sort fields.\nfn validate_sort_by_fields_and_search_after(\n    sort_fields: &[SortField],\n    search_after: &Option<PartialHit>,\n) -> crate::Result<()> {\n    if sort_fields.is_empty() {\n        return Ok(());\n    }\n    if sort_fields.len() > 2 {\n        return Err(SearchError::InvalidArgument(format!(\n            \"sort by field must be up to 2 fields, got {}\",\n            sort_fields.len()\n        )));\n    }\n    let Some(search_after_partial_hit) = search_after.as_ref() else {\n        return Ok(());\n    };\n\n    let sort_fields_without_doc_count = sort_fields\n        .iter()\n        .filter(|sort_field| !SORT_DOC_FIELD_NAMES.contains(&sort_field.field_name.as_str()))\n        .count();\n    let has_doc_sort_field = sort_fields_without_doc_count != sort_fields.len();\n    if has_doc_sort_field && search_after_partial_hit.split_id.is_empty() {\n        return Err(SearchError::InvalidArgument(\n            \"search_after with a sort field `_doc` must define a split ID, segment ID and doc ID \\\n             values\"\n                .to_string(),\n        ));\n    }\n\n    let mut search_after_sort_value_count = 0;\n    // TODO: we could validate if the search after sort value types of consistent with the sort\n    // field types.\n    if let Some(sort_by_value) = search_after_partial_hit.sort_value.as_ref() {\n        sort_by_value.sort_value.context(\"sort value must be set\")?;\n        search_after_sort_value_count += 1;\n    }\n    if let Some(sort_by_value_2) = search_after_partial_hit.sort_value2.as_ref() {\n        sort_by_value_2\n            .sort_value\n            .context(\"sort value must be set\")?;\n        search_after_sort_value_count += 1;\n    }\n    if search_after_sort_value_count != sort_fields_without_doc_count {\n        return Err(SearchError::InvalidArgument(format!(\n            \"`search_after` must have the same number of sort values as sort by fields {:?}\",\n            sort_fields\n                .iter()\n                .map(|sort_field| &sort_field.field_name)\n                .collect_vec()\n        )));\n    }\n    Ok(())\n}\n\nfn get_sort_by_field_entry<'a>(\n    field_name: &str,\n    schema: &'a Schema,\n) -> crate::Result<Option<&'a FieldEntry>> {\n    if \"_score\" == field_name || SORT_DOC_FIELD_NAMES.contains(&field_name) {\n        return Ok(None);\n    }\n    let dynamic_field_opt = schema.get_field(DYNAMIC_FIELD_NAME).ok();\n    let (sort_by_field, _json_path) = schema\n        .find_field_with_default(field_name, dynamic_field_opt)\n        .ok_or_else(|| {\n            SearchError::InvalidArgument(format!(\"unknown field used in `sort by`: {field_name}\"))\n        })?;\n    let sort_by_field_entry = schema.get_field_entry(sort_by_field);\n    Ok(Some(sort_by_field_entry))\n}\n\n/// Validates sort field type.\nfn validate_sort_by_field_type(\n    sort_by_field_entry: &FieldEntry,\n    has_timestamp_format: bool,\n) -> crate::Result<()> {\n    let field_name = sort_by_field_entry.name();\n    if matches!(sort_by_field_entry.field_type(), FieldType::Str(_)) {\n        return Err(SearchError::InvalidArgument(format!(\n            \"sort by field on type text is currently not supported `{field_name}`\"\n        )));\n    }\n    if !sort_by_field_entry.is_fast() {\n        return Err(SearchError::InvalidArgument(format!(\n            \"sort by field must be a fast field, please add the fast property to your field \\\n             `{field_name}`\",\n        )));\n    }\n    if has_timestamp_format && !sort_by_field_entry.field_type().is_date() {\n        return Err(SearchError::InvalidArgument(format!(\n            \"sort by field with a timestamp format must be a datetime field and the field \\\n             `{field_name}` is not\",\n        )));\n    }\n    Ok(())\n}\n\nfn validate_request(\n    schema: &Schema,\n    timestamp_field_name: &Option<&str>,\n    search_request: &SearchRequest,\n) -> crate::Result<()> {\n    if timestamp_field_name.is_none()\n        && (search_request.start_timestamp.is_some() || search_request.end_timestamp.is_some())\n    {\n        return Err(SearchError::InvalidQuery(format!(\n            \"the timestamp field is not set in index: {:?} definition but start-timestamp or \\\n             end-timestamp are set in the query\",\n            search_request.index_id_patterns\n        )));\n    }\n\n    validate_requested_snippet_fields(schema, &search_request.snippet_fields)?;\n\n    if let Some(agg) = search_request.aggregation_request.as_ref() {\n        let _aggs: QuickwitAggregations = serde_json::from_str(agg).map_err(|_err| {\n            let err = serde_json::from_str::<tantivy::aggregation::agg_req::Aggregations>(agg)\n                .unwrap_err();\n            SearchError::InvalidAggregationRequest(err.to_string())\n        })?;\n    };\n\n    if search_request.start_offset > 10_000 {\n        return Err(SearchError::InvalidArgument(format!(\n            \"max value for start_offset is 10_000, but got {}\",\n            search_request.start_offset\n        )));\n    }\n\n    if search_request.max_hits > 10_000 {\n        return Err(SearchError::InvalidArgument(format!(\n            \"max value for max_hits is 10_000, but got {}\",\n            search_request.max_hits\n        )));\n    }\n\n    Ok(())\n}\n\nfn get_scroll_ttl_duration(search_request: &SearchRequest) -> crate::Result<Option<Duration>> {\n    let Some(scroll_ttl_secs) = search_request.scroll_ttl_secs else {\n        return Ok(None);\n    };\n    let scroll_ttl: Duration = Duration::from_secs(scroll_ttl_secs as u64);\n    let max_scroll_ttl = max_scroll_ttl();\n    if scroll_ttl > max_scroll_ttl {\n        return Err(SearchError::InvalidArgument(format!(\n            \"Quickwit only supports scroll TTL period up to {} secs\",\n            max_scroll_ttl.as_secs()\n        )));\n    }\n    Ok(Some(scroll_ttl))\n}\n\n#[instrument(level = \"debug\", skip_all)]\nasync fn search_partial_hits_phase_with_scroll(\n    searcher_context: &SearcherContext,\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    mut search_request: SearchRequest,\n    split_metadatas: &[SplitMetadata],\n    cluster_client: &ClusterClient,\n) -> crate::Result<(LeafSearchResponse, Option<ScrollKeyAndStartOffset>)> {\n    let scroll_ttl_opt = get_scroll_ttl_duration(&search_request)?;\n\n    if let Some(scroll_ttl) = scroll_ttl_opt {\n        let max_hits = search_request.max_hits;\n        // This is a scroll request.\n        //\n        // We increase max hits to add populate the scroll cache.\n        search_request.max_hits = search_request\n            .max_hits\n            .max(shared_consts::SCROLL_BATCH_LEN as u64);\n        search_request.scroll_ttl_secs = None;\n        let mut leaf_search_resp = search_partial_hits_phase(\n            searcher_context,\n            indexes_metas_for_leaf_search,\n            &search_request,\n            split_metadatas,\n            cluster_client,\n        )\n        .await?;\n        let cached_partial_hits = leaf_search_resp.partial_hits.clone();\n        leaf_search_resp.partial_hits.truncate(max_hits as usize);\n        let last_hit = leaf_search_resp\n            .partial_hits\n            .last()\n            .cloned()\n            .unwrap_or_default();\n\n        let scroll_context_search_request =\n            simplify_search_request_for_scroll_api(&search_request)?;\n        let mut scroll_ctx = ScrollContext {\n            indexes_metas_for_leaf_search: indexes_metas_for_leaf_search.clone(),\n            split_metadatas: split_metadatas.to_vec(),\n            search_request: scroll_context_search_request,\n            total_num_hits: leaf_search_resp.num_hits,\n            max_hits_per_page: max_hits,\n            cached_partial_hits_start_offset: search_request.start_offset,\n            cached_partial_hits,\n        };\n        let scroll_key_and_start_offset: ScrollKeyAndStartOffset =\n            ScrollKeyAndStartOffset::new_with_start_offset(\n                scroll_ctx.search_request.start_offset,\n                max_hits as u32,\n                last_hit.clone(),\n            )\n            .next_page(leaf_search_resp.partial_hits.len() as u64, last_hit);\n\n        scroll_ctx.clear_cache_if_unneeded();\n        let payload: Vec<u8> = scroll_ctx.serialize();\n        let scroll_key = scroll_key_and_start_offset.scroll_key();\n        cluster_client\n            .put_kv(&scroll_key, &payload, scroll_ttl)\n            .await;\n        Ok((leaf_search_resp, Some(scroll_key_and_start_offset)))\n    } else {\n        let leaf_search_resp = search_partial_hits_phase(\n            searcher_context,\n            indexes_metas_for_leaf_search,\n            &search_request,\n            split_metadatas,\n            cluster_client,\n        )\n        .await?;\n        Ok((leaf_search_resp, None))\n    }\n}\n\n/// Check if the request is a count request without any filters, so we can just return the split\n/// metadata count.\n///\n/// This is done by exclusion, so we will need to keep it up to date if fields are added.\npub fn is_metadata_count_request(request: &SearchRequest) -> bool {\n    let query_ast: QueryAst = serde_json::from_str(&request.query_ast).unwrap();\n    is_metadata_count_request_with_ast(&query_ast, request)\n}\n\n/// Check if the request is a count request without any filters, so we can just return the split\n/// metadata count.\n///\n/// This is done by exclusion, so we will need to keep it up to date if fields are added.\n///\n/// The passed query_ast should match the serialized on in request.\npub fn is_metadata_count_request_with_ast(query_ast: &QueryAst, request: &SearchRequest) -> bool {\n    if query_ast != &QueryAst::MatchAll {\n        return false;\n    }\n    if request.max_hits != 0 {\n        return false;\n    }\n\n    // If the start and end timestamp encompass the whole split, it is still a count query.\n    // We remove this currently on the leaf level, but not yet on the root level.\n    // There's a small advantage when we would do this on the root level, since we have the\n    // counts available on the split. On the leaf it is currently required to open the split\n    // to get the count.\n    if request.start_timestamp.is_some() || request.end_timestamp.is_some() {\n        return false;\n    }\n    if request.aggregation_request.is_some() || !request.snippet_fields.is_empty() {\n        return false;\n    }\n    true\n}\n\n/// Get a leaf search response that returns the num_docs of the split\npub fn get_count_from_metadata(split_metadatas: &[SplitMetadata]) -> Vec<LeafSearchResponse> {\n    split_metadatas\n        .iter()\n        .map(|metadata| LeafSearchResponse {\n            num_hits: metadata.num_docs as u64,\n            partial_hits: Vec::new(),\n            failed_splits: Vec::new(),\n            num_attempted_splits: 1,\n            intermediate_aggregation_result: None,\n        })\n        .collect()\n}\n\n#[instrument(level = \"debug\", skip_all)]\npub(crate) async fn search_partial_hits_phase(\n    searcher_context: &SearcherContext,\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    search_request: &SearchRequest,\n    split_metadatas: &[SplitMetadata],\n    cluster_client: &ClusterClient,\n) -> crate::Result<LeafSearchResponse> {\n    let leaf_search_responses: Vec<LeafSearchResponse> =\n        if is_metadata_count_request(search_request) {\n            get_count_from_metadata(split_metadatas)\n        } else {\n            let jobs: Vec<SearchJob> = split_metadatas.iter().map(SearchJob::from).collect();\n            let assigned_leaf_search_jobs = cluster_client\n                .search_job_placer\n                .assign_jobs(jobs, &HashSet::default())\n                .await?;\n            let mut leaf_request_tasks = Vec::new();\n            for (client, client_jobs) in assigned_leaf_search_jobs {\n                let leaf_request = jobs_to_leaf_request(\n                    search_request,\n                    indexes_metas_for_leaf_search,\n                    client_jobs,\n                )?;\n                leaf_request_tasks.push(cluster_client.leaf_search(leaf_request, client.clone()));\n            }\n            try_join_all(leaf_request_tasks).await?\n        };\n\n    // Creates a collector which merges responses into one\n    let merge_collector =\n        make_merge_collector(search_request, &searcher_context.get_aggregation_limits())?;\n\n    // Merging is a cpu-bound task.\n    // It should be executed by Tokio's blocking threads.\n\n    // Wrap into result for merge_fruits\n    let leaf_search_responses: Vec<tantivy::Result<LeafSearchResponse>> =\n        leaf_search_responses.into_iter().map(Ok).collect_vec();\n    let span = info_span!(\"merge_fruits\");\n    let leaf_search_response = crate::search_thread_pool()\n        .run_cpu_intensive(move || {\n            let _span_guard = span.enter();\n            merge_collector.merge_fruits(leaf_search_responses)\n        })\n        .await\n        .context(\"failed to merge leaf search responses\")?\n        .map_err(|error: TantivyError| crate::SearchError::Internal(error.to_string()))?;\n    debug!(\n        num_hits = leaf_search_response.num_hits,\n        failed_splits = ?leaf_search_response.failed_splits,\n        num_attempted_splits = leaf_search_response.num_attempted_splits,\n        has_intermediate_aggregation_result = leaf_search_response.intermediate_aggregation_result.is_some(),\n        \"Merged leaf search response.\"\n    );\n    if !leaf_search_response.failed_splits.is_empty() {\n        error!(failed_splits = ?leaf_search_response.failed_splits, \"leaf search response contains at least one failed split\");\n        let errors: String = leaf_search_response.failed_splits.iter().join(\", \");\n        return Err(SearchError::Internal(errors));\n    }\n    Ok(leaf_search_response)\n}\n\npub(crate) fn get_snippet_request(search_request: &SearchRequest) -> Option<SnippetRequest> {\n    if search_request.snippet_fields.is_empty() {\n        return None;\n    }\n    Some(SnippetRequest {\n        snippet_fields: search_request.snippet_fields.clone(),\n        query_ast_resolved: search_request.query_ast.clone(),\n    })\n}\n\n#[instrument(skip_all, fields(partial_hits_num=partial_hits.len()))]\npub(crate) async fn fetch_docs_phase(\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    partial_hits: &[PartialHit],\n    split_metadatas: &[SplitMetadata],\n    search_request: &SearchRequest,\n    cluster_client: &ClusterClient,\n) -> crate::Result<Vec<Hit>> {\n    let snippet_request: Option<SnippetRequest> = get_snippet_request(search_request);\n    let hit_order: HashMap<(String, u32, u32), usize> = partial_hits\n        .iter()\n        .enumerate()\n        .map(|(position, partial_hit)| {\n            let key = (\n                partial_hit.split_id.clone(),\n                partial_hit.segment_ord,\n                partial_hit.doc_id,\n            );\n            (key, position)\n        })\n        .collect();\n\n    let assigned_fetch_docs_jobs = assign_client_fetch_docs_jobs(\n        partial_hits,\n        split_metadatas,\n        &cluster_client.search_job_placer,\n    )\n    .await?;\n\n    let mut fetch_docs_tasks = Vec::new();\n    for (client, client_jobs) in assigned_fetch_docs_jobs {\n        let fetch_jobs_requests = jobs_to_fetch_docs_requests(\n            snippet_request.clone(),\n            indexes_metas_for_leaf_search,\n            client_jobs,\n        )?;\n        for fetch_docs_request in fetch_jobs_requests {\n            fetch_docs_tasks.push(cluster_client.fetch_docs(fetch_docs_request, client.clone()));\n        }\n    }\n    let fetch_docs_responses: Vec<FetchDocsResponse> = try_join_all(fetch_docs_tasks).await?;\n\n    // Merge the fetched docs.\n    let leaf_hits = fetch_docs_responses\n        .into_iter()\n        .flat_map(|response| response.hits.into_iter());\n\n    // Build map of Split ID > index ID to add the index ID to the hits.\n    // Used for ES compatibility.\n    let split_id_to_index_id_map: HashMap<&SplitId, &str> = split_metadatas\n        .iter()\n        .map(|split_metadata| {\n            (\n                &split_metadata.split_id,\n                split_metadata.index_uid.index_id.as_str(),\n            )\n        })\n        .collect();\n    let mut sort_field_iter = search_request.sort_fields.iter();\n    let sort_field_1_datetime_format_opt: Option<SortDatetimeFormat> =\n        get_sort_field_datetime_format(sort_field_iter.next())?;\n    let sort_field_2_datetime_format_opt: Option<SortDatetimeFormat> =\n        get_sort_field_datetime_format(sort_field_iter.next())?;\n    let mut hits_with_position: Vec<(usize, Hit)> = leaf_hits\n        .map(|leaf_hit| {\n            build_hit_with_position(\n                leaf_hit,\n                &split_id_to_index_id_map,\n                &hit_order,\n                &sort_field_1_datetime_format_opt,\n                &sort_field_2_datetime_format_opt,\n            )\n        })\n        .try_collect()?;\n\n    hits_with_position.sort_by_key(|(position, _)| *position);\n    let hits: Vec<Hit> = hits_with_position\n        .into_iter()\n        .map(|(_position, hit)| hit)\n        .collect();\n\n    Ok(hits)\n}\n\nfn build_hit_with_position(\n    mut leaf_hit: LeafHit,\n    split_id_to_index_id_map: &HashMap<&SplitId, &str>,\n    hit_order: &HashMap<(String, u32, u32), usize>,\n    sort_field_1_datetime_format_opt: &Option<SortDatetimeFormat>,\n    sort_field_2_datetime_format_opt: &Option<SortDatetimeFormat>,\n) -> crate::Result<(usize, Hit)> {\n    let partial_hit_ref = leaf_hit\n        .partial_hit\n        .as_mut()\n        .expect(\"partial hit must be present\");\n    let key = (\n        partial_hit_ref.split_id.clone(),\n        partial_hit_ref.segment_ord,\n        partial_hit_ref.doc_id,\n    );\n    let sort_value_opt = partial_hit_ref\n        .sort_value\n        .as_mut()\n        .and_then(|sort_field| sort_field.sort_value.as_mut());\n    if let Some(sort_by_value) = sort_value_opt {\n        if let Some(output_datetime_format) = &sort_field_1_datetime_format_opt {\n            convert_sort_datetime_value(sort_by_value, *output_datetime_format)?;\n        }\n    }\n    let sort_value_2_opt = partial_hit_ref\n        .sort_value2\n        .as_mut()\n        .and_then(|sort_field| sort_field.sort_value.as_mut());\n    if let Some(sort_by_value) = sort_value_2_opt {\n        if let Some(output_datetime_format) = &sort_field_2_datetime_format_opt {\n            convert_sort_datetime_value(sort_by_value, *output_datetime_format)?;\n        }\n    }\n    let position = *hit_order.get(&key).expect(\"hit order must be present\");\n    let index_id = split_id_to_index_id_map\n        .get(&partial_hit_ref.split_id)\n        .map(|split_id| split_id.to_string())\n        .unwrap_or_default();\n\n    Result::<(usize, Hit), SearchError>::Ok((\n        position,\n        Hit {\n            json: leaf_hit.leaf_json,\n            partial_hit: leaf_hit.partial_hit,\n            snippet: leaf_hit.leaf_snippet_json,\n            index_id,\n        },\n    ))\n}\n\nfn get_sort_field_datetime_format(\n    sort_field: Option<&SortField>,\n) -> crate::Result<Option<SortDatetimeFormat>> {\n    if let Some(sort_field) = sort_field {\n        if let Some(sort_field_datetime_format_int) = &sort_field.sort_datetime_format {\n            let sort_field_datetime_format =\n                SortDatetimeFormat::from_i32(*sort_field_datetime_format_int)\n                    .context(\"invalid sort datetime format\")?;\n            return Ok(Some(sort_field_datetime_format));\n        }\n    }\n    Ok(None)\n}\n\n/// Performs a distributed search.\n/// 1. Sends leaf request over gRPC to multiple leaf nodes.\n/// 2. Merges the search results.\n/// 3. Sends fetch docs requests to multiple leaf nodes.\n/// 4. Builds the response with docs and returns.\n#[instrument(skip_all, fields(num_splits=%split_metadatas.len()))]\nasync fn root_search_aux(\n    searcher_context: &SearcherContext,\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    search_request: SearchRequest,\n    split_metadatas: Vec<SplitMetadata>,\n    cluster_client: &ClusterClient,\n) -> crate::Result<SearchResponse> {\n    debug!(split_metadatas = ?PrettySample::new(&split_metadatas, 5));\n    let (first_phase_result, scroll_key_and_start_offset_opt): (\n        LeafSearchResponse,\n        Option<ScrollKeyAndStartOffset>,\n    ) = search_partial_hits_phase_with_scroll(\n        searcher_context,\n        indexes_metas_for_leaf_search,\n        search_request.clone(),\n        &split_metadatas[..],\n        cluster_client,\n    )\n    .await?;\n\n    let hits = fetch_docs_phase(\n        indexes_metas_for_leaf_search,\n        &first_phase_result.partial_hits,\n        &split_metadatas[..],\n        &search_request,\n        cluster_client,\n    )\n    .await?;\n\n    let mut aggregation_result_json_opt = finalize_aggregation_if_any(\n        &search_request,\n        first_phase_result.intermediate_aggregation_result,\n        searcher_context,\n    )?;\n    // In case there is no index, we don't want the response to contain any aggregation structure\n    if indexes_metas_for_leaf_search.is_empty() {\n        aggregation_result_json_opt = None;\n    }\n\n    Ok(SearchResponse {\n        aggregation: aggregation_result_json_opt,\n        num_hits: first_phase_result.num_hits,\n        hits,\n        elapsed_time_micros: 0u64,\n        errors: Vec::new(),\n        scroll_id: scroll_key_and_start_offset_opt\n            .as_ref()\n            .map(ToString::to_string),\n    })\n}\n\nfn finalize_aggregation(\n    intermediate_aggregation_result_bytes_opt: Option<Vec<u8>>,\n    aggregations: QuickwitAggregations,\n    searcher_context: &SearcherContext,\n) -> crate::Result<Option<String>> {\n    let merge_aggregation_result = match aggregations {\n        QuickwitAggregations::FindTraceIdsAggregation(_) => {\n            let Some(intermediate_aggregation_result_bytes) =\n                intermediate_aggregation_result_bytes_opt\n            else {\n                return Ok(None);\n            };\n            // The merge collector has already merged the intermediate results.\n            let aggs: Vec<Span> = postcard::from_bytes(&intermediate_aggregation_result_bytes)?;\n            serde_json::to_string(&aggs)?\n        }\n        QuickwitAggregations::TantivyAggregations(aggregations) => {\n            let intermediate_aggregation_results =\n                if let Some(intermediate_aggregation_result_bytes) =\n                    intermediate_aggregation_result_bytes_opt\n                {\n                    let intermediate_aggregation_results: IntermediateAggregationResults =\n                        postcard::from_bytes(&intermediate_aggregation_result_bytes)?;\n                    intermediate_aggregation_results\n                } else {\n                    // Default, to return correct structure\n                    Default::default()\n                };\n            let final_aggregation_results: AggregationResults = intermediate_aggregation_results\n                .into_final_result(aggregations, &searcher_context.get_aggregation_limits())?;\n            serde_json::to_string(&final_aggregation_results)?\n        }\n    };\n    Ok(Some(merge_aggregation_result))\n}\n\nfn finalize_aggregation_if_any(\n    search_request: &SearchRequest,\n    intermediate_aggregation_result_bytes_opt: Option<Vec<u8>>,\n    searcher_context: &SearcherContext,\n) -> crate::Result<Option<String>> {\n    let Some(aggregations_json) = search_request.aggregation_request.as_ref() else {\n        return Ok(None);\n    };\n    let aggregations: QuickwitAggregations = serde_json::from_str(aggregations_json)?;\n    let aggregation_result_json = finalize_aggregation(\n        intermediate_aggregation_result_bytes_opt,\n        aggregations,\n        searcher_context,\n    )?;\n    Ok(aggregation_result_json)\n}\n\n/// Checks that all of the index researched as found.\n///\n/// An index pattern (= containing a wildcard) not matching is not an error.\n/// A specific index id however must be found.\n///\n/// We put this check here and not in the metastore to make sure the logic is independent\n/// of the metastore implementation, and some different use cases could require different\n/// behaviors. This specification was principally motivated by #4042.\npub fn check_all_index_metadata_found(\n    index_metadatas: &[IndexMetadata],\n    index_id_patterns: &[String],\n) -> crate::Result<()> {\n    let mut index_ids: HashSet<&str> = index_id_patterns\n        .iter()\n        .map(|index_ptn| index_ptn.as_str())\n        .filter(|index_ptn| !index_ptn.contains('*') && !index_ptn.starts_with('-'))\n        .collect();\n\n    if index_ids.is_empty() {\n        // All of the patterns are wildcard patterns.\n        return Ok(());\n    }\n\n    for index_metadata in index_metadatas {\n        index_ids.remove(index_metadata.index_uid.index_id.as_str());\n    }\n\n    if !index_ids.is_empty() {\n        let missing_index_ids = index_ids\n            .into_iter()\n            .map(|missing_index_id| missing_index_id.to_string())\n            .collect();\n        return Err(SearchError::IndexesNotFound {\n            index_ids: missing_index_ids,\n        });\n    }\n\n    Ok(())\n}\n\n/// This function takes in the index metadatas and lists the relevant splits for the search request.\nasync fn refine_and_list_matches(\n    metastore: &mut MetastoreServiceClient,\n    search_request: &mut SearchRequest,\n    indexes_metadata: Vec<IndexMetadata>,\n    query_ast_resolved: QueryAst,\n    sort_fields_is_datetime: HashMap<String, bool>,\n    timestamp_field_opt: Option<String>,\n) -> crate::Result<Vec<SplitMetadata>> {\n    let index_uids = indexes_metadata\n        .iter()\n        .map(|index_metadata| index_metadata.index_uid.clone())\n        .collect_vec();\n    search_request.query_ast = serde_json::to_string(&query_ast_resolved)?;\n\n    // convert search_after datetime values from input datetime format to nanos.\n    convert_search_after_datetime_values(search_request, &sort_fields_is_datetime)?;\n\n    // update_search_after_datetime_in_nanos(&mut search_request)?;\n    if let Some(timestamp_field) = &timestamp_field_opt {\n        refine_start_end_timestamp_from_ast(\n            &query_ast_resolved,\n            timestamp_field,\n            &mut search_request.start_timestamp,\n            &mut search_request.end_timestamp,\n        );\n    }\n    let tag_filter_ast = extract_tags_from_query(query_ast_resolved);\n\n    // TODO if search after is set, we sort by timestamp and we don't want to count all results,\n    // we can refine more here. Same if we sort by _shard_doc\n    let split_metadatas: Vec<SplitMetadata> = list_relevant_splits(\n        index_uids,\n        search_request.start_timestamp,\n        search_request.end_timestamp,\n        tag_filter_ast,\n        metastore,\n    )\n    .await?;\n    Ok(split_metadatas)\n}\n\n/// Performs a distributed search.\n/// 1. Sends leaf request over gRPC to multiple leaf nodes.\n/// 2. Merges the search results.\n/// 3. Sends fetch docs requests to multiple leaf nodes.\n/// 4. Builds the response with docs and returns.\n#[instrument(skip_all)]\npub async fn root_search(\n    // contains split footer cache\n    searcher_context: &SearcherContext,\n    // search request will contains timestamps and tags to prune splits\n    mut search_request: SearchRequest,\n    // metastore client\n    mut metastore: MetastoreServiceClient,\n    // cluster client to communicate between nodes\n    cluster_client: &ClusterClient,\n) -> crate::Result<SearchResponse> {\n    info!(searcher_context = ?searcher_context, search_request = ?search_request);\n    let start_instant = tokio::time::Instant::now();\n    let list_indexes_metadatas_request = ListIndexesMetadataRequest {\n        index_id_patterns: search_request.index_id_patterns.clone(),\n    };\n    let indexes_metadata: Vec<IndexMetadata> = metastore\n        // codegen will generate the correct method call\n        // this will fetch the index metadata from the metastore\n        .list_indexes_metadata(list_indexes_metadatas_request)\n        .await?\n        .deserialize_indexes_metadata()\n        .await?;\n\n    check_all_index_metadata_found(&indexes_metadata[..], &search_request.index_id_patterns[..])?;\n\n    if indexes_metadata.is_empty() {\n        // We go through root_search_aux instead of directly\n        // returning an empty response to make sure we generate\n        // a (pretty useless) scroll id if requested.\n        let mut search_response = root_search_aux(\n            searcher_context,\n            &HashMap::default(),\n            search_request,\n            Vec::new(),\n            cluster_client,\n        )\n        .await?;\n        search_response.elapsed_time_micros = start_instant.elapsed().as_micros() as u64;\n        return Ok(search_response);\n    }\n\n    let request_metadata = validate_request_and_build_metadata(&indexes_metadata, &search_request)?;\n    let split_metadatas = refine_and_list_matches(\n        &mut metastore,\n        &mut search_request,\n        indexes_metadata,\n        request_metadata.query_ast_resolved,\n        request_metadata.sort_fields_is_datetime,\n        request_metadata.timestamp_field_opt,\n    )\n    .await?;\n\n    let mut search_response = root_search_aux(\n        searcher_context,\n        &request_metadata.indexes_meta_for_leaf_search,\n        search_request,\n        split_metadatas,\n        cluster_client,\n    )\n    .await?;\n\n    search_response.elapsed_time_micros = start_instant.elapsed().as_micros() as u64;\n    Ok(search_response)\n}\n\n/// Returns details on how a query would be executed\npub async fn search_plan(\n    mut search_request: SearchRequest,\n    mut metastore: MetastoreServiceClient,\n) -> crate::Result<SearchPlanResponse> {\n    let list_indexes_metadatas_request = ListIndexesMetadataRequest {\n        index_id_patterns: search_request.index_id_patterns.clone(),\n    };\n    let indexes_metadata: Vec<IndexMetadata> = metastore\n        .list_indexes_metadata(list_indexes_metadatas_request)\n        .await?\n        .deserialize_indexes_metadata()\n        .await?;\n\n    check_all_index_metadata_found(&indexes_metadata[..], &search_request.index_id_patterns[..])?;\n    if indexes_metadata.is_empty() {\n        return Ok(SearchPlanResponse {\n            result: serde_json::to_string(&SearchPlanResponseRest {\n                quickwit_ast: QueryAst::MatchAll,\n                tantivy_ast: String::new(),\n                searched_splits: Vec::new(),\n                storage_requests: StorageRequestCount::default(),\n            })?,\n        });\n    }\n    let doc_mapper = build_doc_mapper(\n        &indexes_metadata[0].index_config.doc_mapping,\n        &indexes_metadata[0].index_config.search_settings,\n    )\n    .map_err(|err| SearchError::Internal(format!(\"failed to build doc mapper. cause: {err}\")))?;\n\n    let request_metadata = validate_request_and_build_metadata(&indexes_metadata, &search_request)?;\n    let split_metadatas = refine_and_list_matches(\n        &mut metastore,\n        &mut search_request,\n        indexes_metadata,\n        request_metadata.query_ast_resolved.clone(),\n        request_metadata.sort_fields_is_datetime,\n        request_metadata.timestamp_field_opt,\n    )\n    .await?;\n\n    let (query, mut warmup_info) = doc_mapper.query(\n        doc_mapper.schema(),\n        &request_metadata.query_ast_resolved,\n        true,\n    )?;\n    let merge_collector = make_merge_collector(&search_request, &Default::default())?;\n    warmup_info.merge(merge_collector.warmup_info());\n    warmup_info.simplify();\n\n    let split_ids = split_metadatas\n        .into_iter()\n        .map(|split| format!(\"{}/{}\", split.index_uid.index_id, split.split_id))\n        .collect();\n    // this is an upper bound, we'd need access to a hotdir for more precise results\n    let fieldnorm_query_count = if warmup_info.field_norms {\n        doc_mapper\n            .schema()\n            .fields()\n            .filter(|(_, entry)| entry.has_fieldnorms())\n            .count()\n    } else {\n        0\n    };\n    let sstable_query_count = warmup_info.term_dict_fields.len()\n        + warmup_info\n            .terms_grouped_by_field\n            .values()\n            .map(|terms: &HashMap<tantivy::Term, bool>| terms.len())\n            .sum::<usize>()\n        + warmup_info\n            .term_ranges_grouped_by_field\n            .values()\n            .map(|terms: &HashMap<_, bool>| terms.len())\n            .sum::<usize>();\n    let position_query_count = warmup_info\n        .terms_grouped_by_field\n        .values()\n        .map(|terms: &HashMap<tantivy::Term, bool>| {\n            terms\n                .values()\n                .filter(|load_position| **load_position)\n                .count()\n        })\n        .sum::<usize>()\n        + warmup_info\n            .term_ranges_grouped_by_field\n            .values()\n            .map(|terms: &HashMap<_, bool>| {\n                terms\n                    .values()\n                    .filter(|load_position| **load_position)\n                    .count()\n            })\n            .sum::<usize>();\n    Ok(SearchPlanResponse {\n        result: serde_json::to_string(&SearchPlanResponseRest {\n            quickwit_ast: request_metadata.query_ast_resolved,\n            tantivy_ast: format!(\"{query:#?}\"),\n            searched_splits: split_ids,\n            storage_requests: StorageRequestCount {\n                footer: 1,\n                fastfield: warmup_info.fast_field_names.len(),\n                fieldnorm: fieldnorm_query_count,\n                sstable: sstable_query_count,\n                posting: sstable_query_count,\n                position: position_query_count,\n            },\n        })?,\n    })\n}\n\n/// Converts search after with datetime format to nanoseconds (representation in tantivy).\n/// If the sort field is a datetime field and no datetime format is set, the default format is\n/// milliseconds.\n/// `sort_fields_are_datetime_opt` must be of the same length as `search_request.sort_fields`.\nfn convert_search_after_datetime_values(\n    search_request: &mut SearchRequest,\n    sort_fields_is_datetime: &HashMap<String, bool>,\n) -> crate::Result<()> {\n    for sort_field in search_request.sort_fields.iter_mut() {\n        if *sort_fields_is_datetime\n            .get(&sort_field.field_name)\n            .unwrap_or(&false)\n            && sort_field.sort_datetime_format.is_none()\n        {\n            sort_field.sort_datetime_format = Some(SortDatetimeFormat::UnixTimestampMillis as i32);\n        }\n    }\n    if let Some(partial_hit) = search_request.search_after.as_mut() {\n        let search_after_values = [\n            partial_hit.sort_value.as_mut(),\n            partial_hit.sort_value2.as_mut(),\n        ];\n        for (sort_field, search_after_value_opt) in\n            search_request.sort_fields.iter().zip(search_after_values)\n        {\n            let Some(search_after_sort_by_value) = search_after_value_opt else {\n                continue;\n            };\n            let Some(search_after_sort_value) = search_after_sort_by_value.sort_value.as_mut()\n            else {\n                continue;\n            };\n            let Some(datetime_format_int) = sort_field.sort_datetime_format else {\n                continue;\n            };\n            let input_datetime_format = SortDatetimeFormat::from_i32(datetime_format_int)\n                .context(\"invalid sort datetime format\")?;\n            convert_sort_datetime_value_into_nanos(search_after_sort_value, input_datetime_format)?;\n        }\n    }\n    Ok(())\n}\n\n/// Convert sort values from input datetime format into nanoseconds.\n/// The conversion is done only for U64 and I64 sort values, an error is returned for other types.\nfn convert_sort_datetime_value_into_nanos(\n    sort_value: &mut SortValue,\n    input_format: SortDatetimeFormat,\n) -> crate::Result<()> {\n    match sort_value {\n        SortValue::U64(value) => match input_format {\n            SortDatetimeFormat::UnixTimestampMillis => {\n                *value = value.checked_mul(1_000_000).ok_or_else(|| {\n                    SearchError::Internal(format!(\n                        \"sort value defined in milliseconds is too large and cannot be converted \\\n                         into nanoseconds: {}\",\n                        value\n                    ))\n                })?;\n            }\n            SortDatetimeFormat::UnixTimestampNanos => {\n                // Nothing to do as the internal format is nanos.\n            }\n        },\n        SortValue::I64(value) => match input_format {\n            SortDatetimeFormat::UnixTimestampMillis => {\n                *value = value.checked_mul(1_000_000).ok_or_else(|| {\n                    SearchError::Internal(format!(\n                        \"sort value defined in milliseconds is too large and cannot be converted \\\n                         into nanoseconds: {}\",\n                        value\n                    ))\n                })?;\n            }\n            SortDatetimeFormat::UnixTimestampNanos => {\n                // Nothing to do as the internal format is nanos.\n            }\n        },\n        _ => {\n            return Err(SearchError::Internal(format!(\n                \"datetime conversion are only support for u64 and i64 sort values, not `{:?}`\",\n                sort_value\n            )));\n        }\n    }\n    Ok(())\n}\n\n/// Convert sort values from nanoseconds to the requested output format.\n/// The conversion is done only for U64 and I64 sort values, an error is returned for other types.\nfn convert_sort_datetime_value(\n    sort_value: &mut SortValue,\n    output_format: SortDatetimeFormat,\n) -> crate::Result<()> {\n    match sort_value {\n        SortValue::U64(value) => match output_format {\n            SortDatetimeFormat::UnixTimestampMillis => {\n                *value /= 1_000_000;\n            }\n            SortDatetimeFormat::UnixTimestampNanos => {\n                // Nothing todo as the internal format is in nanos.\n            }\n        },\n        SortValue::I64(value) => match output_format {\n            SortDatetimeFormat::UnixTimestampMillis => {\n                *value /= 1_000_000;\n            }\n            SortDatetimeFormat::UnixTimestampNanos => {\n                // Nothing todo as the internal format is in nanos.\n            }\n        },\n        _ => {\n            return Err(SearchError::Internal(format!(\n                \"datetime conversion are only support for u64 and i64 sort values, not `{:?}`\",\n                sort_value\n            )));\n        }\n    }\n    Ok(())\n}\n\npub(crate) fn refine_start_end_timestamp_from_ast(\n    query_ast: &QueryAst,\n    timestamp_field: &str,\n    start_timestamp: &mut Option<i64>,\n    end_timestamp: &mut Option<i64>,\n) {\n    let mut timestamp_range_extractor = ExtractTimestampRange {\n        timestamp_field,\n        start_timestamp: *start_timestamp,\n        end_timestamp: *end_timestamp,\n    };\n    timestamp_range_extractor\n        .visit(query_ast)\n        .expect(\"can't fail unwrapping Infallible\");\n    *start_timestamp = timestamp_range_extractor.start_timestamp;\n    *end_timestamp = timestamp_range_extractor.end_timestamp;\n}\n\n/// Boundaries identified as being implied by the QueryAst.\n///\n/// `start_timestamp` is to be interpreted as Inclusive (or Unbounded)\n/// `end_timestamp` is to be interpreted as Exclusive (or Unbounded)\n/// In other word, this is a `[start_timestamp..end_timestamp)` interval.\nstruct ExtractTimestampRange<'a> {\n    timestamp_field: &'a str,\n    start_timestamp: Option<i64>,\n    end_timestamp: Option<i64>,\n}\n\nimpl<'a> ExtractTimestampRange<'a> {\n    fn update_start_timestamp(\n        &mut self,\n        lower_bound: &quickwit_query::JsonLiteral,\n        included: bool,\n    ) {\n        use quickwit_query::InterpretUserInput;\n        let Some(lower_bound) = tantivy::DateTime::interpret_json(lower_bound) else {\n            return;\n        };\n        let mut lower_bound = lower_bound.into_timestamp_secs();\n        if !included {\n            // TODO saturating isn't exactly right, we should replace the RangeQuery with\n            // a match_none, but the visitor doesn't allow mutation.\n            lower_bound = lower_bound.saturating_add(1);\n        }\n        self.start_timestamp = Some(\n            self.start_timestamp\n                .map_or(lower_bound, |current| current.max(lower_bound)),\n        );\n    }\n\n    fn update_end_timestamp(&mut self, upper_bound: &quickwit_query::JsonLiteral, included: bool) {\n        use quickwit_query::InterpretUserInput;\n        let Some(upper_bound_timestamp) = tantivy::DateTime::interpret_json(upper_bound) else {\n            return;\n        };\n        let mut upper_bound = upper_bound_timestamp.into_timestamp_secs();\n        let round_up = (upper_bound_timestamp.into_timestamp_nanos() % 1_000_000_000) != 0;\n        if included || round_up {\n            // TODO saturating isn't exactly right, we should replace the RangeQuery with\n            // a match_none, but the visitor doesn't allow mutation.\n            upper_bound = upper_bound.saturating_add(1);\n        }\n        self.end_timestamp = Some(\n            self.end_timestamp\n                .map_or(upper_bound, |current| current.min(upper_bound)),\n        );\n    }\n}\n\nimpl<'a, 'b> QueryAstVisitor<'b> for ExtractTimestampRange<'a> {\n    type Err = std::convert::Infallible;\n\n    fn visit_bool(&mut self, bool_query: &'b BoolQuery) -> Result<(), Self::Err> {\n        // we only want to visit sub-queries which are strict (positive) requirements\n        for ast in bool_query.must.iter().chain(bool_query.filter.iter()) {\n            self.visit(ast)?;\n        }\n        Ok(())\n    }\n\n    fn visit_range(&mut self, range_query: &'b RangeQuery) -> Result<(), Self::Err> {\n        use std::ops::Bound;\n\n        if range_query.field == self.timestamp_field {\n            match &range_query.lower_bound {\n                Bound::Included(lower_bound) => self.update_start_timestamp(lower_bound, true),\n                Bound::Excluded(lower_bound) => self.update_start_timestamp(lower_bound, false),\n                Bound::Unbounded => (),\n            }\n            match &range_query.upper_bound {\n                Bound::Included(upper_bound) => self.update_end_timestamp(upper_bound, true),\n                Bound::Excluded(upper_bound) => self.update_end_timestamp(upper_bound, false),\n                Bound::Unbounded => (),\n            }\n        }\n        Ok(())\n    }\n\n    // if we visit a term, limit the range to DATE..=DATE\n    fn visit_term(&mut self, term_query: &'b TermQuery) -> Result<(), Self::Err> {\n        if term_query.field == self.timestamp_field {\n            // TODO when fixing #3323, this may need to be modified to support numbers too\n            let json_term = quickwit_query::JsonLiteral::String(term_query.value.clone());\n            self.update_start_timestamp(&json_term, true);\n            self.update_end_timestamp(&json_term, true);\n        }\n        Ok(())\n    }\n\n    // if we visit a termset, limit the range to LOWEST..=HIGHEST\n    fn visit_term_set(&mut self, term_query: &'b TermSetQuery) -> Result<(), Self::Err> {\n        if let Some(term_set) = term_query.terms_per_field.get(self.timestamp_field) {\n            // rfc3339 is lexicographically ordered if YEAR <= 9999, so we can use string\n            // ordering to get the start and end quickly.\n            if let Some(first) = term_set.first() {\n                let json_term = quickwit_query::JsonLiteral::String(first.clone());\n                self.update_start_timestamp(&json_term, true);\n            }\n            if let Some(last) = term_set.last() {\n                let json_term = quickwit_query::JsonLiteral::String(last.clone());\n                self.update_end_timestamp(&json_term, true);\n            }\n        }\n        Ok(())\n    }\n}\n\nasync fn assign_client_fetch_docs_jobs(\n    partial_hits: &[PartialHit],\n    split_metadatas: &[SplitMetadata],\n    client_pool: &SearchJobPlacer,\n) -> crate::Result<impl Iterator<Item = (SearchServiceClient, Vec<FetchDocsJob>)>> {\n    let index_uids_and_split_offsets_map: HashMap<String, (IndexUid, SplitIdAndFooterOffsets)> =\n        split_metadatas\n            .iter()\n            .map(|metadata| {\n                (\n                    metadata.split_id().to_string(),\n                    (\n                        metadata.index_uid.clone(),\n                        extract_split_and_footer_offsets(metadata),\n                    ),\n                )\n            })\n            .collect();\n\n    // Group the partial hits per split\n    let mut partial_hits_map: HashMap<String, Vec<PartialHit>> = HashMap::new();\n    for partial_hit in partial_hits.iter() {\n        partial_hits_map\n            .entry(partial_hit.split_id.clone())\n            .or_default()\n            .push(partial_hit.clone());\n    }\n\n    let mut fetch_docs_req_jobs: Vec<FetchDocsJob> = Vec::new();\n    for (split_id, partial_hits) in partial_hits_map {\n        let (index_uid, offsets) = index_uids_and_split_offsets_map\n            .get(&split_id)\n            .ok_or_else(|| {\n                crate::SearchError::Internal(format!(\n                    \"received partial hit from an unknown split {split_id}\"\n                ))\n            })?\n            .clone();\n        let fetch_docs_job = FetchDocsJob {\n            index_uid: index_uid.clone(),\n            offsets,\n            partial_hits,\n        };\n        fetch_docs_req_jobs.push(fetch_docs_job);\n    }\n\n    let assigned_jobs = client_pool\n        .assign_jobs(fetch_docs_req_jobs, &HashSet::new())\n        .await?;\n\n    Ok(assigned_jobs)\n}\n\n// Measure the cost associated to searching in a given split metadata.\nfn compute_split_cost(split_metadata: &SplitMetadata) -> usize {\n    // TODO this formula could be tuned a lot more. The general idea is that there is a fixed\n    // cost to searching a split, plus a somewhat-linear cost depending on the size of the split\n    5 + split_metadata.num_docs / 100_000\n}\n\n/// Builds a LeafSearchRequest to one node, from a list of [`SearchJob`].\npub fn jobs_to_leaf_request(\n    request: &SearchRequest,\n    search_indexes_metadatas: &IndexesMetasForLeafSearch,\n    jobs: Vec<SearchJob>,\n) -> crate::Result<LeafSearchRequest> {\n    let mut search_request_for_leaf = request.clone();\n    search_request_for_leaf.start_offset = 0;\n    search_request_for_leaf.max_hits += request.start_offset;\n\n    let mut leaf_search_request = LeafSearchRequest {\n        search_request: Some(search_request_for_leaf),\n        leaf_requests: Vec::new(),\n        doc_mappers: Vec::new(),\n        index_uris: Vec::new(),\n    };\n\n    let mut added_doc_mappers: HashMap<&str, u32> = HashMap::new();\n    // Group jobs by index uid, as the split offsets are relative to the index.\n    group_jobs_by_index_id(jobs, |job_group| {\n        let index_uid = &job_group[0].index_uid;\n        let search_index_meta = search_indexes_metadatas.get(index_uid).ok_or_else(|| {\n            SearchError::Internal(format!(\n                \"received job for an unknown index {index_uid}. it should never happen\"\n            ))\n        })?;\n        let doc_mapper_ord = *added_doc_mappers\n            .entry(&search_index_meta.doc_mapper_str)\n            .or_insert_with(|| {\n                let ord = leaf_search_request.doc_mappers.len();\n                leaf_search_request\n                    .doc_mappers\n                    .push(search_index_meta.doc_mapper_str.to_string());\n                ord as u32\n            });\n        let index_uri_ord = leaf_search_request.index_uris.len() as u32;\n        leaf_search_request\n            .index_uris\n            .push(search_index_meta.index_uri.to_string());\n\n        let leaf_search_request_ref = LeafRequestRef {\n            split_offsets: job_group.into_iter().map(|job| job.offsets).collect(),\n            doc_mapper_ord,\n            index_uri_ord,\n        };\n        leaf_search_request\n            .leaf_requests\n            .push(leaf_search_request_ref);\n        Ok(())\n    })?;\n    Ok(leaf_search_request)\n}\n\n/// Builds a list of [`FetchDocsRequest`], one per index, from a list of [`FetchDocsJob`].\npub fn jobs_to_fetch_docs_requests(\n    snippet_request_opt: Option<SnippetRequest>,\n    indexes_metas_for_leaf_search: &IndexesMetasForLeafSearch,\n    jobs: Vec<FetchDocsJob>,\n) -> crate::Result<Vec<FetchDocsRequest>> {\n    let mut fetch_docs_requests = Vec::new();\n    // Group jobs by index uid.\n    group_by(\n        jobs,\n        |job| &job.index_uid,\n        |fetch_docs_jobs| {\n            let index_uid = &fetch_docs_jobs[0].index_uid;\n\n            let index_meta = indexes_metas_for_leaf_search\n                .get(index_uid)\n                .ok_or_else(|| {\n                    SearchError::Internal(format!(\n                        \"received search job for an unknown index {index_uid}\"\n                    ))\n                })?;\n            let partial_hits: Vec<PartialHit> = fetch_docs_jobs\n                .iter()\n                .flat_map(|fetch_doc_job| fetch_doc_job.partial_hits.iter().cloned())\n                .collect();\n            let split_offsets: Vec<SplitIdAndFooterOffsets> = fetch_docs_jobs\n                .into_iter()\n                .map(|fetch_doc_job| fetch_doc_job.into())\n                .collect();\n            let fetch_docs_req = FetchDocsRequest {\n                partial_hits,\n                split_offsets,\n                index_uri: index_meta.index_uri.to_string(),\n                snippet_request: snippet_request_opt.clone(),\n                doc_mapper: index_meta.doc_mapper_str.clone(),\n            };\n            fetch_docs_requests.push(fetch_docs_req);\n\n            Ok(())\n        },\n    )?;\n    Ok(fetch_docs_requests)\n}\n\n#[cfg(test)]\nmod tests {\n    use std::ops::Range;\n    use std::str::FromStr;\n    use std::sync::{Arc, RwLock};\n\n    use quickwit_common::shared_consts::SCROLL_BATCH_LEN;\n    use quickwit_common::ServiceStream;\n    use quickwit_config::{DocMapping, IndexConfig, IndexingSettings, SearchSettings};\n    use quickwit_indexing::MockSplitBuilder;\n    use quickwit_metastore::{IndexMetadata, ListSplitsRequestExt, ListSplitsResponseExt};\n    use quickwit_proto::metastore::{\n        ListIndexesMetadataResponse, ListSplitsResponse, MockMetastoreService,\n    };\n    use quickwit_proto::search::{\n        ScrollRequest, SortByValue, SortOrder, SortValue, SplitSearchError,\n    };\n    use quickwit_query::query_ast::{qast_helper, qast_json_helper, query_ast_from_user_text};\n    use tantivy::schema::{FAST, STORED, TEXT};\n\n    use super::*;\n    use crate::{searcher_pool_for_test, MockSearchService};\n\n    #[track_caller]\n    fn check_snippet_fields_validation(snippet_fields: &[String]) -> anyhow::Result<()> {\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_text_field(\"title\", TEXT);\n        schema_builder.add_text_field(\"desc\", TEXT | STORED);\n        schema_builder.add_ip_addr_field(\"ip\", FAST | STORED);\n        let schema = schema_builder.build();\n        validate_requested_snippet_fields(&schema, snippet_fields)\n    }\n\n    #[test]\n    fn test_validate_requested_snippet_fields() {\n        check_snippet_fields_validation(&[\"desc\".to_string()]).unwrap();\n        let field_not_stored_err =\n            check_snippet_fields_validation(&[\"title\".to_string()]).unwrap_err();\n        assert_eq!(\n            field_not_stored_err.to_string(),\n            \"the snippet field `title` must be stored\"\n        );\n        let field_doesnotexist_err =\n            check_snippet_fields_validation(&[\"doesnotexist\".to_string()]).unwrap_err();\n        assert_eq!(\n            field_doesnotexist_err.to_string(),\n            \"The field does not exist: 'doesnotexist'\"\n        );\n        let field_is_not_text_err =\n            check_snippet_fields_validation(&[\"ip\".to_string()]).unwrap_err();\n        assert_eq!(\n            field_is_not_text_err.to_string(),\n            \"the snippet field `ip` must be of type `Str`, got `IpAddr`\"\n        );\n    }\n\n    #[test]\n    fn test_get_sort_by_field_entry() {\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_text_field(\"title\", TEXT);\n        schema_builder.add_text_field(\"desc\", TEXT | STORED);\n        schema_builder.add_u64_field(\"timestamp\", FAST | STORED);\n        let schema = schema_builder.build();\n        get_sort_by_field_entry(\"timestamp\", &schema)\n            .unwrap()\n            .unwrap();\n        let sort_by_field_entry_err = get_sort_by_field_entry(\"doesnotexist\", &schema).unwrap_err();\n        assert_eq!(\n            sort_by_field_entry_err.to_string(),\n            \"Invalid argument: unknown field used in `sort by`: doesnotexist\"\n        );\n        for sort_field_name in &[\"_doc\", \"_score\", \"_shard_doc\"] {\n            assert!(get_sort_by_field_entry(sort_field_name, &schema)\n                .unwrap()\n                .is_none());\n        }\n    }\n\n    fn index_metadata_for_multi_indexes_test(index_id: &str, index_uri: &str) -> IndexMetadata {\n        let index_uri = Uri::from_str(index_uri).unwrap();\n        let doc_mapping_json = r#\"{\n            \"mode\": \"lenient\",\n            \"field_mappings\": [\n                {\n                    \"name\": \"timestamp\",\n                    \"type\": \"datetime\",\n                    \"fast\": true\n                },\n                {\n                    \"name\": \"body\",\n                    \"type\": \"text\",\n                    \"stored\": true\n                }\n            ],\n            \"timestamp_field\": \"timestamp\",\n            \"store_source\": true\n        }\"#;\n        let doc_mapping = serde_json::from_str(doc_mapping_json).unwrap();\n        let indexing_settings = IndexingSettings::default();\n        let search_settings = SearchSettings {\n            default_search_fields: vec![\"body\".to_string()],\n        };\n        IndexMetadata::new(IndexConfig {\n            index_id: index_id.to_string(),\n            index_uri,\n            doc_mapping,\n            indexing_settings,\n            search_settings,\n            retention_policy_opt: Default::default(),\n        })\n    }\n\n    #[test]\n    fn test_validate_request_and_build_metadatas_ok() {\n        let request_query_ast = qast_helper(\"body:test\", &[]);\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: serde_json::to_string(&request_query_ast).unwrap(),\n            max_hits: 10,\n            start_offset: 10,\n            sort_fields: vec![\n                SortField {\n                    field_name: \"timestamp\".to_string(),\n                    sort_order: SortOrder::Desc as i32,\n                    sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n                },\n                SortField {\n                    field_name: \"_doc\".to_string(),\n                    sort_order: SortOrder::Asc as i32,\n                    sort_datetime_format: None,\n                },\n            ],\n            ..Default::default()\n        };\n        let index_metadata = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_metadata_with_other_config =\n            index_metadata_for_multi_indexes_test(\"test-index-2\", \"ram:///test-index-2\");\n        let mut index_metadata_no_timestamp =\n            IndexMetadata::for_test(\"test-index-3\", \"ram:///test-index-3\");\n        index_metadata_no_timestamp\n            .index_config\n            .doc_mapping\n            .timestamp_field = None;\n        let request_metadata = validate_request_and_build_metadata(\n            &[\n                index_metadata,\n                index_metadata_with_other_config,\n                index_metadata_no_timestamp,\n            ],\n            &search_request,\n        )\n        .unwrap();\n        assert_eq!(\n            request_metadata.timestamp_field_opt,\n            Some(\"timestamp\".to_string())\n        );\n        assert_eq!(request_metadata.query_ast_resolved, request_query_ast);\n        assert_eq!(request_metadata.indexes_meta_for_leaf_search.len(), 3);\n        assert_eq!(request_metadata.sort_fields_is_datetime.len(), 2);\n        assert_eq!(\n            request_metadata.sort_fields_is_datetime.get(\"timestamp\"),\n            Some(&true)\n        );\n        assert_eq!(\n            request_metadata.sort_fields_is_datetime.get(\"_doc\"),\n            Some(&false)\n        );\n    }\n\n    #[test]\n    fn test_validate_request_and_build_metadatas_fail_with_different_timestamps() {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            start_offset: 10,\n            ..Default::default()\n        };\n        let index_metadata_1 = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let mut index_metadata_2 = IndexMetadata::for_test(\"test-index-2\", \"ram:///test-index-2\");\n        let doc_mapping_json_2 = r#\"{\n            \"mode\": \"lenient\",\n            \"field_mappings\": [\n                {\n                    \"name\": \"timestamp-2\",\n                    \"type\": \"datetime\",\n                    \"fast\": true\n                },\n                {\n                    \"name\": \"body\",\n                    \"type\": \"text\"\n                }\n            ],\n            \"timestamp_field\": \"timestamp-2\",\n            \"store_source\": true\n        }\"#;\n        let doc_mapping_2: DocMapping = serde_json::from_str(doc_mapping_json_2).unwrap();\n        index_metadata_2.index_config.doc_mapping = doc_mapping_2;\n        index_metadata_2\n            .index_config\n            .search_settings\n            .default_search_fields = Vec::new();\n        let timestamp_field_different = validate_request_and_build_metadata(\n            &[index_metadata_1, index_metadata_2],\n            &search_request,\n        )\n        .unwrap_err();\n        assert_eq!(\n            timestamp_field_different.to_string(),\n            \"the timestamp field (if present) must be the same for all indexes\"\n        );\n    }\n\n    #[test]\n    fn test_validate_request_and_build_metadatas_fail_with_different_resolved_qast() {\n        let qast = query_ast_from_user_text(\"test\", None);\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: serde_json::to_string(&qast).unwrap(),\n            max_hits: 10,\n            start_offset: 10,\n            ..Default::default()\n        };\n        let index_metadata_1 = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let mut index_metadata_2 = IndexMetadata::for_test(\"test-index-2\", \"ram:///test-index-2\");\n        index_metadata_2\n            .index_config\n            .search_settings\n            .default_search_fields = vec![\"owner\".to_string()];\n        let timestamp_field_different = validate_request_and_build_metadata(\n            &[index_metadata_1, index_metadata_2],\n            &search_request,\n        )\n        .unwrap_err();\n        assert_eq!(\n            timestamp_field_different.to_string(),\n            \"resolved query ASTs must be the same across indexes. resolving queries with \\\n             different default fields are different between indexes is not supported\"\n        );\n    }\n\n    fn index_metadata_for_multi_indexes_test_with_incompatible_sort_type(\n        index_id: &str,\n        index_uri: &str,\n    ) -> IndexMetadata {\n        let index_uri = Uri::from_str(index_uri).unwrap();\n        let doc_mapping_json = r#\"{\n            \"mode\": \"lenient\",\n            \"field_mappings\": [\n                {\n                    \"name\": \"timestamp\",\n                    \"type\": \"datetime\",\n                    \"fast\": true\n                },\n                {\n                    \"name\": \"body\",\n                    \"type\": \"text\",\n                    \"stored\": true\n                },\n                {\n                    \"name\": \"response_date\",\n                    \"type\": \"i64\",\n                    \"stored\": true,\n                    \"fast\": true\n                }\n            ],\n            \"timestamp_field\": \"timestamp\",\n            \"store_source\": true\n        }\"#;\n        let doc_mapping = serde_json::from_str(doc_mapping_json).unwrap();\n        let indexing_settings = IndexingSettings::default();\n        let search_settings = SearchSettings {\n            default_search_fields: vec![\"body\".to_string()],\n        };\n        IndexMetadata::new(IndexConfig {\n            index_id: index_id.to_string(),\n            index_uri,\n            doc_mapping,\n            indexing_settings,\n            search_settings,\n            retention_policy_opt: Default::default(),\n        })\n    }\n\n    #[test]\n    fn test_validate_request_and_build_metadatas_fail_with_incompatible_sort_field_types() {\n        let request_query_ast = qast_helper(\"body:test\", &[]);\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: serde_json::to_string(&request_query_ast).unwrap(),\n            max_hits: 10,\n            start_offset: 10,\n            sort_fields: vec![SortField {\n                field_name: \"response_date\".to_string(),\n                sort_order: SortOrder::Desc as i32,\n                sort_datetime_format: None,\n            }],\n            ..Default::default()\n        };\n        let index_metadata = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_metadata_with_other_config =\n            index_metadata_for_multi_indexes_test_with_incompatible_sort_type(\n                \"test-index-2\",\n                \"ram:///test-index-2\",\n            );\n        let search_error = validate_request_and_build_metadata(\n            &[index_metadata, index_metadata_with_other_config],\n            &search_request,\n        )\n        .unwrap_err();\n        assert_eq!(\n            search_error.to_string(),\n            \"sort datetime field `response_date` must be of type datetime on all indexes\"\n        );\n    }\n\n    #[test]\n    fn test_convert_sort_datetime_value() {\n        let mut sort_value = SortValue::U64(1617000000000000000);\n        convert_sort_datetime_value(&mut sort_value, SortDatetimeFormat::UnixTimestampMillis)\n            .unwrap();\n        assert_eq!(sort_value, SortValue::U64(1617000000000));\n        let mut sort_value = SortValue::I64(1617000000000000000);\n        convert_sort_datetime_value(&mut sort_value, SortDatetimeFormat::UnixTimestampMillis)\n            .unwrap();\n        assert_eq!(sort_value, SortValue::I64(1617000000000));\n\n        // conversion with float values should fail.\n        let mut sort_value = SortValue::F64(1617000000000000000.0);\n        let error =\n            convert_sort_datetime_value(&mut sort_value, SortDatetimeFormat::UnixTimestampMillis)\n                .unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"internal error: `datetime conversion are only support for u64 and i64 sort values, \\\n             not `F64(1.617e18)``\"\n        );\n    }\n\n    #[test]\n    fn test_convert_sort_datetime_value_into_nanos() {\n        let mut sort_value = SortValue::U64(1617000000000);\n        convert_sort_datetime_value_into_nanos(\n            &mut sort_value,\n            SortDatetimeFormat::UnixTimestampMillis,\n        )\n        .unwrap();\n        assert_eq!(sort_value, SortValue::U64(1617000000000000000));\n        let mut sort_value = SortValue::I64(1617000000000);\n        convert_sort_datetime_value_into_nanos(\n            &mut sort_value,\n            SortDatetimeFormat::UnixTimestampMillis,\n        )\n        .unwrap();\n        assert_eq!(sort_value, SortValue::I64(1617000000000000000));\n\n        // conversion with a too large millisecond value should fail.\n        let mut sort_value = SortValue::I64(1617000000000000);\n        let error = convert_sort_datetime_value_into_nanos(\n            &mut sort_value,\n            SortDatetimeFormat::UnixTimestampMillis,\n        )\n        .unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"internal error: `sort value defined in milliseconds is too large and cannot be \\\n             converted into nanoseconds: 1617000000000000`\"\n        );\n        // conversion with float values should fail.\n        let mut sort_value = SortValue::F64(1617000000000000.0);\n        let error = convert_sort_datetime_value_into_nanos(\n            &mut sort_value,\n            SortDatetimeFormat::UnixTimestampMillis,\n        )\n        .unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"internal error: `datetime conversion are only support for u64 and i64 sort values, \\\n             not `F64(1617000000000000.0)``\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_field_types_with_doc_and_shard_doc() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"_doc\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n            SortField {\n                field_name: \"_shard_doc\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_date_field(\"timestamp\", FAST);\n        schema_builder.add_u64_field(\"id\", FAST);\n        let schema = schema_builder.build();\n        let mut sort_field_are_datetime = HashMap::new();\n        validate_sort_field_types(&schema, &sort_fields, &mut sort_field_are_datetime).unwrap();\n        assert_eq!(sort_field_are_datetime.get(\"_doc\"), Some(&false));\n        assert_eq!(sort_field_are_datetime.get(\"_shard_doc\"), Some(&false));\n    }\n\n    #[test]\n    fn test_validate_sort_field_types_valid() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_date_field(\"timestamp\", FAST);\n        schema_builder.add_u64_field(\"id\", FAST);\n        let schema = schema_builder.build();\n        let mut sort_field_are_datetime = HashMap::new();\n        validate_sort_field_types(&schema, &sort_fields, &mut sort_field_are_datetime).unwrap();\n        assert_eq!(sort_field_are_datetime.get(\"timestamp\"), Some(&true));\n        assert_eq!(sort_field_are_datetime.get(\"id\"), Some(&false));\n    }\n\n    #[test]\n    fn test_validate_sort_field_types_with_inconsistent_datetime_type() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let mut schema_builder = Schema::builder();\n        schema_builder.add_date_field(\"timestamp\", FAST);\n        schema_builder.add_u64_field(\"id\", FAST);\n        let schema = schema_builder.build();\n        {\n            let mut sort_field_are_datetime = HashMap::new();\n            sort_field_are_datetime.insert(\"timestamp\".to_string(), false);\n            sort_field_are_datetime.insert(\"id\".to_string(), false);\n            let error =\n                validate_sort_field_types(&schema, &sort_fields, &mut sort_field_are_datetime)\n                    .unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"sort datetime field `timestamp` must be of type datetime on all indexes\"\n            );\n        }\n        {\n            let mut sort_field_are_datetime = HashMap::new();\n            sort_field_are_datetime.insert(\"id\".to_string(), true);\n            let error =\n                validate_sort_field_types(&schema, &sort_fields, &mut sort_field_are_datetime)\n                    .unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"sort datetime field `id` must be of type datetime on all indexes\"\n            );\n        }\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_with_datetime_format_ok() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        validate_sort_by_fields_and_search_after(&sort_fields, &None).unwrap();\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_ok() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: Some(SortByValue {\n                sort_value: Some(SortValue::U64(2)),\n            }),\n            split_id: \"\".to_string(),\n            segment_ord: 0,\n            doc_id: 0,\n        };\n        validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap();\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_ok_with_doc_sort_field() {\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"_doc\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: None,\n            split_id: \"split1\".to_string(),\n            segment_ord: 1,\n            doc_id: 1,\n        };\n        validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap();\n    }\n\n    #[test]\n    fn test_validate_sort_by_field_type() {\n        let mut schema_builder = Schema::builder();\n        let timestamp_field = schema_builder.add_date_field(\"timestamp\", FAST);\n        let id_field = schema_builder.add_u64_field(\"id\", FAST);\n        let no_fast_field = schema_builder.add_u64_field(\"no_fast\", STORED);\n        let text_field = schema_builder.add_text_field(\"text\", STORED);\n        let schema = schema_builder.build();\n        {\n            let sort_by_field_entry = schema.get_field_entry(timestamp_field);\n            validate_sort_by_field_type(sort_by_field_entry, false).unwrap();\n            validate_sort_by_field_type(sort_by_field_entry, true).unwrap();\n        }\n        {\n            let sort_by_field_entry = schema.get_field_entry(id_field);\n            validate_sort_by_field_type(sort_by_field_entry, false).unwrap();\n            let error = validate_sort_by_field_type(sort_by_field_entry, true).unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"Invalid argument: sort by field with a timestamp format must be a datetime field \\\n                 and the field `id` is not\"\n            );\n        }\n        {\n            let sort_by_field_entry = schema.get_field_entry(no_fast_field);\n            let error = validate_sort_by_field_type(sort_by_field_entry, true).unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"Invalid argument: sort by field must be a fast field, please add the fast \\\n                 property to your field `no_fast`\"\n            );\n        }\n        {\n            let sort_by_field_entry = schema.get_field_entry(text_field);\n            let error = validate_sort_by_field_type(sort_by_field_entry, true).unwrap_err();\n            assert_eq!(\n                error.to_string(),\n                \"Invalid argument: sort by field on type text is currently not supported `text`\"\n            );\n        }\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_invalid_1() {\n        // 2 sort fields + search after with only one sort value is invalid.\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: None,\n            split_id: \"split1\".to_string(),\n            segment_ord: 1,\n            doc_id: 1,\n        };\n        let error =\n            validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: `search_after` must have the same number of sort values as sort by \\\n             fields [\\\"timestamp\\\", \\\"id\\\"]\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_invalid_with_missing_split_id() {\n        // 2 sort fields + search after with only one sort value is invalid.\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"_doc\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: None,\n            split_id: \"\".to_string(),\n            segment_ord: 1,\n            doc_id: 1,\n        };\n        let error =\n            validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: search_after with a sort field `_doc` must define a split ID, \\\n             segment ID and doc ID values\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_valid_1() {\n        // 2 sort fields + search after with only one sort value is invalid.\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"id\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: None,\n            },\n        ];\n        let partial_hit = PartialHit {\n            sort_value: Some(SortByValue {\n                sort_value: Some(SortValue::U64(1)),\n            }),\n            sort_value2: None,\n            split_id: \"split1\".to_string(),\n            segment_ord: 1,\n            doc_id: 1,\n        };\n        let error =\n            validate_sort_by_fields_and_search_after(&sort_fields, &Some(partial_hit)).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: `search_after` must have the same number of sort values as sort by \\\n             fields [\\\"timestamp\\\", \\\"id\\\"]\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_by_field_type_invalid() {\n        // sort non-datetime field with a datetime format is invalid.\n        let mut schema_builder = Schema::builder();\n        let field = schema_builder.add_u64_field(\"timestamp\", FAST);\n        let schema = schema_builder.build();\n        let field_entry = schema.get_field_entry(field);\n        let error = validate_sort_by_field_type(field_entry, true).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: sort by field with a timestamp format must be a datetime field and \\\n             the field `timestamp` is not\"\n        );\n    }\n\n    #[test]\n    fn test_validate_sort_by_fields_and_search_after_invalid_3() {\n        // 3 sort fields is not possible.\n        let sort_fields = vec![\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n            SortField {\n                field_name: \"timestamp\".to_string(),\n                sort_order: 0,\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampMillis as i32),\n            },\n        ];\n        let error = validate_sort_by_fields_and_search_after(&sort_fields, &None).unwrap_err();\n        assert_eq!(\n            error.to_string(),\n            \"Invalid argument: sort by field must be up to 2 fields, got 3\"\n        );\n    }\n\n    fn mock_partial_hit(\n        split_id: &str,\n        sort_value: u64,\n        doc_id: u32,\n    ) -> quickwit_proto::search::PartialHit {\n        quickwit_proto::search::PartialHit {\n            sort_value: Some(SortValue::U64(sort_value).into()),\n            sort_value2: None,\n            split_id: split_id.to_string(),\n            segment_ord: 1,\n            doc_id,\n        }\n    }\n\n    fn mock_partial_hit_opt_sort_value(\n        split_id: &str,\n        sort_value: Option<u64>,\n        doc_id: u32,\n    ) -> quickwit_proto::search::PartialHit {\n        quickwit_proto::search::PartialHit {\n            sort_value: sort_value.map(|sort_value| SortValue::U64(sort_value).into()),\n            sort_value2: None,\n            split_id: split_id.to_string(),\n            segment_ord: 1,\n            doc_id,\n        }\n    }\n\n    fn get_doc_for_fetch_req(\n        fetch_docs_req: quickwit_proto::search::FetchDocsRequest,\n    ) -> Vec<quickwit_proto::search::LeafHit> {\n        fetch_docs_req\n            .partial_hits\n            .into_iter()\n            .map(|req| quickwit_proto::search::LeafHit {\n                leaf_json: serde_json::to_string_pretty(&serde_json::json!({\n                    \"title\": [req.doc_id.to_string()],\n                    \"body\": [\"test 1\"],\n                    \"url\": [\"http://127.0.0.1/1\"]\n                }))\n                .expect(\"Json serialization should not fail\"),\n                partial_hit: Some(req),\n                leaf_snippet_json: None,\n            })\n            .collect()\n    }\n\n    #[tokio::test]\n    async fn test_root_search_offset_out_of_bounds_1085() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            start_offset: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_indexes_metadata_request| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 3,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split1\", 3, 1),\n                        mock_partial_hit(\"split1\", 2, 2),\n                        mock_partial_hit(\"split1\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split2\", 3, 1),\n                        mock_partial_hit(\"split2\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 5);\n        assert_eq!(search_response.hits.len(), 0);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_single_split() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_list_splits_request| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service = MockSearchService::new();\n        mock_search_service.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 3,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split1\", 3, 1),\n                        mock_partial_hit(\"split1\", 2, 2),\n                        mock_partial_hit(\"split1\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n\n        let searcher_context = SearcherContext::for_test();\n        let search_response = root_search(\n            &searcher_context,\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split1\", 3, 1),\n                        mock_partial_hit(\"split1\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 1,\n                    partial_hits: vec![mock_partial_hit(\"split2\", 2, 2)],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_with_failure() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 2,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                if leaf_search_req.leaf_requests[0].split_offsets.len() == 2 {\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: 2,\n                        partial_hits: vec![\n                            mock_partial_hit(\"split1\", 3, 1),\n                            mock_partial_hit(\"split1\", 1, 3),\n                        ],\n                        failed_splits: vec![SplitSearchError {\n                            error: \"some error\".to_string(),\n                            split_id: \"split2\".to_string(),\n                            retryable_error: true,\n                        }],\n                        num_attempted_splits: 2,\n                        ..Default::default()\n                    })\n                } else {\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: 1,\n                        partial_hits: vec![mock_partial_hit(\"split2\", 2, 2)],\n                        failed_splits: Vec::new(),\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                }\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service_1)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 2);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_sort_heteregeneous_field_ascending(\n    ) -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            sort_fields: vec![SortField {\n                field_name: \"response_date\".to_string(),\n                sort_order: SortOrder::Asc.into(),\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampNanos as i32),\n            }],\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::U64(2u64).into()),\n                            sort_value2: None,\n                            split_id: \"split1\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 0,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: None,\n                            sort_value2: None,\n                            split_id: \"split1\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 1,\n                        },\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 3,\n                    partial_hits: vec![\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::I64(-1i64).into()),\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 1,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::I64(1i64).into()),\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 0,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: None,\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 2,\n                        },\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request.clone(),\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await?;\n\n        assert_eq!(search_response.num_hits, 5);\n        assert_eq!(search_response.hits.len(), 5);\n        assert_eq!(\n            search_response.hits[0].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 1,\n                sort_value: Some(SortValue::I64(-1i64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[1].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 0,\n                sort_value: Some(SortValue::I64(1i64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[2].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split1\".to_string(),\n                segment_ord: 0,\n                doc_id: 0,\n                sort_value: Some(SortValue::U64(2u64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[3].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split1\".to_string(),\n                segment_ord: 0,\n                doc_id: 1,\n                sort_value: None,\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[4].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 2,\n                sort_value: None,\n                sort_value2: None,\n            }\n        );\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_sort_heteregeneous_field_descending(\n    ) -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            sort_fields: vec![SortField {\n                field_name: \"response_date\".to_string(),\n                sort_order: SortOrder::Desc.into(),\n                sort_datetime_format: Some(SortDatetimeFormat::UnixTimestampNanos as i32),\n            }],\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::U64(2u64).into()),\n                            sort_value2: None,\n                            split_id: \"split1\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 0,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: None,\n                            sort_value2: None,\n                            split_id: \"split1\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 1,\n                        },\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 3,\n                    partial_hits: vec![\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::I64(1i64).into()),\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 0,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: Some(SortValue::I64(-1i64).into()),\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 1,\n                        },\n                        quickwit_proto::search::PartialHit {\n                            sort_value: None,\n                            sort_value2: None,\n                            split_id: \"split2\".to_string(),\n                            segment_ord: 0,\n                            doc_id: 2,\n                        },\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request.clone(),\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await?;\n\n        assert_eq!(search_response.num_hits, 5);\n        assert_eq!(search_response.hits.len(), 5);\n        assert_eq!(\n            search_response.hits[0].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split1\".to_string(),\n                segment_ord: 0,\n                doc_id: 0,\n                sort_value: Some(SortValue::U64(2u64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[1].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 0,\n                sort_value: Some(SortValue::I64(1i64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[2].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 1,\n                sort_value: Some(SortValue::I64(-1i64).into()),\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[3].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split2\".to_string(),\n                segment_ord: 0,\n                doc_id: 2,\n                sort_value: None,\n                sort_value2: None,\n            }\n        );\n        assert_eq!(\n            search_response.hits[4].partial_hit.as_ref().unwrap(),\n            &PartialHit {\n                split_id: \"split1\".to_string(),\n                segment_ord: 0,\n                doc_id: 1,\n                sort_value: None,\n                sort_value2: None,\n            }\n        );\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_retry_on_other_node() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1\n            .expect_leaf_search()\n            .times(2)\n            .returning(\n                |leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                    let split_ids: Vec<&str> = leaf_search_req.leaf_requests[0]\n                        .split_offsets\n                        .iter()\n                        .map(|metadata| metadata.split_id.as_str())\n                        .collect();\n                    if split_ids == [\"split1\"] {\n                        Ok(quickwit_proto::search::LeafSearchResponse {\n                            num_hits: 2,\n                            partial_hits: vec![\n                                mock_partial_hit(\"split1\", 3, 1),\n                                mock_partial_hit(\"split1\", 1, 3),\n                            ],\n                            failed_splits: Vec::new(),\n                            num_attempted_splits: 1,\n                            ..Default::default()\n                        })\n                    } else if split_ids == [\"split2\"] {\n                        // RETRY REQUEST!\n                        Ok(quickwit_proto::search::LeafSearchResponse {\n                            num_hits: 1,\n                            partial_hits: vec![mock_partial_hit(\"split2\", 2, 2)],\n                            failed_splits: Vec::new(),\n                            num_attempted_splits: 1,\n                            ..Default::default()\n                        })\n                    } else {\n                        panic!(\"unexpected request in test {split_ids:?}\");\n                    }\n                },\n            );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2\n            .expect_leaf_search()\n            .times(1)\n            .returning(\n                |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        // requests from split 2 arrive here - simulate failure\n                        num_hits: 0,\n                        partial_hits: Vec::new(),\n                        failed_splits: vec![SplitSearchError {\n                            error: \"mock_error\".to_string(),\n                            split_id: \"split2\".to_string(),\n                            retryable_error: true,\n                        }],\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                },\n            );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multiple_splits_retry_on_all_nodes() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_indexes_metadata_request| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1\n            .expect_leaf_search()\n            .withf(|leaf_search_req| {\n                leaf_search_req.leaf_requests[0].split_offsets[0].split_id == \"split2\"\n            })\n            .return_once(|_| {\n                // requests from split 2 arrive here - simulate failure.\n                // a retry will be made on the second service.\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 0,\n                    partial_hits: Vec::new(),\n                    failed_splits: vec![SplitSearchError {\n                        error: \"mock_error\".to_string(),\n                        split_id: \"split2\".to_string(),\n                        retryable_error: true,\n                    }],\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            });\n        mock_search_service_1\n            .expect_leaf_search()\n            .withf(|leaf_search_req| {\n                leaf_search_req.leaf_requests[0].split_offsets[0].split_id == \"split1\"\n            })\n            .return_once(|_| {\n                // RETRY REQUEST from split1\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 2,\n                    partial_hits: vec![\n                        mock_partial_hit(\"split1\", 3, 1),\n                        mock_partial_hit(\"split1\", 1, 3),\n                    ],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            });\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2\n            .expect_leaf_search()\n            .withf(|leaf_search_req| {\n                leaf_search_req.leaf_requests[0].split_offsets[0].split_id == \"split2\"\n            })\n            .return_once(|_| {\n                // retry for split 2 arrive here, simulate success.\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 1,\n                    partial_hits: vec![mock_partial_hit(\"split2\", 2, 2)],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            });\n        mock_search_service_2\n            .expect_leaf_search()\n            .withf(|leaf_search_req| {\n                leaf_search_req.leaf_requests[0].split_offsets[0].split_id == \"split1\"\n            })\n            .return_once(|_| {\n                // requests from split 1 arrive here - simulate failure, then success.\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    // requests from split 2 arrive here - simulate failure\n                    num_hits: 0,\n                    partial_hits: Vec::new(),\n                    failed_splits: vec![SplitSearchError {\n                        error: \"mock_error\".to_string(),\n                        split_id: \"split1\".to_string(),\n                        retryable_error: true,\n                    }],\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            });\n        mock_search_service_2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_single_split_retry_single_node() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_list_splits_request| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut first_call = true;\n        let mut mock_search_service = MockSearchService::new();\n        mock_search_service.expect_leaf_search().times(2).returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                // requests from split 2 arrive here - simulate failure, then success\n                if first_call {\n                    first_call = false;\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: 0,\n                        partial_hits: Vec::new(),\n                        failed_splits: vec![SplitSearchError {\n                            error: \"mock_error\".to_string(),\n                            split_id: \"split1\".to_string(),\n                            retryable_error: true,\n                        }],\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                } else {\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: 1,\n                        partial_hits: vec![mock_partial_hit(\"split1\", 2, 2)],\n                        failed_splits: Vec::new(),\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                }\n            },\n        );\n        mock_search_service.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 1);\n        assert_eq!(search_response.hits.len(), 1);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_single_split_retry_single_node_fails() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n\n        let mut mock_search_service = MockSearchService::new();\n        mock_search_service.expect_leaf_search().times(2).returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 0,\n                    partial_hits: Vec::new(),\n                    failed_splits: vec![SplitSearchError {\n                        error: \"mock_error\".to_string(),\n                        split_id: \"split1\".to_string(),\n                        retryable_error: true,\n                    }],\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service.expect_fetch_docs().returning(\n            |_fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Err(SearchError::Internal(\"mockerr docs\".to_string()))\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await;\n        assert!(search_response.is_err());\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_one_splits_two_nodes_but_one_is_failing_for_split(\n    ) -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        // Service1 - broken node.\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                // retry requests from split 1 arrive here\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 1,\n                    partial_hits: vec![mock_partial_hit(\"split1\", 2, 2)],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        // Service2 - working node.\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 0,\n                    partial_hits: Vec::new(),\n                    failed_splits: vec![SplitSearchError {\n                        error: \"mock_error\".to_string(),\n                        split_id: \"split1\".to_string(),\n                        retryable_error: true,\n                    }],\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |_fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Err(SearchError::Internal(\"mockerr docs\".to_string()))\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 1);\n        assert_eq!(search_response.hits.len(), 1);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_one_splits_two_nodes_but_one_is_failing_completely(\n    ) -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n\n        // Service1 - working node.\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1.expect_leaf_search().returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Ok(quickwit_proto::search::LeafSearchResponse {\n                    num_hits: 1,\n                    partial_hits: vec![mock_partial_hit(\"split1\", 2, 2)],\n                    failed_splits: Vec::new(),\n                    num_attempted_splits: 1,\n                    ..Default::default()\n                })\n            },\n        );\n        mock_search_service_1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n        // Service2 - broken node.\n        let mut mock_search_service_2 = MockSearchService::new();\n        mock_search_service_2.expect_leaf_search().returning(\n            move |_leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                Err(SearchError::Internal(\"mockerr search\".to_string()))\n            },\n        );\n        mock_search_service_2.expect_fetch_docs().returning(\n            |_fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                Err(SearchError::Internal(\"mockerr docs\".to_string()))\n            },\n        );\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service_1),\n            (\"127.0.0.1:1002\", mock_search_service_2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 1);\n        assert_eq!(search_response.hits.len(), 1);\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_invalid_queries() -> anyhow::Result<()> {\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", MockSearchService::new())]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let searcher_context = SearcherContext::for_test();\n        let metastore = MetastoreServiceClient::from_mock(mock_metastore);\n\n        assert!(root_search(\n            &searcher_context,\n            quickwit_proto::search::SearchRequest {\n                index_id_patterns: vec![\"test-index\".to_string()],\n                query_ast: qast_json_helper(\"invalid_field:\\\"test\\\"\", &[\"body\"]),\n                max_hits: 10,\n                ..Default::default()\n            },\n            metastore.clone(),\n            &cluster_client,\n        )\n        .await\n        .is_err());\n\n        assert!(root_search(\n            &searcher_context,\n            quickwit_proto::search::SearchRequest {\n                index_id_patterns: vec![\"test-index\".to_string()],\n                query_ast: qast_json_helper(\"test\", &[\"invalid_field\"]),\n                max_hits: 10,\n                ..Default::default()\n            },\n            metastore,\n            &cluster_client,\n        )\n        .await\n        .is_err());\n\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_invalid_aggregation() -> anyhow::Result<()> {\n        let agg_req = r#\"\n            {\n                \"expensive_colors\": {\n                    \"termss\": {\n                        \"field\": \"color\",\n                        \"order\": {\n                            \"price_stats.max\": \"desc\"\n                        }\n                    },\n                    \"aggs\": {\n                        \"price_stats\" : {\n                            \"stats\": {\n                                \"field\": \"price\"\n                            }\n                        }\n                    }\n                }\n            }\"#;\n\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            aggregation_request: Some(agg_req.to_string()),\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", MockSearchService::new())]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await;\n        assert!(search_response.is_err());\n        assert!(search_response\n            .unwrap_err()\n            .to_string()\n            .starts_with(\"invalid aggregation request: unknown variant `termss`, expected one of\"));\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_root_search_invalid_request() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            start_offset: 20_000,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![MockSplitBuilder::new(\"split1\")\n                    .with_index_uid(&index_uid)\n                    .build()];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", MockSearchService::new())]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let metastore = MetastoreServiceClient::from_mock(mock_metastore);\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            metastore.clone(),\n            &cluster_client,\n        )\n        .await;\n        assert!(search_response.is_err());\n        assert_eq!(\n            search_response.unwrap_err().to_string(),\n            \"Invalid argument: max value for start_offset is 10_000, but got 20000\",\n        );\n\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 20_000,\n            ..Default::default()\n        };\n\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            metastore,\n            &cluster_client,\n        )\n        .await;\n        assert!(search_response.is_err());\n        assert_eq!(\n            search_response.unwrap_err().to_string(),\n            \"Invalid argument: max value for max_hits is 10_000, but got 20000\",\n        );\n\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_search_plan_multiple_splits() -> anyhow::Result<()> {\n        use quickwit_query::query_ast::{FullTextMode, FullTextParams, FullTextQuery};\n        use quickwit_query::MatchAllOrNone;\n\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index\".to_string()],\n            query_ast: qast_json_helper(\"test-query\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index\", \"ram:///test-index\");\n        let index_uid = index_metadata.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata.clone()\n                ]))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let search_response = search_plan(\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n        )\n        .await\n        .unwrap();\n        let response: SearchPlanResponseRest =\n            serde_json::from_str(&search_response.result).unwrap();\n        assert_eq!(\n            response,\n            SearchPlanResponseRest {\n                quickwit_ast: QueryAst::FullText(FullTextQuery {\n                    field: \"body\".to_string(),\n                    text: \"test-query\".to_string(),\n                    params: FullTextParams {\n                        tokenizer: None,\n                        mode: FullTextMode::PhraseFallbackToIntersection,\n                        zero_terms_query: MatchAllOrNone::MatchNone,\n                    },\n                    lenient: false,\n                },),\n                tantivy_ast: r#\"BooleanQuery {\n    subqueries: [\n        (\n            Must,\n            TermQuery(Term(field=3, type=Str, \"test\")),\n        ),\n        (\n            Must,\n            TermQuery(Term(field=3, type=Str, \"query\")),\n        ),\n    ],\n    minimum_number_should_match: 0,\n}\"#\n                .to_string(),\n                searched_splits: vec![\n                    \"test-index/split1\".to_string(),\n                    \"test-index/split2\".to_string()\n                ],\n                storage_requests: StorageRequestCount {\n                    footer: 1,\n                    fastfield: 0,\n                    fieldnorm: 0,\n                    sstable: 2,\n                    posting: 2,\n                    position: 0,\n                },\n            }\n        );\n        Ok(())\n    }\n\n    #[test]\n    fn test_extract_timestamp_range_from_ast() {\n        use std::ops::Bound;\n\n        use quickwit_query::JsonLiteral;\n\n        let timestamp_field = \"timestamp\";\n\n        let simple_range = quickwit_query::query_ast::RangeQuery {\n            field: timestamp_field.to_string(),\n            lower_bound: Bound::Included(JsonLiteral::String(\"2021-04-13T22:45:41Z\".to_owned())),\n            upper_bound: Bound::Excluded(JsonLiteral::String(\"2021-05-06T06:51:19Z\".to_owned())),\n        }\n        .into();\n\n        // direct range\n        let mut timestamp_range_extractor = ExtractTimestampRange {\n            timestamp_field,\n            start_timestamp: None,\n            end_timestamp: None,\n        };\n        timestamp_range_extractor.visit(&simple_range).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353941));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283879));\n\n        // range inside a must bool query\n        let bool_query_must = quickwit_query::query_ast::BoolQuery {\n            must: vec![simple_range.clone()],\n            ..Default::default()\n        };\n        timestamp_range_extractor.start_timestamp = None;\n        timestamp_range_extractor.end_timestamp = None;\n        timestamp_range_extractor\n            .visit(&bool_query_must.into())\n            .unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353941));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283879));\n\n        // range inside a should bool query\n        let bool_query_should = quickwit_query::query_ast::BoolQuery {\n            should: vec![simple_range.clone()],\n            ..Default::default()\n        };\n        timestamp_range_extractor.start_timestamp = Some(123);\n        timestamp_range_extractor.end_timestamp = None;\n        timestamp_range_extractor\n            .visit(&bool_query_should.into())\n            .unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(123));\n        assert_eq!(timestamp_range_extractor.end_timestamp, None);\n\n        // start bound was already more restrictive\n        timestamp_range_extractor.start_timestamp = Some(1618601297);\n        timestamp_range_extractor.end_timestamp = Some(i64::MAX);\n        timestamp_range_extractor.visit(&simple_range).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618601297));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283879));\n\n        // end bound was already more restrictive\n        timestamp_range_extractor.start_timestamp = Some(1);\n        timestamp_range_extractor.end_timestamp = Some(1618601297);\n        timestamp_range_extractor.visit(&simple_range).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353941));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1618601297));\n\n        // bounds are (start..end] instead of [start..end)\n        let unusual_bounds = quickwit_query::query_ast::RangeQuery {\n            field: timestamp_field.to_string(),\n            lower_bound: Bound::Excluded(JsonLiteral::String(\"2021-04-13T22:45:41Z\".to_owned())),\n            upper_bound: Bound::Included(JsonLiteral::String(\"2021-05-06T06:51:19Z\".to_owned())),\n        }\n        .into();\n        timestamp_range_extractor.start_timestamp = None;\n        timestamp_range_extractor.end_timestamp = None;\n        timestamp_range_extractor.visit(&unusual_bounds).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353942));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283880));\n\n        let wrong_field = quickwit_query::query_ast::RangeQuery {\n            field: \"other_field\".to_string(),\n            lower_bound: Bound::Included(JsonLiteral::String(\"2021-04-13T22:45:41Z\".to_owned())),\n            upper_bound: Bound::Excluded(JsonLiteral::String(\"2021-05-06T06:51:19Z\".to_owned())),\n        }\n        .into();\n        timestamp_range_extractor.start_timestamp = None;\n        timestamp_range_extractor.end_timestamp = None;\n        timestamp_range_extractor.visit(&wrong_field).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, None);\n        assert_eq!(timestamp_range_extractor.end_timestamp, None);\n\n        let high_precision = quickwit_query::query_ast::RangeQuery {\n            field: timestamp_field.to_string(),\n            lower_bound: Bound::Included(JsonLiteral::String(\n                \"2021-04-13T22:45:41.001Z\".to_owned(),\n            )),\n            upper_bound: Bound::Excluded(JsonLiteral::String(\n                \"2021-05-06T06:51:19.001Z\".to_owned(),\n            )),\n        }\n        .into();\n\n        // the upper bound should be rounded up as to includes documents from X.000 to X.001\n        let mut timestamp_range_extractor = ExtractTimestampRange {\n            timestamp_field,\n            start_timestamp: None,\n            end_timestamp: None,\n        };\n        timestamp_range_extractor.visit(&high_precision).unwrap();\n        assert_eq!(timestamp_range_extractor.start_timestamp, Some(1618353941));\n        assert_eq!(timestamp_range_extractor.end_timestamp, Some(1620283880));\n    }\n\n    fn create_search_resp(\n        index_uri: &str,\n        hit_range: Range<usize>,\n        search_after: Option<PartialHit>,\n    ) -> LeafSearchResponse {\n        let (num_total_hits, split_id) = match index_uri {\n            \"ram:///test-index-1\" => (TOTAL_NUM_HITS_INDEX_1, \"split1\"),\n            \"ram:///test-index-2\" => (TOTAL_NUM_HITS_INDEX_2, \"split2\"),\n            _ => panic!(\"unexpected index uri\"),\n        };\n\n        let doc_ids = (0..num_total_hits)\n            .rev()\n            .filter(|elem| {\n                if let Some(search_after) = &search_after {\n                    if split_id == search_after.split_id {\n                        *elem < (search_after.doc_id as usize)\n                    } else {\n                        split_id < search_after.split_id.as_str()\n                    }\n                } else {\n                    true\n                }\n            })\n            .skip(hit_range.start)\n            .take(hit_range.end - hit_range.start);\n        quickwit_proto::search::LeafSearchResponse {\n            num_hits: num_total_hits as u64,\n            partial_hits: doc_ids\n                .map(|doc_id| mock_partial_hit_opt_sort_value(split_id, None, doc_id as u32))\n                .collect(),\n            num_attempted_splits: 1,\n            ..Default::default()\n        }\n    }\n\n    const TOTAL_NUM_HITS_INDEX_1: usize = 2_005;\n    const TOTAL_NUM_HITS_INDEX_2: usize = 10;\n    const MAX_HITS_PER_PAGE: usize = 93;\n    const MAX_HITS_PER_PAGE_LARGE: usize = 1_005;\n\n    #[tokio::test]\n    async fn test_root_search_with_scroll() {\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_uid = index_metadata.index_uid.clone();\n        let index_metadata_2 = IndexMetadata::for_test(\"test-index-2\", \"ram:///test-index-2\");\n        let index_uid_2 = index_metadata_2.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                let indexes_metadata = vec![index_metadata.clone(), index_metadata_2.clone()];\n                Ok(ListIndexesMetadataResponse::for_test(indexes_metadata))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid_2)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        // We add two mock_search_service to simulate a multi node environment, where the requests\n        // are forwarded two node.\n        let mut mock_search_service1 = MockSearchService::new();\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_none());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n\n        let mut mock_search_service2 = MockSearchService::new();\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_none());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, SCROLL_BATCH_LEN);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n\n        let kv: Arc<RwLock<HashMap<Vec<u8>, Vec<u8>>>> = Default::default();\n        let kv_clone = kv.clone();\n        mock_search_service1\n            .expect_put_kv()\n            .returning(move |put_kv_req| {\n                kv_clone\n                    .write()\n                    .unwrap()\n                    .insert(put_kv_req.key, put_kv_req.payload);\n            });\n        mock_search_service1\n            .expect_get_kv()\n            .returning(move |get_kv_req| kv.read().unwrap().get(&get_kv_req.key).cloned());\n\n        let kv: Arc<RwLock<HashMap<Vec<u8>, Vec<u8>>>> = Default::default();\n        let kv_clone = kv.clone();\n        mock_search_service2\n            .expect_put_kv()\n            .returning(move |put_kv_req| {\n                kv_clone\n                    .write()\n                    .unwrap()\n                    .insert(put_kv_req.key, put_kv_req.payload);\n            });\n        mock_search_service2\n            .expect_get_kv()\n            .returning(move |get_kv_req| kv.read().unwrap().get(&get_kv_req.key).cloned());\n\n        mock_search_service1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                assert!(fetch_docs_req.partial_hits.len() <= MAX_HITS_PER_PAGE);\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n\n        mock_search_service2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                assert!(fetch_docs_req.partial_hits.len() <= MAX_HITS_PER_PAGE);\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service1),\n            (\"127.0.0.1:1002\", mock_search_service2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let searcher_context = SearcherContext::for_test();\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n\n        let mut count_seen_hits = 0;\n\n        let mut scroll_id: String = {\n            let search_request = quickwit_proto::search::SearchRequest {\n                index_id_patterns: vec![\"test-index-*\".to_string()],\n                query_ast: qast_json_helper(\"test\", &[\"body\"]),\n                max_hits: MAX_HITS_PER_PAGE as u64,\n                scroll_ttl_secs: Some(60),\n                ..Default::default()\n            };\n            let search_response = root_search(\n                &searcher_context,\n                search_request,\n                MetastoreServiceClient::from_mock(mock_metastore),\n                &cluster_client,\n            )\n            .await\n            .unwrap();\n            assert_eq!(\n                search_response.num_hits,\n                (TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2) as u64\n            );\n            assert_eq!(search_response.hits.len(), MAX_HITS_PER_PAGE);\n            let expected = (0..TOTAL_NUM_HITS_INDEX_2)\n                .rev()\n                .zip(std::iter::repeat(\"split2\"))\n                .chain(\n                    (0..TOTAL_NUM_HITS_INDEX_1)\n                        .rev()\n                        .zip(std::iter::repeat(\"split1\")),\n                );\n            for (hit, (doc_id, split)) in search_response.hits.iter().zip(expected) {\n                assert_eq!(\n                    hit.partial_hit.as_ref().unwrap(),\n                    &mock_partial_hit_opt_sort_value(split, None, doc_id as u32)\n                );\n            }\n            count_seen_hits += search_response.hits.len();\n            search_response.scroll_id.unwrap()\n        };\n        for page in 1.. {\n            let scroll_req = ScrollRequest {\n                scroll_id,\n                scroll_ttl_secs: Some(60),\n            };\n            let scroll_resp =\n                crate::service::scroll(scroll_req, &cluster_client, &searcher_context)\n                    .await\n                    .unwrap();\n            assert_eq!(\n                scroll_resp.num_hits,\n                (TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2) as u64\n            );\n            let expected = (0..TOTAL_NUM_HITS_INDEX_2)\n                .rev()\n                .zip(std::iter::repeat(\"split2\"))\n                .chain(\n                    (0..TOTAL_NUM_HITS_INDEX_1)\n                        .rev()\n                        .zip(std::iter::repeat(\"split1\")),\n                )\n                .skip(page * MAX_HITS_PER_PAGE);\n            for (hit, (doc_id, split)) in scroll_resp.hits.iter().zip(expected) {\n                assert_eq!(\n                    hit.partial_hit.as_ref().unwrap(),\n                    &mock_partial_hit_opt_sort_value(split, None, doc_id as u32)\n                );\n            }\n            scroll_id = scroll_resp.scroll_id.unwrap();\n            count_seen_hits += scroll_resp.hits.len();\n            if scroll_resp.hits.is_empty() {\n                break;\n            }\n        }\n\n        assert_eq!(\n            count_seen_hits,\n            TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2\n        );\n    }\n\n    #[tokio::test]\n    async fn test_root_search_with_scroll_large_page() {\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_uid = index_metadata.index_uid.clone();\n        let index_metadata_2 = IndexMetadata::for_test(\"test-index-2\", \"ram:///test-index-2\");\n        let index_uid_2 = index_metadata_2.index_uid.clone();\n        mock_metastore\n            .expect_list_indexes_metadata()\n            .returning(move |_index_ids_query| {\n                let indexes_metadata = vec![index_metadata.clone(), index_metadata_2.clone()];\n                Ok(ListIndexesMetadataResponse::for_test(indexes_metadata))\n            });\n        mock_metastore\n            .expect_list_splits()\n            .returning(move |_filter| {\n                let splits = vec![\n                    MockSplitBuilder::new(\"split1\")\n                        .with_index_uid(&index_uid)\n                        .build(),\n                    MockSplitBuilder::new(\"split2\")\n                        .with_index_uid(&index_uid_2)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        // We add two mock_search_service to simulate a multi node environment, where the requests\n        // are forwarded two nodes.\n        let mut mock_search_service1 = MockSearchService::new();\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_none());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service1\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        let kv: Arc<RwLock<HashMap<Vec<u8>, Vec<u8>>>> = Default::default();\n        let kv_clone = kv.clone();\n        mock_search_service1\n            .expect_put_kv()\n            .returning(move |put_kv_req| {\n                kv_clone\n                    .write()\n                    .unwrap()\n                    .insert(put_kv_req.key, put_kv_req.payload);\n            });\n        mock_search_service1\n            .expect_get_kv()\n            .returning(move |get_kv_req| kv.read().unwrap().get(&get_kv_req.key).cloned());\n        mock_search_service1.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                assert!(fetch_docs_req.partial_hits.len() <= MAX_HITS_PER_PAGE_LARGE);\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n\n        let mut mock_search_service2 = MockSearchService::new();\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_none());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        mock_search_service2\n            .expect_leaf_search()\n            .times(1)\n            .returning(|req: quickwit_proto::search::LeafSearchRequest| {\n                let search_req = req.search_request.unwrap();\n                // the leaf request does not need to know about the scroll_ttl.\n                assert_eq!(search_req.start_offset, 0u64);\n                assert!(search_req.scroll_ttl_secs.is_none());\n                assert_eq!(search_req.max_hits as usize, MAX_HITS_PER_PAGE_LARGE);\n                assert!(search_req.search_after.is_some());\n                Ok(create_search_resp(\n                    &req.index_uris[0],\n                    search_req.start_offset as usize\n                        ..(search_req.start_offset + search_req.max_hits) as usize,\n                    search_req.search_after,\n                ))\n            });\n        let kv: Arc<RwLock<HashMap<Vec<u8>, Vec<u8>>>> = Default::default();\n        let kv_clone = kv.clone();\n        mock_search_service2\n            .expect_put_kv()\n            .returning(move |put_kv_req| {\n                kv_clone\n                    .write()\n                    .unwrap()\n                    .insert(put_kv_req.key, put_kv_req.payload);\n            });\n        mock_search_service2\n            .expect_get_kv()\n            .returning(move |get_kv_req| kv.read().unwrap().get(&get_kv_req.key).cloned());\n        mock_search_service2.expect_fetch_docs().returning(\n            |fetch_docs_req: quickwit_proto::search::FetchDocsRequest| {\n                assert!(fetch_docs_req.partial_hits.len() <= MAX_HITS_PER_PAGE_LARGE);\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            },\n        );\n\n        let searcher_pool = searcher_pool_for_test([\n            (\"127.0.0.1:1001\", mock_search_service1),\n            (\"127.0.0.1:1002\", mock_search_service2),\n        ]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let searcher_context = SearcherContext::for_test();\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n\n        let mut count_seen_hits = 0;\n\n        let mut scroll_id: String = {\n            let search_request = quickwit_proto::search::SearchRequest {\n                index_id_patterns: vec![\"test-index-*\".to_string()],\n                query_ast: qast_json_helper(\"test\", &[\"body\"]),\n                max_hits: MAX_HITS_PER_PAGE_LARGE as u64,\n                scroll_ttl_secs: Some(60),\n                ..Default::default()\n            };\n            let search_response = root_search(\n                &searcher_context,\n                search_request,\n                MetastoreServiceClient::from_mock(mock_metastore),\n                &cluster_client,\n            )\n            .await\n            .unwrap();\n            assert_eq!(\n                search_response.num_hits,\n                (TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2) as u64\n            );\n            assert_eq!(search_response.hits.len(), MAX_HITS_PER_PAGE_LARGE);\n            let expected = (0..TOTAL_NUM_HITS_INDEX_2)\n                .rev()\n                .zip(std::iter::repeat(\"split2\"))\n                .chain(\n                    (0..TOTAL_NUM_HITS_INDEX_1)\n                        .rev()\n                        .zip(std::iter::repeat(\"split1\")),\n                );\n            for (hit, (doc_id, split)) in search_response.hits.iter().zip(expected) {\n                assert_eq!(\n                    hit.partial_hit.as_ref().unwrap(),\n                    &mock_partial_hit_opt_sort_value(split, None, doc_id as u32)\n                );\n            }\n            count_seen_hits += search_response.hits.len();\n            search_response.scroll_id.unwrap()\n        };\n        for page in 1.. {\n            let scroll_req = ScrollRequest {\n                scroll_id,\n                scroll_ttl_secs: Some(60),\n            };\n            let scroll_resp =\n                crate::service::scroll(scroll_req, &cluster_client, &searcher_context)\n                    .await\n                    .unwrap();\n            assert_eq!(\n                scroll_resp.num_hits,\n                (TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2) as u64\n            );\n            let expected = (0..TOTAL_NUM_HITS_INDEX_2)\n                .rev()\n                .zip(std::iter::repeat(\"split2\"))\n                .chain(\n                    (0..TOTAL_NUM_HITS_INDEX_1)\n                        .rev()\n                        .zip(std::iter::repeat(\"split1\")),\n                )\n                .skip(page * MAX_HITS_PER_PAGE_LARGE);\n            for (hit, (doc_id, split)) in scroll_resp.hits.iter().zip(expected) {\n                assert_eq!(\n                    hit.partial_hit.as_ref().unwrap(),\n                    &mock_partial_hit_opt_sort_value(split, None, doc_id as u32)\n                );\n            }\n            scroll_id = scroll_resp.scroll_id.unwrap();\n            count_seen_hits += scroll_resp.hits.len();\n            if scroll_resp.hits.is_empty() {\n                break;\n            }\n        }\n\n        assert_eq!(\n            count_seen_hits,\n            TOTAL_NUM_HITS_INDEX_1 + TOTAL_NUM_HITS_INDEX_2\n        );\n    }\n\n    #[tokio::test]\n    async fn test_root_search_multi_indices() -> anyhow::Result<()> {\n        let search_request = quickwit_proto::search::SearchRequest {\n            index_id_patterns: vec![\"test-index-*\".to_string()],\n            query_ast: qast_json_helper(\"test\", &[\"body\"]),\n            max_hits: 10,\n            ..Default::default()\n        };\n        let mut mock_metastore = MockMetastoreService::new();\n        let index_metadata_1 = IndexMetadata::for_test(\"test-index-1\", \"ram:///test-index-1\");\n        let index_uid_1 = index_metadata_1.index_uid.clone();\n        let index_metadata_2 =\n            index_metadata_for_multi_indexes_test(\"test-index-2\", \"ram:///test-index-2\");\n        let index_uid_2 = index_metadata_2.index_uid.clone();\n        let index_metadata_3 =\n            index_metadata_for_multi_indexes_test(\"test-index-3\", \"ram:///test-index-3\");\n        let index_uid_3 = index_metadata_3.index_uid.clone();\n        mock_metastore.expect_list_indexes_metadata().return_once(\n            move |list_indexes_metadata_request: ListIndexesMetadataRequest| {\n                let index_id_patterns = list_indexes_metadata_request.index_id_patterns;\n                assert_eq!(&index_id_patterns, &[\"test-index-*\".to_string()]);\n                Ok(ListIndexesMetadataResponse::for_test(vec![\n                    index_metadata_1,\n                    index_metadata_2,\n                    index_metadata_3,\n                ]))\n            },\n        );\n        mock_metastore\n            .expect_list_splits()\n            .return_once(move |list_splits_request| {\n                let list_splits_query =\n                    list_splits_request.deserialize_list_splits_query().unwrap();\n                assert!(\n                    list_splits_query.index_uids\n                        == vec![\n                            index_uid_1.clone(),\n                            index_uid_2.clone(),\n                            index_uid_3.clone()\n                        ]\n                );\n                let splits = vec![\n                    MockSplitBuilder::new(\"index-1-split-1\")\n                        .with_index_uid(&index_uid_1)\n                        .build(),\n                    MockSplitBuilder::new(\"index-1-split-2\")\n                        .with_index_uid(&index_uid_1)\n                        .build(),\n                    MockSplitBuilder::new(\"index-2-split-1\")\n                        .with_index_uid(&index_uid_2)\n                        .build(),\n                ];\n                let splits_response = ListSplitsResponse::try_from_splits(splits).unwrap();\n                Ok(ServiceStream::from(vec![Ok(splits_response)]))\n            });\n        let mut mock_search_service_1 = MockSearchService::new();\n        mock_search_service_1\n            .expect_leaf_search()\n            .times(1)\n            .withf(|leaf_search_req| {\n                (&leaf_search_req.index_uris[0] == \"ram:///test-index-1\"\n                    && leaf_search_req.leaf_requests[0].split_offsets.len() == 2)\n                    || (leaf_search_req.index_uris[0] == \"ram:///test-index-2\"\n                        && leaf_search_req.leaf_requests[0].split_offsets[0].split_id\n                            == \"index-2-split-1\")\n            })\n            .returning(\n                |leaf_search_req: quickwit_proto::search::LeafSearchRequest| {\n                    let mut partial_hits = leaf_search_req.leaf_requests[0]\n                        .split_offsets\n                        .iter()\n                        .map(|split_offset| mock_partial_hit(&split_offset.split_id, 3, 1))\n                        .collect_vec();\n                    let partial_hits2 = leaf_search_req.leaf_requests[1]\n                        .split_offsets\n                        .iter()\n                        .map(|split_offset| mock_partial_hit(&split_offset.split_id, 3, 1))\n                        .collect_vec();\n                    partial_hits.extend_from_slice(&partial_hits2);\n                    Ok(quickwit_proto::search::LeafSearchResponse {\n                        num_hits: leaf_search_req.leaf_requests[0].split_offsets.len() as u64\n                            + leaf_search_req.leaf_requests[1].split_offsets.len() as u64,\n                        partial_hits,\n                        failed_splits: Vec::new(),\n                        num_attempted_splits: 1,\n                        ..Default::default()\n                    })\n                },\n            );\n        mock_search_service_1\n            .expect_fetch_docs()\n            .times(2)\n            .withf(|fetch_docs_req: &FetchDocsRequest| {\n                (fetch_docs_req.index_uri == \"ram:///test-index-1\"\n                    && fetch_docs_req.partial_hits.len() == 2)\n                    || (fetch_docs_req.index_uri == \"ram:///test-index-2\"\n                        && fetch_docs_req.partial_hits[0].split_id == \"index-2-split-1\")\n            })\n            .returning(|fetch_docs_req| {\n                Ok(quickwit_proto::search::FetchDocsResponse {\n                    hits: get_doc_for_fetch_req(fetch_docs_req),\n                })\n            });\n        let searcher_pool = searcher_pool_for_test([(\"127.0.0.1:1001\", mock_search_service_1)]);\n        let search_job_placer = SearchJobPlacer::new(searcher_pool);\n        let cluster_client = ClusterClient::new(search_job_placer.clone());\n        let search_response = root_search(\n            &SearcherContext::for_test(),\n            search_request,\n            MetastoreServiceClient::from_mock(mock_metastore),\n            &cluster_client,\n        )\n        .await\n        .unwrap();\n        assert_eq!(search_response.num_hits, 3);\n        assert_eq!(search_response.hits.len(), 3);\n        assert_eq!(\n            search_response\n                .hits\n                .iter()\n                .map(|hit| &hit.index_id)\n                .collect_vec(),\n            vec![\"test-index-1\", \"test-index-1\", \"test-index-2\"]\n        );\n        Ok(())\n    }\n}\n```\nasync fn search_partial_hits_phase_with_scroll(\n\n\n","messages":[{"id":{"replica_id":0,"value":0},"start":0,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":361}},"image_offsets":[]},{"id":{"replica_id":0,"value":23},"start":8024,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":362}},"image_offsets":[]},{"id":{"replica_id":0,"value":24},"start":10183,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":363}},"image_offsets":[]},{"id":{"replica_id":0,"value":59},"start":10257,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":364}},"image_offsets":[]},{"id":{"replica_id":0,"value":60},"start":210413,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":365}},"image_offsets":[]},{"id":{"replica_id":0,"value":98},"start":210414,"metadata":{"role":"assistant","status":{"Error":"The final message must be from the user. To provide a system prompt, you must provide the system prompt followed by a user prompt."},"timestamp":{"replica_id":0,"value":366}},"image_offsets":[]},{"id":{"replica_id":0,"value":99},"start":210415,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":367}},"image_offsets":[]},{"id":{"replica_id":0,"value":158},"start":406193,"metadata":{"role":"assistant","status":{"Error":"Failed to connect to API: 400 Bad Request {\"error\":{\"message\":\"prompt token limit exceeded\",\"param\":\"\",\"code\":\"\",\"type\":\"\"}}"},"timestamp":{"replica_id":0,"value":368}},"image_offsets":[]},{"id":{"replica_id":0,"value":159},"start":406194,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":369}},"image_offsets":[]},{"id":{"replica_id":0,"value":234},"start":601945,"metadata":{"role":"assistant","status":{"Error":"Failed to connect to API: 400 Bad Request {\"error\":{\"message\":\"prompt token limit exceeded\",\"param\":\"\",\"code\":\"\",\"type\":\"\"}}"},"timestamp":{"replica_id":0,"value":370}},"image_offsets":[]},{"id":{"replica_id":0,"value":235},"start":601946,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":371}},"image_offsets":[]},{"id":{"replica_id":0,"value":359},"start":797699,"metadata":{"role":"assistant","status":{"Error":"Failed to connect to API: 400 Bad Request {\"error\":{\"message\":\"prompt token limit exceeded\",\"param\":\"\",\"code\":\"\",\"type\":\"\"}}"},"timestamp":{"replica_id":0,"value":374}},"image_offsets":[]},{"id":{"replica_id":0,"value":360},"start":797700,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":373}},"image_offsets":[]}],"summary":"Quickwit Search Flow Sequence Diagram","slash_command_output_sections":[{"range":{"start":0,"end":1},"icon":"Library","label":"Default"},{"range":{"start":3,"end":7919},"icon":"Route","label":"Workflow"},{"range":{"start":10618,"end":206321},"icon":"File","label":"quickwit/quickwit/quickwit-search/src/root.rs"},{"range":{"start":210415,"end":406118},"icon":"File","label":"quickwit/quickwit/quickwit-search/src/root.rs"},{"range":{"start":406194,"end":601897},"icon":"File","label":"quickwit/quickwit/quickwit-search/src/root.rs"},{"range":{"start":601946,"end":797649},"icon":"File","label":"quickwit/quickwit/quickwit-search/src/root.rs"}]}