{"id":"57a8de3a-6b26-473f-8a01-dbfbe163aae0","zed":"context","version":"0.4.0","text":"\n\n\n\n```rs quickwit/quickwit/quickwit-search/src/fetch_docs.rs:244-245\n// Excerpt from: async fn fetch_docs_in_split\nues(field_name, field_values)\n                {\n```\n\n```rs quickwit/quickwit/quickwit-search/src/fetch_docs.rs:167-266\n// Excerpt from: \nasync fn fetch_docs_in_split(\n    searcher_context: Arc<SearcherContext>,\n    mut global_doc_addrs: Vec<GlobalDocAddress>,\n    index_storage: Arc<dyn Storage>,\n    split: &SplitIdAndFooterOffsets,\n    doc_mapper: Arc<dyn DocMapper>,\n    snippet_request_opt: Option<&SnippetRequest>,\n) -> anyhow::Result<Vec<(GlobalDocAddress, Document)>> {\n    global_doc_addrs.sort_by_key(|doc| doc.doc_addr);\n    // Opens the index without the ephemeral unbounded cache, this cache is indeed not useful\n    // when fetching docs as we will fetch them only once.\n    let mut index = open_index_with_caches(\n        &searcher_context,\n        index_storage,\n        split,\n        Some(doc_mapper.tokenizer_manager()),\n        false,\n    )\n    .await\n    .context(\"open-index-for-split\")?;\n    // we add an executor here, we could add it in open_index_with_caches, though we should verify\n    // the side-effect before\n    let tantivy_executor = crate::search_thread_pool()\n        .get_underlying_rayon_thread_pool()\n        .into();\n    index.set_executor(tantivy_executor);\n    let index_reader = index\n        .reader_builder()\n        // the docs are presorted so a cache size of NUM_CONCURRENT_REQUESTS is fine\n        .doc_store_cache_num_blocks(NUM_CONCURRENT_REQUESTS)\n        .reload_policy(ReloadPolicy::Manual)\n        .try_into()?;\n    let searcher = Arc::new(index_reader.searcher());\n    let fields_snippet_generator_opt = if let Some(snippet_request) = snippet_request_opt {\n        Some(create_fields_snippet_generator(&searcher, doc_mapper.clone(), snippet_request).await?)\n    } else {\n        None\n    };\n\n    let doc_futures = global_doc_addrs.into_iter().map(|global_doc_addr| {\n        let moved_searcher = searcher.clone();\n        let moved_doc_mapper = doc_mapper.clone();\n        let fields_snippet_generator_opt_clone = fields_snippet_generator_opt.clone();\n        async move {\n            let doc: TantivyDocument = moved_searcher\n                .doc_async(global_doc_addr.doc_addr)\n                .await\n                .context(\"searcher-doc-async\")?;\n\n            let named_field_doc = doc.to_named_doc(moved_searcher.schema());\n            let content_json =\n                convert_document_to_json_string(named_field_doc, &*moved_doc_mapper)?;\n            if fields_snippet_generator_opt_clone.is_none() {\n                return Ok((\n                    global_doc_addr,\n                    Document {\n                        content_json,\n                        snippet_json: None,\n                    },\n                ));\n            }\n\n            let fields_snippet_generator_clone = fields_snippet_generator_opt_clone.unwrap();\n            if fields_snippet_generator_clone.is_empty() {\n                return Ok((\n                    global_doc_addr,\n                    Document {\n                        content_json,\n                        snippet_json: None,\n                    },\n                ));\n            }\n\n            let mut snippets = HashMap::new();\n            for (field, field_values) in doc.get_sorted_field_values() {\n                let field_name = moved_searcher.schema().get_field_name(field);\n                if let Some(values) = fields_snippet_generator_clone\n                    .snippets_from_field_values(field_name, field_values)\n                {\n                    snippets.insert(field_name, values);\n                }\n            }\n            let snippet_json = serde_json::to_string(&snippets)?;\n            Ok((\n                global_doc_addr,\n                Document {\n                    content_json,\n                    snippet_json: Some(snippet_json),\n                },\n            ))\n        }\n        .in_current_span()\n    });\n\n    futures::stream::iter(doc_futures)\n        .buffer_unordered(NUM_CONCURRENT_REQUESTS)\n        .try_collect::<Vec<_>>()\n        .await\n}\n\n```\nwhen reading from the function openindex with caches, do we use the cache which was populated during phase 1 of search where we get the partial hits? Also, can it happen that a split file points to a doc that is not present in the index?\nLet's break down your questions one by one:\n\n### 1. Cache Usage in `open_index_with_caches`\n\nThe function `open_index_with_caches` is used to open an index with specific caching configurations. In the context of the `fetch_docs_in_split` function, the cache is not the ephemeral unbounded cache but a bounded cache with a size defined by `NUM_CONCURRENT_REQUESTS`. This is because the documents are fetched only once, and an unbounded cache would not provide any additional benefit.\n\nHere's the relevant part of the code:\n\n```rust\nlet mut index = open_index_with_caches(\n    &searcher_context,\n    index_storage,\n    split,\n    Some(doc_mapper.tokenizer_manager()),\n    false, // This indicates that the ephemeral unbounded cache is not used.\n)\n.await\n.context(\"open-index-for-split\")?;\n```\n\nThe cache used here is specifically configured for the document store, and it is bounded. This means that the cache populated during the first phase of the search (where partial hits are obtained) is not directly reused here. Instead, a new cache is set up for fetching the documents.\n\n### 2. Split File Pointing to a Non-Existent Document\n\nIn the context of a search engine like Quickwit, a split file is a segment of the index that contains a subset of the documents. Each document within a split is identified by a unique document address.\n\nTheoretically, it should not happen that a split file points to a document that is not present in the index. The split file and the index are designed to be consistent with each other. However, there are a few scenarios where inconsistencies might arise:\n\n1. **Corruption**: If the index or split file gets corrupted, it might point to non-existent documents.\n2. **Concurrent Modifications**: If the index is being modified concurrently (e.g., documents are being deleted or added), there might be a brief period where inconsistencies exist.\n3. **Bugs**: Software bugs in the indexing or splitting logic could lead to inconsistencies.\n\nIn practice, robust search engines implement various checks and balances to ensure that such inconsistencies are minimized or handled gracefully.\n\nIn the `fetch_docs_in_split` function, the document fetching is done asynchronously, and each document fetch is wrapped in error handling (`context(\"searcher-doc-async\")?`). If a document is not found, an error will be returned, and the error handling logic will need to address it.\n\nHere's the relevant part of the code:\n\n```rust\nlet doc: TantivyDocument = moved_searcher\n    .doc_async(global_doc_addr.doc_addr)\n    .await\n    .context(\"searcher-doc-async\")?;\n```\n\nIf the document is not found, the `doc_async` method will return an error, which will be propagated up the call stack.\n\n### Summary\n\n- The cache used in `open_index_with_caches` during `fetch_docs_in_split` is a new bounded cache, not the ephemeral unbounded cache used during the initial search phase.\n- It should not normally happen that a split file points to a non-existent document, but if it does, it would likely be due to corruption, concurrent modifications, or bugs. The code includes error handling to manage such scenarios.\n\n```rs quickwit/quickwit/quickwit-search/src/leaf.rs:351-458\n// Excerpt from: \n/// Apply a leaf search on a single split.\nasync fn leaf_search_single_split(\n    searcher_context: &SearcherContext,\n    mut search_request: SearchRequest,\n    storage: Arc<dyn Storage>,\n    split: SplitIdAndFooterOffsets,\n    doc_mapper: Arc<dyn DocMapper>,\n    split_filter: Arc<RwLock<CanSplitDoBetter>>,\n    aggregations_limits: AggregationLimits,\n) -> crate::Result<LeafSearchResponse> {\n    rewrite_request(\n        &mut search_request,\n        &split,\n        doc_mapper.timestamp_field_name(),\n    );\n    // Check cache\n    // This cache takes in account the split id and the search request\n    //\n    if let Some(cached_answer) = searcher_context\n        .leaf_search_cache\n        .get(split.clone(), search_request.clone())\n    {\n        return Ok(cached_answer);\n    }\n\n    let query_ast: QueryAst = serde_json::from_str(search_request.query_ast.as_str())\n        .map_err(|err| SearchError::InvalidQuery(err.to_string()))?;\n\n    // CanSplitDoBetter or rewrite_request may have changed the request to be a count only request\n    // This may be the case for AllQuery with a sort by date and time filter, where the current\n    // split can't have better results.\n    //\n    if is_metadata_count_request_with_ast(&query_ast, &search_request) {\n        return Ok(get_leaf_resp_from_count(split.num_docs));\n    }\n\n    let split_id = split.split_id.to_string();\n    // this will return index with hotcache if available\n    let index = open_index_with_caches(\n        searcher_context,\n        storage,\n        &split,\n        Some(doc_mapper.tokenizer_manager()),\n        true,\n    )\n    .await?;\n    let split_schema = index.schema();\n\n    let reader = index\n        .reader_builder()\n        .reload_policy(ReloadPolicy::Manual)\n        .try_into()?;\n    let searcher = reader.searcher();\n\n    // collector is needed to collect the search results\n    let mut collector =\n        make_collector_for_split(split_id.clone(), &search_request, aggregations_limits)?;\n\n    let (query, mut warmup_info) = doc_mapper.query(split_schema.clone(), &query_ast, false)?;\n\n    let collector_warmup_info = collector.warmup_info();\n    warmup_info.merge(collector_warmup_info);\n    warmup_info.simplify();\n\n    // all of the FST lookup happens here. This is the most expensive part of the search\n    // and we want to do it only once per split\n    warmup(&searcher, &warmup_info).await?;\n    let span = info_span!(\"tantivy_search\");\n\n    let (search_request, leaf_search_response) = {\n        let split = split.clone();\n\n        crate::search_thread_pool()\n            // actual serach happens in a rayon thread pool\n            // where tantivy calls in the\n            .run_cpu_intensive(move || {\n                let _span_guard = span.enter();\n                // Our search execution has been scheduled, let's check if we can improve the\n                // request based on the results of the preceding searches\n                check_optimize_search_request(&mut search_request, &split, &split_filter);\n                collector.update_search_param(&search_request);\n                if is_metadata_count_request_with_ast(&query_ast, &search_request) {\n                    return Ok((\n                        search_request,\n                        get_leaf_resp_from_count(searcher.num_docs() as u64),\n                    ));\n                }\n                if collector.is_count_only() {\n                    let count = query.count(&searcher)? as u64;\n                    Ok((search_request, get_leaf_resp_from_count(count)))\n                } else {\n                    searcher\n                        .search(&query, &collector)\n                        .map(|resp| (search_request, resp))\n                }\n            })\n            .await\n            .map_err(|_| {\n                crate::SearchError::Internal(format!(\"leaf search panicked. split={split_id}\"))\n            })??\n    };\n\n    // update cache\n    searcher_context\n        .leaf_search_cache\n        .put(split, search_request, leaf_search_response.clone());\n    Ok(leaf_search_response)\n}\n```\nso in this function which is called in phase 1, we populate the cache but we cannot use it in phase 2 right?\nYou are correct in your understanding. The `leaf_search_single_split` function is responsible for performing a search on a single split during the first phase of the search process. This function includes logic to check and populate a cache (`leaf_search_cache`) with the results of the search request for a given split.\n\nHere's a breakdown of the relevant parts of the function:\n\n1. **Cache Check**:\n   ```rust\n   if let Some(cached_answer) = searcher_context\n       .leaf_search_cache\n       .get(split.clone(), search_request.clone())\n   {\n       return Ok(cached_answer);\n   }\n   ```\n   This part checks if the result for the given split and search request is already in the cache. If it is, it returns the cached result immediately.\n\n2. **Perform Search**:\n   If the result is not in the cache, the function proceeds to perform the search. This involves opening the index, creating a searcher, and executing the query.\n\n3. **Update Cache**:\n   ```rust\n   searcher_context\n       .leaf_search_cache\n       .put(split, search_request, leaf_search_response.clone());\n   ```\n   After the search is completed, the result is stored in the cache for future use.\n\n### Cache Usage in Phase 2\n\nIn the second phase of the search process, which involves fetching the actual documents (`fetch_docs_in_split` function), the cache populated during the first phase (`leaf_search_cache`) is not directly used. The second phase focuses on retrieving the full documents based on the document addresses obtained in the first phase.\n\nThe `fetch_docs_in_split` function opens the index again, but it uses a different caching strategy specifically for the document store:\n\n```rust\nlet mut index = open_index_with_caches(\n    &searcher_context,\n    index_storage,\n    split,\n    Some(doc_mapper.tokenizer_manager()),\n    false, // This indicates that the ephemeral unbounded cache is not used.\n)\n.await\n.context(\"open-index-for-split\")?;\n```\n\nIn this case, the cache is configured to be bounded and is used to optimize the retrieval of documents, not the search results.\n\n### Summary\n\n- **Phase 1 (`leaf_search_single_split`)**: The cache (`leaf_search_cache`) is used to store and retrieve search results for specific splits and search requests.\n- **Phase 2 (`fetch_docs_in_split`)**: A different caching strategy is used, focusing on document retrieval rather than search results. The cache from Phase 1 is not directly used in this phase.\n\nTherefore, while the cache populated in Phase 1 helps optimize repeated search requests, it does not directly benefit the document fetching process in Phase 2.\n\n```rs quickwit/quickwit/quickwit-search/src/leaf.rs:132-169\n// Excerpt from: pub(crate) async fn open_index_with_caches\npub(crate) async fn open_index_with_caches(\n    searcher_context: &SearcherContext,\n    index_storage: Arc<dyn Storage>,\n    split_and_footer_offsets: &SplitIdAndFooterOffsets,\n    tokenizer_manager: Option<&TokenizerManager>,\n    ephemeral_unbounded_cache: bool,\n) -> anyhow::Result<Index> {\n    // hot cache bytes contains ???\n    let (hotcache_bytes, bundle_storage) =\n        open_split_bundle(searcher_context, index_storage, split_and_footer_offsets).await?;\n\n    // We wrap the bundle storage with the fast fields cache.\n    let bundle_storage_with_cache = wrap_storage_with_cache(\n        searcher_context.fast_fields_cache.clone(),\n        Arc::new(bundle_storage),\n    );\n    let directory = StorageDirectory::new(bundle_storage_with_cache);\n\n    // This directory is what allows quickwit to fetch all the data without having to do read operations\n    // the cache which is placed in front of the directory is what allows to reduce read calls\n    let hot_directory = if ephemeral_unbounded_cache {\n        let caching_directory = CachingDirectory::new_unbounded(Arc::new(directory));\n        HotDirectory::open(caching_directory, hotcache_bytes.read_bytes()?)?\n    } else {\n        HotDirectory::open(directory, hotcache_bytes.read_bytes()?)?\n    };\n\n    let mut index = Index::open(hot_directory)?;\n    if let Some(tokenizer_manager) = tokenizer_manager {\n        index.set_tokenizers(tokenizer_manager.tantivy_manager().clone());\n    }\n    index.set_fast_field_tokenizers(\n        quickwit_query::get_quickwit_fastfield_normalizer_manager()\n            .tantivy_manager()\n            .clone(),\n    );\n    Ok(index)\n}\n```\nbut this function itself has a cache right? will this not be used as well\nYes, the `open_index_with_caches` function itself involves caching mechanisms that are used to optimize the index opening process. Let's break down the caching aspects involved in this function:\n\n### Caching Mechanisms in `open_index_with_caches`\n\n1. **Hot Cache Bytes**:\n   ```rust\n   let (hotcache_bytes, bundle_storage) =\n       open_split_bundle(searcher_context, index_storage, split_and_footer_offsets).await?;\n   ```\n   The `open_split_bundle` function retrieves the hot cache bytes and the bundle storage. The hot cache bytes contain precomputed data that can speed up the opening of the index.\n\n2. **Fast Fields Cache**:\n   ```rust\n   let bundle_storage_with_cache = wrap_storage_with_cache(\n       searcher_context.fast_fields_cache.clone(),\n       Arc::new(bundle_storage),\n   );\n   let directory = StorageDirectory::new(bundle_storage_with_cache);\n   ```\n   The `wrap_storage_with_cache` function wraps the bundle storage with a fast fields cache. This cache helps in reducing the number of read operations required to access fast fields, which are often used in search queries.\n\n3. **Ephemeral Unbounded Cache**:\n   ```rust\n   let hot_directory = if ephemeral_unbounded_cache {\n       let caching_directory = CachingDirectory::new_unbounded(Arc::new(directory));\n       HotDirectory::open(caching_directory, hotcache_bytes.read_bytes()?)?\n   } else {\n       HotDirectory::open(directory, hotcache_bytes.read_bytes()?)?\n   };\n   ```\n   Depending on the `ephemeral_unbounded_cache` flag, the function may use an unbounded caching directory. This type of cache is useful for scenarios where the data is accessed only once and can be discarded afterward.\n\n### Usage in Phase 2\n\nIn the context of Phase 2 (document fetching), the `open_index_with_caches` function is indeed used, and the caches involved in this function help optimize the process of opening the index and accessing the necessary data. Specifically:\n\n- **Fast Fields Cache**: This cache helps in efficiently accessing fast fields, which can be useful when fetching documents.\n- **Hot Cache Bytes**: These precomputed bytes speed up the index opening process.\n- **Ephemeral Unbounded Cache**: If enabled, this cache can reduce the number of read operations by caching data in an unbounded manner.\n\n### Summary\n\nWhile the `leaf_search_cache` from Phase 1 is not directly used in Phase 2, the `open_index_with_caches` function itself employs several caching mechanisms that help optimize the index opening and data access processes. These caches are beneficial in both phases, albeit in different contexts:\n\n- **Phase 1 (Search)**: The `leaf_search_cache` is used to store and retrieve search results for specific splits and search requests.\n- **Phase 2 (Document Fetching)**: The caches within `open_index_with_caches` (fast fields cache, hot cache bytes, and potentially the ephemeral unbounded cache) help optimize the process of opening the index and accessing the necessary data for document retrieval.\n\nTherefore, while the specific cache populated in Phase 1 is not reused in Phase 2, the caching mechanisms within `open_index_with_caches` do provide performance benefits during document fetching.\n","messages":[{"id":{"replica_id":0,"value":0},"start":0,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":268}},"image_offsets":[]},{"id":{"replica_id":0,"value":41},"start":4349,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":269}},"image_offsets":[]},{"id":{"replica_id":0,"value":42},"start":7471,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":270}},"image_offsets":[]},{"id":{"replica_id":0,"value":110},"start":11721,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":271}},"image_offsets":[]},{"id":{"replica_id":0,"value":111},"start":14305,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":272}},"image_offsets":[]},{"id":{"replica_id":0,"value":188},"start":16133,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":273}},"image_offsets":[]},{"id":{"replica_id":0,"value":189},"start":19309,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":274}},"image_offsets":[]}],"summary":"Cache Usage and Document Consistency in Quickwit Fetch Docs Function","slash_command_output_sections":[{"range":{"start":0,"end":1},"icon":"Library","label":"Default"}]}