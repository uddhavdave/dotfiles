{"id":"020aa915-9ca2-4b63-b66f-10576f23aed5","zed":"context","version":"0.4.0","text":"\n\n\n```rs openobserve/src/config/src/meta/tantivy_inverted_index.rs\nuse std::{\n    io::{self, Write},\n    path::{Path, PathBuf},\n    sync::{Arc, LazyLock, RwLock},\n};\n\nuse ahash::HashSet;\nuse anyhow::{Context, Result};\nuse futures::{AsyncRead, AsyncSeek};\nuse itertools::Itertools;\nuse tantivy::{\n    directory::{error::OpenReadError, Directory, RamDirectory, WatchCallback, WatchHandle},\n    doc,\n    schema::Schema,\n    HasLen,\n};\n\nuse crate::{\n    get_config,\n    meta::puffin::{reader::PuffinBytesReader, writer::PuffinBytesWriter},\n};\n\n// This is an identifier for tantivy blobs inside puffin file.\n// Note: Tantivy blobs are not compressed.\nconst TANTIVY_INDEX_VERSION: &str = \"TIIv0.1.0\";\n\n// We do not need all of the tantivy files, only the .term and .idx files\n// for getting doc IDs and also the meta.json file\n// This might change in the future when we add more features to the index\nconst ALLOWED_FILE_EXT: &[&str] = &[\"term\", \"idx\", \"pos\"];\nconst META_JSON: &str = \"meta.json\";\n\n// Lazy loaded global instance of RAM directory which will contain\n// all the files of an empty tantivy index. This instance will be used to fill the missing files\n// from the `.ttv` file, as tantivy needs them regardless of the configuration of a field.\nstatic EMPTY_PUFFIN_DIRECTORY: LazyLock<PuffinDirectory> = LazyLock::new(|| {\n    let puffin_dir = PuffinDirectory::new();\n    let puffin_dir_clone = puffin_dir.clone();\n    let schema = Schema::builder().build();\n    let mut index_writer = tantivy::IndexBuilder::new()\n        .schema(schema)\n        .single_segment_index_writer(puffin_dir_clone, 50_000_000)\n        .unwrap();\n    let _ = index_writer.add_document(doc!());\n    index_writer.finalize().unwrap();\n    puffin_dir\n});\n\n/// Puffin directory is a puffin file which contains all the tantivy files.\n/// Each tantivy file is stored as a blob in the puffin file, along with their file name.\n#[derive(Debug)]\npub struct PuffinDirectory {\n    ram_directory: Arc<RamDirectory>,\n    /// record all the files paths in the puffin file\n    file_paths: Arc<RwLock<HashSet<PathBuf>>>,\n}\n\nimpl Clone for PuffinDirectory {\n    fn clone(&self) -> Self {\n        PuffinDirectory {\n            ram_directory: self.ram_directory.clone(),\n            file_paths: self.file_paths.clone(),\n        }\n    }\n}\n\npub fn convert_puffin_dir_to_tantivy_dir(\n    mut puffin_dir_path: PathBuf,\n    puffin_dir: PuffinDirectory,\n) {\n    // create directory\n    let cfg = get_config();\n    let file_name = puffin_dir_path.file_name().unwrap();\n    let mut file_name = file_name.to_os_string();\n    file_name.push(\".folder\");\n    puffin_dir_path.set_file_name(file_name);\n    let mut tantivy_folder_path = PathBuf::from(&cfg.common.data_stream_dir);\n    tantivy_folder_path.push(PathBuf::from(&puffin_dir_path));\n\n    // Check if the folder already exists\n    if !tantivy_folder_path.exists() {\n        std::fs::create_dir_all(&tantivy_folder_path).unwrap();\n        log::info!(\n            \"Created folder for index at {}\",\n            tantivy_folder_path.to_str().unwrap()\n        );\n    } else {\n        log::warn!(\n            \"Folder already exists for index at {}\",\n            tantivy_folder_path.to_str().unwrap()\n        );\n    }\n\n    for file in puffin_dir.list_files() {\n        let file_data = puffin_dir.open_read(&PathBuf::from(file.clone())).unwrap();\n        let mut file_handle = std::fs::OpenOptions::new()\n            .write(true)\n            .create(true)\n            .open(tantivy_folder_path.join(&file))\n            .unwrap();\n        file_handle\n            .write_all(&file_data.read_bytes().unwrap())\n            .unwrap();\n        file_handle.flush().unwrap();\n    }\n}\n\nimpl PuffinDirectory {\n    pub fn new() -> Self {\n        PuffinDirectory {\n            ram_directory: Arc::new(RamDirectory::create()),\n            file_paths: Arc::new(RwLock::new(HashSet::default())),\n        }\n    }\n\n    pub fn list_files(&self) -> Vec<PathBuf> {\n        self.file_paths\n            .read()\n            .expect(\"poisoned lock\")\n            .iter()\n            .cloned()\n            .collect()\n    }\n\n    // This function will serialize the directory into a single puffin file\n    pub fn to_puffin_bytes(&self) -> Result<Vec<u8>> {\n        let mut puffin_buf: Vec<u8> = Vec::new();\n        let mut puffin_writer = PuffinBytesWriter::new(&mut puffin_buf);\n        let empty_puffin_dir = &EMPTY_PUFFIN_DIRECTORY;\n        let mut segment_id = String::new();\n\n        let file_paths = self.file_paths.read().expect(\"poisoned lock\");\n        let allowed_file_paths = file_paths.iter().filter(|path| {\n            let mut allowed = false;\n            if let Some(path_ext) = path.extension() {\n                if ALLOWED_FILE_EXT.contains(&path_ext.to_str().unwrap()) {\n                    allowed = true;\n                }\n            }\n\n            // check if its meta.json file\n            if !allowed && path.to_str().unwrap() == META_JSON {\n                allowed = true;\n            };\n            allowed\n        });\n        for path in allowed_file_paths.clone() {\n            if segment_id.is_empty() && path.extension().is_some_and(|ext| ext != \"json\") {\n                segment_id = path.file_stem().unwrap().to_str().unwrap().to_owned();\n            }\n\n            let file_data = self.ram_directory.open_read(path)?;\n            log::debug!(\n                \"Serializing file to puffin: len: {}, path: {}\",\n                file_data.len(),\n                path.to_str().unwrap()\n            );\n            puffin_writer\n                .add_blob(\n                    &file_data\n                        .read_bytes()\n                        .expect(\"failed to read file\")\n                        .to_vec(),\n                    TANTIVY_INDEX_VERSION.to_string(),\n                    path.to_str().unwrap().to_owned(),\n                    false,\n                )\n                .context(\"Failed to add blob\")?;\n        }\n\n        let allowed_file_paths = allowed_file_paths.collect_vec();\n        // find the files which are present in the empty puffin dir instance and write them\n        // to the new puffin directory\n        for file in empty_puffin_dir\n            .list_files()\n            .iter()\n            .filter(|file_name| !file_name.extension().is_some_and(|ext| ext == \"json\"))\n        {\n            let mut empty_puffin_dir_path = PathBuf::from(&file);\n\n            // convert the empty puffin dir path to match the current dir file names\n            let ext = empty_puffin_dir_path.extension().unwrap().to_str().unwrap();\n            empty_puffin_dir_path.set_file_name(format!(\"{}.{}\", segment_id, ext));\n\n            // we skip the files which are already added\n            if allowed_file_paths.contains(&&empty_puffin_dir_path) {\n                continue;\n            }\n\n            let path = PathBuf::from(&file);\n            let file_data = empty_puffin_dir.open_read(&path)?;\n\n            log::debug!(\n                \"Substituting file for puffin dir: len: {}, path: {}\",\n                file_data.len(),\n                path.to_str().unwrap()\n            );\n\n            puffin_writer\n                .add_blob(\n                    &file_data\n                        .read_bytes()\n                        .expect(\"failed to read file\")\n                        .to_vec(),\n                    TANTIVY_INDEX_VERSION.to_string(),\n                    empty_puffin_dir_path.to_str().unwrap().to_owned(),\n                    false,\n                )\n                .context(\"Failed to add blob\")?;\n        }\n\n        puffin_writer.finish().context(\"Failed to finish writing\")?;\n        Ok(puffin_buf)\n    }\n\n    /// Open a puffin direcotry from the given bytes data\n    pub async fn from_bytes<R>(data: R) -> Result<Self>\n    where\n        R: AsyncRead + AsyncSeek + Unpin + Send,\n    {\n        let mut puffin_reader = PuffinBytesReader::new(data);\n        let puffin_dir = PuffinDirectory::new();\n\n        let puffin_meta = puffin_reader\n            .get_metadata()\n            .await\n            .context(\"Failed to get blobs meta\")?;\n\n        for blob_meta in puffin_meta.blob_metadata {\n            let blob = puffin_reader.read_blob_bytes(&blob_meta).await?;\n            // Fetch the files names from the blob_meta itself\n            if let Some(file_name) = blob_meta.properties.get(\"file_name\") {\n                let path = PathBuf::from(file_name);\n                let mut writer = puffin_dir\n                    .open_write(&path)\n                    .context(\"Failed to write to RAM directory\")?;\n                writer.write_all(&blob)?;\n                writer.flush()?;\n                puffin_dir.add_file_path(path);\n            }\n        }\n        Ok(puffin_dir)\n    }\n\n    fn add_file_path(&self, path: PathBuf) {\n        self.file_paths.write().unwrap().insert(path);\n    }\n}\n\n/// This implementation is used during index creation.\nimpl Directory for PuffinDirectory {\n    fn get_file_handle(\n        &self,\n        path: &Path,\n    ) -> Result<std::sync::Arc<dyn tantivy::directory::FileHandle>, OpenReadError> {\n        self.ram_directory.get_file_handle(path)\n    }\n\n    fn delete(&self, path: &Path) -> Result<(), tantivy::directory::error::DeleteError> {\n        self.ram_directory.delete(path)\n    }\n\n    fn exists(&self, path: &Path) -> Result<bool, OpenReadError> {\n        self.ram_directory.exists(path)\n    }\n\n    fn open_write(\n        &self,\n        path: &Path,\n    ) -> Result<tantivy::directory::WritePtr, tantivy::directory::error::OpenWriteError> {\n        // capture the files being written to ram directory\n        self.file_paths.write().unwrap().insert(path.to_path_buf());\n        self.ram_directory.open_write(path)\n    }\n\n    // this should read from the puffin source\n    fn atomic_read(&self, path: &Path) -> Result<Vec<u8>, OpenReadError> {\n        self.ram_directory.atomic_read(path)\n    }\n\n    fn atomic_write(&self, path: &Path, data: &[u8]) -> io::Result<()> {\n        // capture the files being written to ram directory\n        self.file_paths\n            .write()\n            .expect(\"poisoned lock\")\n            .insert(path.to_path_buf());\n        self.ram_directory.atomic_write(path, data)\n    }\n\n    fn sync_directory(&self) -> io::Result<()> {\n        self.ram_directory.sync_directory()\n    }\n\n    fn watch(&self, watch_callback: WatchCallback) -> tantivy::Result<WatchHandle> {\n        self.ram_directory.watch(watch_callback)\n    }\n}\n```\n\nI want to use the Puffin Directory in two modes, Read and write. When in write mode I want to be able to capture file from ram directory and serialize them to a puffin file. When in read mode, I want to open the puffin files and read from the puffin files using offset when its called using open_read or atomic_read\n\nTo achieve the functionality of using the `PuffinDirectory` in both read and write modes, you can introduce a mode enum and modify the `PuffinDirectory` struct to handle these modes appropriately. Here's how you can do it:\n\n1. **Define the Mode Enum**: Create an enum to represent the read and write modes.\n2. **Modify the `PuffinDirectory` Struct**: Add a field to store the current mode.\n3. **Adjust Methods Based on Mode**: Modify the methods to behave differently based on the mode.\n\nHere's the updated code:\n\n```rust\nuse std::{\n    io::{self, Write},\n    path::{Path, PathBuf},\n    sync::{Arc, LazyLock, RwLock},\n};\n\nuse ahash::HashSet;\nuse anyhow::{Context, Result};\nuse futures::{AsyncRead, AsyncSeek};\nuse itertools::Itertools;\nuse tantivy::{\n    directory::{error::OpenReadError, Directory, RamDirectory, WatchCallback, WatchHandle},\n    doc,\n    schema::Schema,\n    HasLen,\n};\n\nuse crate::{\n    get_config,\n    meta::puffin::{reader::PuffinBytesReader, writer::PuffinBytesWriter},\n};\n\n// This is an identifier for tantivy blobs inside puffin file.\n// Note: Tantivy blobs are not compressed.\nconst TANTIVY_INDEX_VERSION: &str = \"TIIv0.1.0\";\n\n// We do not need all of the tantivy files, only the .term and .idx files\n// for getting doc IDs and also the meta.json file\n// This might change in the future when we add more features to the index\nconst ALLOWED_FILE_EXT: &[&str] = &[\"term\", \"idx\", \"pos\"];\nconst META_JSON: &str = \"meta.json\";\n\n// Lazy loaded global instance of RAM directory which will contain\n// all the files of an empty tantivy index. This instance will be used to fill the missing files\n// from the `.ttv` file, as tantivy needs them regardless of the configuration of a field.\nstatic EMPTY_PUFFIN_DIRECTORY: LazyLock<PuffinDirectory> = LazyLock::new(|| {\n    let puffin_dir = PuffinDirectory::new(PuffinMode::Write);\n    let puffin_dir_clone = puffin_dir.clone();\n    let schema = Schema::builder().build();\n    let mut index_writer = tantivy::IndexBuilder::new()\n        .schema(schema)\n        .single_segment_index_writer(puffin_dir_clone, 50_000_000)\n        .unwrap();\n    let _ = index_writer.add_document(doc!());\n    index_writer.finalize().unwrap();\n    puffin_dir\n});\n\n/// Mode for PuffinDirectory\n#[derive(Debug, Clone, Copy)]\npub enum PuffinMode {\n    Read,\n    Write,\n}\n\n/// Puffin directory is a puffin file which contains all the tantivy files.\n/// Each tantivy file is stored as a blob in the puffin file, along with their file name.\n#[derive(Debug)]\npub struct PuffinDirectory {\n    ram_directory: Arc<RamDirectory>,\n    /// record all the files paths in the puffin file\n    file_paths: Arc<RwLock<HashSet<PathBuf>>>,\n    mode: PuffinMode,\n}\n\nimpl Clone for PuffinDirectory {\n    fn clone(&self) -> Self {\n        PuffinDirectory {\n            ram_directory: self.ram_directory.clone(),\n            file_paths: self.file_paths.clone(),\n            mode: self.mode,\n        }\n    }\n}\n\npub fn convert_puffin_dir_to_tantivy_dir(\n    mut puffin_dir_path: PathBuf,\n    puffin_dir: PuffinDirectory,\n) {\n    // create directory\n    let cfg = get_config();\n    let file_name = puffin_dir_path.file_name().unwrap();\n    let mut file_name = file_name.to_os_string();\n    file_name.push(\".folder\");\n    puffin_dir_path.set_file_name(file_name);\n    let mut tantivy_folder_path = PathBuf::from(&cfg.common.data_stream_dir);\n    tantivy_folder_path.push(PathBuf::from(&puffin_dir_path));\n\n    // Check if the folder already exists\n    if !tantivy_folder_path.exists() {\n        std::fs::create_dir_all(&tantivy_folder_path).unwrap();\n        log::info!(\n            \"Created folder for index at {}\",\n            tantivy_folder_path.to_str().unwrap()\n        );\n    } else {\n        log::warn!(\n            \"Folder already exists for index at {}\",\n            tantivy_folder_path.to_str().unwrap()\n        );\n    }\n\n    for file in puffin_dir.list_files() {\n        let file_data = puffin_dir.open_read(&PathBuf::from(file.clone())).unwrap();\n        let mut file_handle = std::fs::OpenOptions::new()\n            .write(true)\n            .create(true)\n            .open(tantivy_folder_path.join(&file))\n            .unwrap();\n        file_handle\n            .write_all(&file_data.read_bytes().unwrap())\n            .unwrap();\n        file_handle.flush().unwrap();\n    }\n}\n\nimpl PuffinDirectory {\n    pub fn new(mode: PuffinMode) -> Self {\n        PuffinDirectory {\n            ram_directory: Arc::new(RamDirectory::create()),\n            file_paths: Arc::new(RwLock::new(HashSet::default())),\n            mode,\n        }\n    }\n\n    pub fn list_files(&self) -> Vec<PathBuf> {\n        self.file_paths\n            .read()\n            .expect(\"poisoned lock\")\n            .iter()\n            .cloned()\n            .collect()\n    }\n\n    // This function will serialize the directory into a single puffin file\n    pub fn to_puffin_bytes(&self) -> Result<Vec<u8>> {\n        let mut puffin_buf: Vec<u8> = Vec::new();\n        let mut puffin_writer = PuffinBytesWriter::new(&mut puffin_buf);\n        let empty_puffin_dir = &EMPTY_PUFFIN_DIRECTORY;\n        let mut segment_id = String::new();\n\n        let file_paths = self.file_paths.read().expect(\"poisoned lock\");\n        let allowed_file_paths = file_paths.iter().filter(|path| {\n            let mut allowed = false;\n            if let Some(path_ext) = path.extension() {\n                if ALLOWED_FILE_EXT.contains(&path_ext.to_str().unwrap()) {\n                    allowed = true;\n                }\n            }\n\n            // check if its meta.json file\n            if !allowed && path.to_str().unwrap() == META_JSON {\n                allowed = true;\n            };\n            allowed\n        });\n        for path in allowed_file_paths.clone() {\n            if segment_id.is_empty() && path.extension().is_some_and(|ext| ext != \"json\") {\n                segment_id = path.file_stem().unwrap().to_str().unwrap().to_owned();\n            }\n\n            let file_data = self.ram_directory.open_read(path)?;\n            log::debug!(\n                \"Serializing file to puffin: len: {}, path: {}\",\n                file_data.len(),\n                path.to_str().unwrap()\n            );\n            puffin_writer\n                .add_blob(\n                    &file_data\n                        .read_bytes()\n                        .expect(\"failed to read file\")\n                        .to_vec(),\n                    TANTIVY_INDEX_VERSION.to_string(),\n                    path.to_str().unwrap().to_owned(),\n                    false,\n                )\n                .context(\"Failed to add blob\")?;\n        }\n\n        let allowed_file_paths = allowed_file_paths.collect_vec();\n        // find the files which are present in the empty puffin dir instance and write them\n        // to the new puffin directory\n        for file in empty_puffin_dir\n            .list_files()\n            .iter()\n            .filter(|file_name| !file_name.extension().is_some_and(|ext| ext == \"json\"))\n        {\n            let mut empty_puffin_dir_path = PathBuf::from(&file);\n\n            // convert the empty puffin dir path to match the current dir file names\n            let ext = empty_puffin_dir_path.extension().unwrap().to_str().unwrap();\n            empty_puffin_dir_path.set_file_name(format!(\"{}.{}\", segment_id, ext));\n\n            // we skip the files which are already added\n            if allowed_file_paths.contains(&&empty_puffin_dir_path) {\n                continue;\n            }\n\n            let path = PathBuf::from(&file);\n            let file_data = empty_puffin_dir.open_read(&path)?;\n\n            log::debug!(\n                \"Substituting file for puffin dir: len: {}, path: {}\",\n                file_data.len(),\n                path.to_str().unwrap()\n            );\n\n            puffin_writer\n                .add_blob(\n                    &file_data\n                        .read_bytes()\n                        .expect(\"failed to read file\")\n                        .to_vec(),\n                    TANTIVY_INDEX_VERSION.to_string(),\n                    empty_puffin_dir_path.to_str().unwrap().to_owned(),\n                    false,\n                )\n                .context(\"Failed to add blob\")?;\n        }\n\n        puffin_writer.finish().context(\"Failed to finish writing\")?;\n        Ok(puffin_buf)\n    }\n\n    /// Open a puffin directory from the given bytes data\n    pub async fn from_bytes<R>(data: R) -> Result<Self>\n    where\n        R: AsyncRead + AsyncSeek + Unpin + Send,\n    {\n        let mut puffin_reader = PuffinBytesReader::new(data);\n        let puffin_dir = PuffinDirectory::new(PuffinMode::Read);\n\n        let puffin_meta = puffin_reader\n            .get_metadata()\n            .await\n            .context(\"Failed to get blobs meta\")?;\n\n        for blob_meta in puffin_meta.blob_metadata {\n            let blob = puffin_reader.read_blob_bytes(&blob_meta).await?;\n            // Fetch the files names from the blob_meta itself\n            if let Some(file_name) = blob_meta.properties.get(\"file_name\") {\n                let path = PathBuf::from(file_name);\n                let mut writer = puffin_dir\n                    .open_write(&path)\n                    .context(\"Failed to write to RAM directory\")?;\n                writer.write_all(&blob)?;\n                writer.flush()?;\n                puffin_dir.add_file_path(path);\n            }\n        }\n        Ok(puffin_dir)\n    }\n\n    fn add_file_path(&self, path: PathBuf) {\n        self.file_paths.write().unwrap().insert(path);\n    }\n}\n\n/// This implementation is used during index creation.\nimpl Directory for PuffinDirectory {\n    fn get_file_handle(\n        &self,\n        path: &Path,\n    ) -> Result<std::sync::Arc<dyn tantivy::directory::FileHandle>, OpenReadError> {\n        self.ram_directory.get_file_handle(path)\n    }\n\n    fn delete(&self, path: &Path) -> Result<(), tantivy::directory::error::DeleteError> {\n        self.ram_directory.delete(path)\n    }\n\n    fn exists(&self, path: &Path) -> Result<bool, OpenReadError> {\n        self.ram_directory.exists(path)\n    }\n\n    fn open_write(\n        &self,\n        path: &Path,\n    ) -> Result<tantivy::directory::WritePtr, tantivy::directory::error::OpenWriteError> {\n        // capture the files being written to ram directory\n        self.file_paths.write().unwrap().insert(path.to_path_buf());\n        self.ram_directory.open_write(path)\n    }\n\n    // this should read from the puffin source\n    fn atomic_read(&self, path: &Path) -> Result<Vec<u8>, OpenReadError> {\n        match self.mode {\n            PuffinMode::Read => {\n                // Implement reading from the puffin file using offset\n                // This is a placeholder, you need to implement the actual logic\n                Err(OpenReadError::FileDoesNotExist(path.to_path_buf()))\n            }\n            PuffinMode::Write => self.ram_directory.atomic_read(path),\n        }\n    }\n\n    fn atomic_write(&self, path: &Path, data: &[u8]) -> io::Result<()> {\n        // capture the files being written to ram directory\n        self.file_paths\n            .write()\n            .expect(\"poisoned lock\")\n            .insert(path.to_path_buf());\n        self.ram_directory.atomic_write(path, data)\n    }\n\n    fn sync_directory(&self) -> io::Result<()> {\n        self.ram_directory.sync_directory()\n    }\n\n    fn watch(&self, watch_callback: WatchCallback) -> tantivy::Result<WatchHandle> {\n        self.ram_directory.watch(watch_callback)\n    }\n}\n```\n\n### Explanation:\n\n1. **Mode Enum**: The `PuffinMode` enum is introduced to distinguish between read and write modes.\n2. **PuffinDirectory Struct**: The `mode` field is added to the `PuffinDirectory` struct to store the current mode.\n3. **Constructor**: The `new` method now takes a `PuffinMode` parameter to set the mode.\n4. **atomic_read Method**: The `atomic_read` method is modified to behave differently based on the mode. In read mode, you need to implement the logic to read from the puffin file using offsets. The current implementation is a placeholder and returns an error.\n\nYou will need to implement the actual logic for reading from the puffin file using offsets in the `atomic_read` method when in read mode. This involves managing the offsets and reading the appropriate bytes from the puffin file.\nis using generics a better approach here? when using new function open the directory in write mode and when using from bytes open the directory in read mode.\n\nUsing generics can indeed be a more elegant and type-safe approach to distinguish between read and write modes for the `PuffinDirectory`. By leveraging Rust's type system, you can ensure that certain methods are only available in specific modes, reducing the risk of runtime errors.\n\nHere's how you can refactor the code to use generics for read and write modes:\n\n1. **Define Mode Traits**: Create traits for read and write modes.\n2. **Implement Mode-Specific Methods**: Implement methods specific to each mode.\n3. **Use Generics in `PuffinDirectory`**: Use generics to parameterize the `PuffinDirectory` with the mode.\n\n### Step 1: Define Mode Traits\n\n```rust\npub trait PuffinMode {}\n\npub struct ReadMode;\npub struct WriteMode;\n\nimpl PuffinMode for ReadMode {}\nimpl PuffinMode for WriteMode {}\n```\n\n### Step 2: Implement Mode-Specific Methods\n\n```rust\nuse std::{\n    io::{self, Write},\n    path::{Path, PathBuf},\n    sync::{Arc, LazyLock, RwLock},\n};\n\nuse ahash::HashSet;\nuse anyhow::{Context, Result};\nuse futures::{AsyncRead, AsyncSeek};\nuse itertools::Itertools;\nuse tantivy::{\n    directory::{error::OpenReadError, Directory, RamDirectory, WatchCallback, WatchHandle},\n    doc,\n    schema::Schema,\n    HasLen,\n};\n\nuse crate::{\n    get_config,\n    meta::puffin::{reader::PuffinBytesReader, writer::PuffinBytesWriter},\n};\n\n// This is an identifier for tantivy blobs inside puffin file.\n// Note: Tantivy blobs are not compressed.\nconst TANTIVY_INDEX_VERSION: &str = \"TIIv0.1.0\";\n\n// We do not need all of the tantivy files, only the .term and .idx files\n// for getting doc IDs and also the meta.json file\n// This might change in the future when we add more features to the index\nconst ALLOWED_FILE_EXT: &[&str] = &[\"term\", \"idx\", \"pos\"];\nconst META_JSON: &str = \"meta.json\";\n\n// Lazy loaded global instance of RAM directory which will contain\n// all the files of an empty tantivy index. This instance will be used to fill the missing files\n// from the `.ttv` file, as tantivy needs them regardless of the configuration of a field.\nstatic EMPTY_PUFFIN_DIRECTORY: LazyLock<PuffinDirectory<WriteMode>> = LazyLock::new(|| {\n    let puffin_dir = PuffinDirectory::new();\n    let puffin_dir_clone = puffin_dir.clone();\n    let schema = Schema::builder().build();\n    let mut index_writer = tantivy::IndexBuilder::new()\n        .schema(schema)\n        .single_segment_index_writer(puffin_dir_clone, 50_000_000)\n        .unwrap();\n    let _ = index_writer.add_document(doc!());\n    index_writer.finalize().unwrap();\n    puffin_dir\n});\n\n/// Puffin directory is a puffin file which contains all the tantivy files.\n/// Each tantivy file is stored as a blob in the puffin file, along with their file name.\n#[derive(Debug)]\npub struct PuffinDirectory<M: PuffinMode> {\n    ram_directory: Arc<RamDirectory>,\n    /// record all the files paths in the puffin file\n    file_paths: Arc<RwLock<HashSet<PathBuf>>>,\n    _mode: std::marker::PhantomData<M>,\n}\n\nimpl<M: PuffinMode> Clone for PuffinDirectory<M> {\n    fn clone(&self) -> Self {\n        PuffinDirectory {\n            ram_directory: self.ram_directory.clone(),\n            file_paths: self.file_paths.clone(),\n            _mode: std::marker::PhantomData,\n        }\n    }\n}\n\npub fn convert_puffin_dir_to_tantivy_dir(\n    mut puffin_dir_path: PathBuf,\n    puffin_dir: PuffinDirectory<ReadMode>,\n) {\n    // create directory\n    let cfg = get_config();\n    let file_name = puffin_dir_path.file_name().unwrap();\n    let mut file_name = file_name.to_os_string();\n    file_name.push(\".folder\");\n    puffin_dir_path.set_file_name(file_name);\n    let mut tantivy_folder_path = PathBuf::from(&cfg.common.data_stream_dir);\n    tantivy_folder_path.push(PathBuf::from(&puffin_dir_path));\n\n    // Check if the folder already exists\n    if !tantivy_folder_path.exists() {\n        std::fs::create_dir_all(&tantivy_folder_path).unwrap();\n        log::info!(\n            \"Created folder for index at {}\",\n            tantivy_folder_path.to_str().unwrap()\n        );\n    } else {\n        log::warn!(\n            \"Folder already exists for index at {}\",\n            tantivy_folder_path.to_str().unwrap()\n        );\n    }\n\n    for file in puffin_dir.list_files() {\n        let file_data = puffin_dir.open_read(&PathBuf::from(file.clone())).unwrap();\n        let mut file_handle = std::fs::OpenOptions::new()\n            .write(true)\n            .create(true)\n            .open(tantivy_folder_path.join(&file))\n            .unwrap();\n        file_handle\n            .write_all(&file_data.read_bytes().unwrap())\n            .unwrap();\n        file_handle.flush().unwrap();\n    }\n}\n\nimpl PuffinDirectory<WriteMode> {\n    pub fn new() -> Self {\n        PuffinDirectory {\n            ram_directory: Arc::new(RamDirectory::create()),\n            file_paths: Arc::new(RwLock::new(HashSet::default())),\n            _mode: std::marker::PhantomData,\n        }\n    }\n\n    pub fn list_files(&self) -> Vec<PathBuf> {\n        self.file_paths\n            .read()\n            .expect(\"poisoned lock\")\n            .iter()\n            .cloned()\n            .collect()\n    }\n\n    // This function will serialize the directory into a single puffin file\n    pub fn to_puffin_bytes(&self) -> Result<Vec<u8>> {\n        let mut puffin_buf: Vec<u8> = Vec::new();\n        let mut puffin_writer = PuffinBytesWriter::new(&mut puffin_buf);\n        let empty_puffin_dir = &EMPTY_PUFFIN_DIRECTORY;\n        let mut segment_id = String::new();\n\n        let file_paths = self.file_paths.read().expect(\"poisoned lock\");\n        let allowed_file_paths = file_paths.iter().filter(|path| {\n            let mut allowed = false;\n            if let Some(path_ext) = path.extension() {\n                if ALLOWED_FILE_EXT.contains(&path_ext.to_str().unwrap()) {\n                    allowed = true;\n                }\n            }\n\n            // check if its meta.json file\n            if !allowed && path.to_str().unwrap() == META_JSON {\n                allowed = true;\n            };\n            allowed\n        });\n        for path in allowed_file_paths.clone() {\n            if segment_id.is_empty() && path.extension().is_some_and(|ext| ext != \"json\") {\n                segment_id = path.file_stem().unwrap().to_str().unwrap().to_owned();\n            }\n\n            let file_data = self.ram_directory.open_read(path)?;\n            log::debug!(\n                \"Serializing file to puffin: len: {}, path: {}\",\n                file_data.len(),\n                path.to_str().unwrap()\n            );\n            puffin_writer\n                .add_blob(\n                    &file_data\n                        .read_bytes()\n                        .expect(\"failed to read file\")\n                        .to_vec(),\n                    TANTIVY_INDEX_VERSION.to_string(),\n                    path.to_str().unwrap().to_owned(),\n                    false,\n                )\n                .context(\"Failed to add blob\")?;\n        }\n\n        let allowed_file_paths = allowed_file_paths.collect_vec();\n        // find the files which are present in the empty puffin dir instance and write them\n        // to the new puffin directory\n        for file in empty_puffin_dir\n            .list_files()\n            .iter()\n            .filter(|file_name| !file_name.extension().is_some_and(|ext| ext == \"json\"))\n        {\n            let mut empty_puffin_dir_path = PathBuf::from(&file);\n\n            // convert the empty puffin dir path to match the current dir file names\n            let ext = empty_puffin_dir_path.extension().unwrap().to_str().unwrap();\n            empty_puffin_dir_path.set_file_name(format!(\"{}.{}\", segment_id, ext));\n\n            // we skip the files which are already added\n            if allowed_file_paths.contains(&&empty_puffin_dir_path) {\n                continue;\n            }\n\n            let path = PathBuf::from(&file);\n            let file_data = empty_puffin_dir.open_read(&path)?;\n\n            log::debug!(\n                \"Substituting file for puffin dir: len: {}, path: {}\",\n                file_data.len(),\n                path.to_str().unwrap()\n            );\n\n            puffin_writer\n                .add_blob(\n                    &file_data\n                        .read_bytes()\n                        .expect(\"failed to read file\")\n                        .to_vec(),\n                    TANTIVY_INDEX_VERSION.to_string(),\n                    empty_puffin_dir_path.to_str().unwrap().to_owned(),\n                    false,\n                )\n                .context(\"Failed to add blob\")?;\n        }\n\n        puffin_writer.finish().context(\"Failed to finish writing\")?;\n        Ok(puffin_buf)\n    }\n}\n\nimpl PuffinDirectory<ReadMode> {\n    /// Open a puffin directory from the given bytes data\n    pub async fn from_bytes<R>(data: R) -> Result<Self>\n    where\n        R: AsyncRead + AsyncSeek + Unpin + Send,\n    {\n        let mut puffin_reader = PuffinBytesReader::new(data);\n        let puffin_dir = PuffinDirectory {\n            ram_directory: Arc::new(RamDirectory::create()),\n            file_paths: Arc::new(RwLock::new(HashSet::default())),\n            _mode: std::marker::PhantomData,\n        };\n\n        let puffin_meta = puffin_reader\n            .get_metadata()\n            .await\n            .context(\"Failed to get blobs meta\")?;\n\n        for blob_meta in puffin_meta.blob_metadata {\n            let blob = puffin_reader.read_blob_bytes(&blob_meta).await?;\n            // Fetch the files names from the blob_meta itself\n            if let Some(file_name) = blob_meta.properties.get(\"file_name\") {\n                let path = PathBuf::from(file_name);\n                let mut writer = puffin_dir\n                    .open_write(&path)\n                    .context(\"Failed to write to RAM directory\")?;\n                writer.write_all(&blob)?;\n                writer.flush()?;\n                puffin_dir.add_file_path(path);\n            }\n        }\n        Ok(puffin_dir)\n    }\n\n    fn add_file_path(&self, path: PathBuf) {\n        self.file_paths.write().unwrap().insert(path);\n    }\n}\n\n/// This implementation is used during index creation.\nimpl<M: PuffinMode> Directory for PuffinDirectory<M> {\n    fn get_file_handle(\n        &self,\n        path: &Path,\n    ) -> Result<std::sync::Arc<dyn tantivy::directory::FileHandle>, OpenReadError> {\n        self.ram_directory.get_file_handle(path)\n    }\n\n    fn delete(&self, path: &Path) -> Result<(), tantivy::directory::error::DeleteError> {\n        self.ram_directory.delete(path)\n    }\n\n    fn exists(&self, path: &Path) -> Result<bool, OpenReadError> {\n        self.ram_directory.exists(path)\n    }\n\n    fn open_write(\n        &self,\n        path: &Path,\n    ) -> Result<tantivy::directory::WritePtr, tantivy::directory::error::OpenWriteError> {\n        // capture the files being written to ram directory\n        self.file_paths.write().unwrap().insert(path.to_path_buf());\n        self.ram_directory.open_write(path)\n    }\n\n    // this should read from the puffin source\n    fn atomic_read(&self, path: &Path) -> Result<Vec<u8>, OpenReadError> {\n        self.ram_directory.atomic_read(path)\n    }\n\n    fn atomic_write(&self, path: &Path, data: &[u8]) -> io::Result<()> {\n        // capture the files being written to ram directory\n        self.file_paths\n            .write()\n            .expect(\"poisoned lock\")\n            .insert(path.to_path_buf());\n        self.ram_directory.atomic_write(path, data)\n    }\n\n    fn sync_directory(&self) -> io::Result<()> {\n        self.ram_directory.sync_directory()\n    }\n\n    fn watch(&self, watch_callback: WatchCallback) -> tantivy::Result<WatchHandle> {\n        self.ram_directory.watch(watch_callback)\n    }\n}\n```\n\n### Explanation:\n\n1. **Mode Traits**: `PuffinMode` is a trait implemented by `ReadMode` and `WriteMode`.\n2. **Generic Parameter**: `PuffinDirectory` is now generic over `M: PuffinMode`.\n3. **Mode-Specific Methods**: Methods like `to_puffin_bytes` and `from_bytes` are implemented only for the specific modes they are relevant to.\n4. **PhantomData**: The `_mode` field is used to hold the generic type parameter without actually storing any data of that type.\n\nBy using generics, you ensure that the `PuffinDirectory` is used correctly in either read or write mode, and you get compile-time guarantees about the mode-specific behavior.\nI do not want to use RamDirectory when in Read mode, I just want to store offsets/blob metadata in the `from_bytes` function and when the `open_read` function is called, I want to read the blob metadata , get the offset and read the blob from the source\n\nTo achieve this, you can modify the `PuffinDirectory` to store offsets and blob metadata when in read mode, and then use this information to read the blobs directly from the source when `open_read` is called. Here's how you can do it:\n\n1. **Define Mode Traits**: Create traits for read and write modes.\n2. **Implement Mode-Specific Methods**: Implement methods specific to each mode.\n3. **Use Generics in `PuffinDirectory`**: Use generics to parameterize the `PuffinDirectory` with the mode.\n4. **Store Offsets and Blob Metadata**: In read mode, store offsets and blob metadata instead of using `RamDirectory`.\n\n### Step 1: Define Mode Traits\n\n```rust\npub trait PuffinMode {}\n\npub struct ReadMode;\npub struct WriteMode;\n\nimpl PuffinMode for ReadMode {}\nimpl PuffinMode for WriteMode {}\n```\n\n### Step 2: Implement Mode-Specific Methods\n\n```rust\nuse std::{\n    io::{self, Write},\n    path::{Path, PathBuf},\n    sync::{Arc, LazyLock, RwLock},\n};\n\nuse ahash::HashSet;\nuse anyhow::{Context, Result};\nuse futures::{AsyncRead, AsyncSeek};\nuse itertools::Itertools;\nuse tantivy::{\n    directory::{error::OpenReadError, Directory, RamDirectory, WatchCallback, WatchHandle},\n    doc,\n    schema::Schema,\n    HasLen,\n};\n\nuse crate::{\n    get_config,\n    meta::puffin::{reader::PuffinBytesReader, writer::PuffinBytesWriter},\n};\n\n// This is an identifier for tantivy blobs inside puffin file.\n// Note: Tantivy blobs are not compressed.\nconst TANTIVY_INDEX_VERSION: &str = \"TIIv0.1.0\";\n\n// We do not need all of the tantivy files, only the .term and .idx files\n// for getting doc IDs and also the meta.json file\n// This might change in the future when we add more features to the index\nconst ALLOWED_FILE_EXT: &[&str] = &[\"term\", \"idx\", \"pos\"];\nconst META_JSON: &str = \"meta.json\";\n\n// Lazy loaded global instance of RAM directory which will contain\n// all the files of an empty tantivy index. This instance will be used to fill the missing files\n// from the `.ttv` file, as tantivy needs them regardless of the configuration of a field.\nstatic EMPTY_PUFFIN_DIRECTORY: LazyLock<PuffinDirectory<WriteMode>> = LazyLock::new(|| {\n    let puffin_dir = PuffinDirectory::new();\n    let puffin_dir_clone = puffin_dir.clone();\n    let schema = Schema::builder().build();\n    let mut index_writer = tantivy::IndexBuilder::new()\n        .schema(schema)\n        .single_segment_index_writer(puffin_dir_clone, 50_000_000)\n        .unwrap();\n    let _ = index_writer.add_document(doc!());\n    index_writer.finalize().unwrap();\n    puffin_dir\n});\n\n/// Puffin directory is a puffin file which contains all the tantivy files.\n/// Each tantivy file is stored as a blob in the puffin file, along with their file name.\n#[derive(Debug)]\npub struct PuffinDirectory<M: PuffinMode> {\n    ram_directory: Option<Arc<RamDirectory>>,\n    /// record all the files paths in the puffin file\n    file_paths: Arc<RwLock<HashSet<PathBuf>>>,\n    blob_metadata: Option<Arc<RwLock<HashMap<PathBuf, BlobMeta>>>>,\n    _mode: std::marker::PhantomData<M>,\n}\n\nimpl<M: PuffinMode> Clone for PuffinDirectory<M> {\n    fn clone(&self) -> Self {\n        PuffinDirectory {\n            ram_directory: self.ram_directory.clone(),\n            file_paths: self.file_paths.clone(),\n            blob_metadata: self.blob_metadata.clone(),\n            _mode: std::marker::PhantomData,\n        }\n    }\n}\n\npub fn convert_puffin_dir_to_tantivy_dir(\n    mut puffin_dir_path: PathBuf,\n    puffin_dir: PuffinDirectory<ReadMode>,\n) {\n    // create directory\n    let cfg = get_config();\n    let file_name = puffin_dir_path.file_name().unwrap();\n    let mut file_name = file_name.to_os_string();\n    file_name.push(\".folder\");\n    puffin_dir_path.set_file_name(file_name);\n    let mut tantivy_folder_path = PathBuf::from(&cfg.common.data_stream_dir);\n    tantivy_folder_path.push(PathBuf::from(&puffin_dir_path));\n\n    // Check if the folder already exists\n    if !tantivy_folder_path.exists() {\n        std::fs::create_dir_all(&tantivy_folder_path).unwrap();\n        log::info!(\n            \"Created folder for index at {}\",\n            tantivy_folder_path.to_str().unwrap()\n        );\n    } else {\n        log::warn!(\n            \"Folder already exists for index at {}\",\n            tantivy_folder_path.to_str().unwrap()\n        );\n    }\n\n    for file in puffin_dir.list_files() {\n        let file_data = puffin_dir.open_read(&PathBuf::from(file.clone())).unwrap();\n        let mut file_handle = std::fs::OpenOptions::new()\n            .write(true)\n            .create(true)\n            .open(tantivy_folder_path.join(&file))\n            .unwrap();\n        file_handle\n            .write_all(&file_data.read_bytes().unwrap())\n            .unwrap();\n        file_handle.flush().unwrap();\n    }\n}\n\nimpl PuffinDirectory<WriteMode> {\n    pub fn new() -> Self {\n        PuffinDirectory {\n            ram_directory: Some(Arc::new(RamDirectory::create())),\n            file_paths: Arc::new(RwLock::new(HashSet::default())),\n            blob_metadata: None,\n            _mode: std::marker::PhantomData,\n        }\n    }\n\n    pub fn list_files(&self) -> Vec<PathBuf> {\n        self.file_paths\n            .read()\n            .expect(\"poisoned lock\")\n            .iter()\n            .cloned()\n            .collect()\n    }\n\n    // This function will serialize the directory into a single puffin file\n    pub fn to_puffin_bytes(&self) -> Result<Vec<u8>> {\n        let mut puffin_buf: Vec<u8> = Vec::new();\n        let mut puffin_writer = PuffinBytesWriter::new(&mut puffin_buf);\n        let empty_puffin_dir = &EMPTY_PUFFIN_DIRECTORY;\n        let mut segment_id = String::new();\n\n        let file_paths = self.file_paths.read().expect(\"poisoned lock\");\n        let allowed_file_paths = file_paths.iter().filter(|path| {\n            let mut allowed = false;\n            if let Some(path_ext) = path.extension() {\n                if ALLOWED_FILE_EXT.contains(&path_ext.to_str().unwrap()) {\n                    allowed = true;\n                }\n            }\n\n            // check if its meta.json file\n            if !allowed && path.to_str().unwrap() == META_JSON {\n                allowed = true;\n            };\n            allowed\n        });\n        for path in allowed_file_paths.clone() {\n            if segment_id.is_empty() && path.extension().is_some_and(|ext| ext != \"json\") {\n                segment_id = path.file_stem().unwrap().to_str().unwrap().to_owned();\n            }\n\n            let file_data = self.ram_directory.as_ref().unwrap().open_read(path)?;\n            log::debug!(\n                \"Serializing file to puffin: len: {}, path: {}\",\n                file_data.len(),\n                path.to_str().unwrap()\n            );\n            puffin_writer\n                .add_blob(\n                    &file_data\n                        .read_bytes()\n                        .expect(\"failed to read file\")\n                        .to_vec(),\n                    TANTIVY_INDEX_VERSION.to_string(),\n                    path.to_str().unwrap().to_owned(),\n                    false,\n                )\n                .context(\"Failed to add blob\")?;\n        }\n\n        let allowed_file_paths = allowed_file_paths.collect_vec();\n        // find the files which are present in the empty puffin dir instance and write them\n        // to the new puffin directory\n        for file in empty_puffin_dir\n            .list_files()\n            .iter()\n            .filter(|file_name| !file_name.extension().is_some_and(|ext| ext == \"json\"))\n        {\n            let mut empty_puffin_dir_path = PathBuf::from(&file);\n\n            // convert the empty puffin dir path to match the current dir file names\n            let ext = empty_puffin_dir_path.extension().unwrap().to_str().unwrap();\n            empty_puffin_dir_path.set_file_name(format!(\"{}.{}\", segment_id, ext));\n\n            // we skip the files which are already added\n            if allowed_file_paths.contains(&&empty_puffin_dir_path) {\n                continue;\n            }\n\n            let path = PathBuf::from(&file);\n            let file_data = empty_puffin_dir.open_read(&path)?;\n\n            log::debug!(\n                \"Substituting file for puffin dir: len: {}, path: {}\",\n                file_data.len(),\n                path.to_str().unwrap()\n            );\n\n            puffin_writer\n                .add_blob(\n                    &file_data\n                        .read_bytes()\n                        .expect(\"failed to read file\")\n                        .to_vec(),\n                    TANTIVY_INDEX_VERSION.to_string(),\n                    empty_puffin_dir_path.to_str().unwrap().to_owned(),\n                    false,\n                )\n                .context(\"Failed to add blob\")?;\n        }\n\n        puffin_writer.finish().context(\"Failed to finish writing\")?;\n        Ok(puffin_buf)\n    }\n}\n\nimpl PuffinDirectory<ReadMode> {\n    /// Open a puffin directory from the given bytes data\n    pub async fn from_bytes<R>(data: R) -> Result<Self>\n    where\n        R: AsyncRead + AsyncSeek + Unpin + Send,\n    {\n        let mut puffin_reader = PuffinBytesReader::new(data);\n        let puffin_dir = PuffinDirectory {\n            ram_directory: None,\n            file_paths: Arc::new(RwLock::new(HashSet::default())),\n            blob_metadata: Some(Arc::new(RwLock::new(HashMap::default()))),\n            _mode: std::marker::PhantomData,\n        };\n\n        let puffin_meta = puffin_reader\n            .get_metadata()\n            .await\n            .context(\"Failed to get blobs meta\")?;\n\n        for blob_meta in puffin_meta.blob_metadata {\n            let blob = puffin_reader.read_blob_bytes(&blob_meta).await?;\n            // Fetch the files names from the blob_meta itself\n            if let Some(file_name) = blob_meta.properties.get(\"file_name\") {\n                let path = PathBuf::from(file_name);\n                puffin_dir.add_file_path(path.clone());\n                puffin_dir.add_blob_metadata(path, blob_meta);\n            }\n        }\n        Ok(puffin_dir)\n    }\n\n    fn add_file_path(&self, path: PathBuf) {\n        self.file_paths.write().unwrap().insert(path);\n    }\n\n    fn add_blob_metadata(&self, path: PathBuf, blob_meta: BlobMeta) {\n        self.blob_metadata\n            .as_ref()\n            .unwrap()\n            .write()\n            .unwrap()\n            .insert(path, blob_meta);\n    }\n}\n\n/// This implementation is used during index creation.\nimpl<M: PuffinMode> Directory for PuffinDirectory<M> {\n    fn get_file_handle(\n        &self,\n        path: &Path,\n    ) -> Result<std::sync::Arc<dyn tantivy::directory::FileHandle>, OpenReadError> {\n        match &self.ram_directory {\n            Some(ram_directory) => ram_directory.get_file_handle(path),\n            None => Err(OpenReadError::FileDoesNotExist(path.to_path_buf())),\n        }\n    }\n\n    fn delete(&self, path: &Path) -> Result<(), tantivy::directory::error::DeleteError> {\n        match &self.ram_directory {\n            Some(ram_directory) => ram_directory.delete(path),\n            None => Err(tantivy::directory::error::DeleteError::FileDoesNotExist(\n                path.to_path_buf(),\n            )),\n        }\n    }\n\n    fn exists(&self, path: &Path) -> Result<bool, OpenReadError> {\n        match &self.ram_directory {\n            Some(ram_directory) => ram_directory.exists(path),\n            None => Ok(self.file_paths.read().unwrap().contains(path)),\n        }\n    }\n\n    fn open_write(\n        &self,\n        path: &Path,\n    ) -> Result<tantivy::directory::WritePtr, tantivy::directory::error::OpenWriteError> {\n        match &self.ram_directory {\n            Some(ram_directory) => {\n                self.file_paths.write().unwrap().insert(path.to_path_buf());\n                ram_directory.open_write(path)\n            }\n            None => Err(tantivy::directory::error::OpenWriteError::FileAlreadyExists(\n                path.to_path_buf(),\n            )),\n        }\n    }\n\n    fn atomic_read(&self, path: &Path) -> Result<Vec<u8>, OpenReadError> {\n        match &self.ram_directory {\n            Some(ram_directory) => ram_directory.atomic_read(path),\n            None => {\n                let blob_meta = self\n                    .blob_metadata\n                    .as_ref()\n                    .unwrap()\n                    .read()\n                    .unwrap()\n                    .get(path)\n                    .ok_or(OpenReadError::FileDoesNotExist(path.to_path_buf()))?;\n                let mut puffin_reader = PuffinBytesReader::new(blob_meta.clone());\n                let blob = puffin_reader.read_blob_bytes(blob_meta).await?;\n                Ok(blob)\n            }\n        }\n    }\n\n    fn atomic_write(&self, path: &Path, data: &[u8]) -> io::Result<()> {\n        match &self.ram_directory {\n            Some(ram_directory) => {\n                self.file_paths\n                    .write()\n                    .expect(\"poisoned lock\")\n                    .insert(path.to_path_buf());\n                ram_directory.atomic_write(path, data)\n            }\n            None => Err(io::Error::new(\n                io::ErrorKind::Other,\n                \"Cannot write in read mode\",\n            )),\n        }\n    }\n\n    fn sync_directory(&self) -> io::Result<()> {\n        match &self.ram_directory {\n            Some(ram_directory) => ram_directory.sync_directory(),\n            None => Ok(()),\n        }\n    }\n\n    fn watch(&self, watch_callback: WatchCallback) -> tantivy::Result<WatchHandle> {\n        match &self.ram_directory {\n            Some(ram_directory) => ram_directory.watch(watch_callback),\n            None => Err(tantivy::TantivyError::InvalidArgument(\n                \"Watch not supported in read mode\".to_string(),\n            )),\n        }\n    }\n}\n```\n\n### Explanation:\n\n1. **Mode Traits**: `PuffinMode` is a trait implemented by `ReadMode` and `WriteMode`.\n2. **Generic Parameter**: `PuffinDirectory` is now generic over `M: PuffinMode`.\n3. **Mode-Specific Methods**: Methods like `to_puffin_bytes` and `from_bytes` are implemented only for the specific modes they are relevant to.\n4. **PhantomData**: The `_mode` field is used to hold the generic type parameter without actually storing any data of that type.\n5. **Blob Metadata Storage**: In read mode, the `PuffinDirectory` stores blob metadata and offsets instead of using `RamDirectory`.\n6. **Conditional Logic**: Methods like `atomic_read` and `open_write` contain conditional logic to handle the different modes appropriately.\n\nBy using generics and conditional logic, you ensure that the `PuffinDirectory` is used correctly in either read or write mode, and you get compile-time guarantees about the mode-specific behavior.\n","messages":[{"id":{"replica_id":0,"value":0},"start":0,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":498}}},{"id":{"replica_id":0,"value":68},"start":10737,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":499}}},{"id":{"replica_id":0,"value":69},"start":22983,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":500}}},{"id":{"replica_id":0,"value":200},"start":23142,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":501}}},{"id":{"replica_id":0,"value":201},"start":35409,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":502}}},{"id":{"replica_id":0,"value":453},"start":35664,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":503}}},{"id":{"replica_id":0,"value":454},"start":50271,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":504}}}],"summary":"Implementing Read and Write Modes for Puffin Directory in Rust","slash_command_output_sections":[{"range":{"start":0,"end":1},"icon":"Library","label":"Default","metadata":null},{"range":{"start":3,"end":10419},"icon":"File","label":"openobserve/src/config/src/meta/tantivy_inverted_index.rs","metadata":{"path":"openobserve/src/config/src/meta/tantivy_inverted_index.rs"}}]}