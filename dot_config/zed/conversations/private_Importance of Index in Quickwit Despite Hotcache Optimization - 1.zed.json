{"id":"c440414f-d6bc-4dd4-8254-5726a7bb721a","zed":"context","version":"0.4.0","text":"\n\n\n```rs quickwit/quickwit/quickwit-search/src/leaf.rs\n// Copyright (C) 2024 Quickwit, Inc.\n//\n// Quickwit is offered under the AGPL v3.0 and as commercial software.\n// For commercial licensing, contact us at hello@quickwit.io.\n//\n// AGPL:\n// This program is free software: you can redistribute it and/or modify\n// it under the terms of the GNU Affero General Public License as\n// published by the Free Software Foundation, either version 3 of the\n// License, or (at your option) any later version.\n//\n// This program is distributed in the hope that it will be useful,\n// but WITHOUT ANY WARRANTY; without even the implied warranty of\n// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n// GNU Affero General Public License for more details.\n//\n// You should have received a copy of the GNU Affero General Public License\n// along with this program. If not, see <http://www.gnu.org/licenses/>.\n\nuse std::collections::{HashMap, HashSet};\nuse std::ops::Bound;\nuse std::path::PathBuf;\nuse std::str::FromStr;\nuse std::sync::{Arc, Mutex, RwLock};\n\nuse anyhow::Context;\nuse futures::future::try_join_all;\nuse quickwit_common::pretty::PrettySample;\nuse quickwit_directories::{CachingDirectory, HotDirectory, StorageDirectory};\nuse quickwit_doc_mapper::{DocMapper, TermRange, WarmupInfo};\nuse quickwit_proto::search::{\n    CountHits, LeafSearchRequest, LeafSearchResponse, PartialHit, SearchRequest, SortOrder,\n    SortValue, SplitIdAndFooterOffsets, SplitSearchError,\n};\nuse quickwit_query::query_ast::{BoolQuery, QueryAst, QueryAstTransformer, RangeQuery, TermQuery};\nuse quickwit_query::tokenizers::TokenizerManager;\nuse quickwit_storage::{\n    wrap_storage_with_cache, BundleStorage, MemorySizedCache, OwnedBytes, SplitCache, Storage,\n    StorageResolver,\n};\nuse tantivy::aggregation::agg_req::{AggregationVariants, Aggregations};\nuse tantivy::aggregation::AggregationLimits;\nuse tantivy::directory::FileSlice;\nuse tantivy::fastfield::FastFieldReaders;\nuse tantivy::schema::Field;\nuse tantivy::{DateTime, Index, ReloadPolicy, Searcher, Term};\nuse tokio::task::JoinError;\nuse tracing::*;\n\nuse crate::collector::{make_collector_for_split, make_merge_collector, IncrementalCollector};\nuse crate::root::is_metadata_count_request_with_ast;\nuse crate::service::{deserialize_doc_mapper, SearcherContext};\nuse crate::{QuickwitAggregations, SearchError};\n\n/// Here is where they fetch the split footer and check for maches\n#[instrument(skip_all)]\nasync fn get_split_footer_from_cache_or_fetch(\n    index_storage: Arc<dyn Storage>,\n    split_and_footer_offsets: &SplitIdAndFooterOffsets,\n    footer_cache: &MemorySizedCache<String>,\n) -> anyhow::Result<OwnedBytes> {\n    {\n        let possible_val = footer_cache.get(&split_and_footer_offsets.split_id);\n        if let Some(footer_data) = possible_val {\n            return Ok(footer_data);\n        }\n    }\n    let split_file = PathBuf::from(format!(\"{}.split\", split_and_footer_offsets.split_id));\n    let footer_data_opt = index_storage\n        .get_slice(\n            &split_file,\n            split_and_footer_offsets.split_footer_start as usize\n                ..split_and_footer_offsets.split_footer_end as usize,\n        )\n        .await\n        .with_context(|| {\n            format!(\n                \"failed to fetch hotcache and footer from {} for split `{}`\",\n                index_storage.uri(),\n                split_and_footer_offsets.split_id\n            )\n        })?;\n\n    footer_cache.put(\n        split_and_footer_offsets.split_id.to_owned(),\n        footer_data_opt.clone(),\n    );\n\n    Ok(footer_data_opt)\n}\n\n/// Returns hotcache_bytes and the split directory (`BundleStorage`) with cache layer:\n/// - A split footer cache given by `SearcherContext.split_footer_cache`.\n#[instrument(skip_all, fields(split_footer_start=split_and_footer_offsets.split_footer_start, split_footer_end=split_and_footer_offsets.split_footer_end))]\npub(crate) async fn open_split_bundle(\n    searcher_context: &SearcherContext,\n    index_storage: Arc<dyn Storage>,\n    split_and_footer_offsets: &SplitIdAndFooterOffsets,\n) -> anyhow::Result<(FileSlice, BundleStorage)> {\n    let split_file = PathBuf::from(format!(\"{}.split\", split_and_footer_offsets.split_id));\n    let footer_data = get_split_footer_from_cache_or_fetch(\n        index_storage.clone(),\n        split_and_footer_offsets,\n        &searcher_context.split_footer_cache,\n    )\n    .await?;\n\n    // We wrap the top-level storage with the split cache.\n    // This is before the bundle storage: at this point, this storage is reading `.split` files.\n    let index_storage_with_split_cache =\n        if let Some(split_cache) = searcher_context.split_cache_opt.as_ref() {\n            SplitCache::wrap_storage(split_cache.clone(), index_storage.clone())\n        } else {\n            index_storage.clone()\n        };\n\n    let (hotcache_bytes, bundle_storage) = BundleStorage::open_from_split_data(\n        index_storage_with_split_cache,\n        split_file,\n        FileSlice::new(Arc::new(footer_data)),\n    )?;\n\n    Ok((hotcache_bytes, bundle_storage))\n}\n\n/// Opens a `tantivy::Index` for the given split with several cache layers:\n/// - A split footer cache given by `SearcherContext.split_footer_cache`.\n/// - A fast fields cache given by `SearcherContext.storage_long_term_cache`.\n/// - An ephemeral unbounded cache directory whose lifetime is tied to the returned `Index`.\n/// This function will also take care of getting partial file fetches from storage (S3)\n#[instrument(skip_all, fields(split_footer_start=split_and_footer_offsets.split_footer_start, split_footer_end=split_and_footer_offsets.split_footer_end))]\npub(crate) async fn open_index_with_caches(\n    searcher_context: &SearcherContext,\n    index_storage: Arc<dyn Storage>,\n    split_and_footer_offsets: &SplitIdAndFooterOffsets,\n    tokenizer_manager: Option<&TokenizerManager>,\n    ephemeral_unbounded_cache: bool,\n) -> anyhow::Result<Index> {\n    // hot cache bytes contains term dict, doc store and other files < 10MB\n    let (hotcache_bytes, bundle_storage) =\n        open_split_bundle(searcher_context, index_storage, split_and_footer_offsets).await?;\n\n    // We wrap the bundle storage with the fast fields cache.\n    let bundle_storage_with_cache = wrap_storage_with_cache(\n        searcher_context.fast_fields_cache.clone(),\n        Arc::new(bundle_storage),\n    );\n    let directory = StorageDirectory::new(bundle_storage_with_cache);\n\n    // This directory is what allows quickwit to fetch all the data without having to do read operations\n    // the cache which is placed in front of the directory is what allows to reduce read calls\n    let hot_directory = if ephemeral_unbounded_cache {\n        let caching_directory = CachingDirectory::new_unbounded(Arc::new(directory));\n        HotDirectory::open(caching_directory, hotcache_bytes.read_bytes()?)?\n    } else {\n        HotDirectory::open(directory, hotcache_bytes.read_bytes()?)?\n    };\n\n    let mut index = Index::open(hot_directory)?;\n    if let Some(tokenizer_manager) = tokenizer_manager {\n        index.set_tokenizers(tokenizer_manager.tantivy_manager().clone());\n    }\n    index.set_fast_field_tokenizers(\n        quickwit_query::get_quickwit_fastfield_normalizer_manager()\n            .tantivy_manager()\n            .clone(),\n    );\n    Ok(index)\n}\n\n/// Tantivy search does not make it possible to fetch data asynchronously during\n/// search.\n///\n/// It is required to download all required information in advance.\n/// This is the role of the `warmup` function.\n///\n/// The downloaded data depends on the query (which term's posting list is required,\n/// are position required too), and the collector.\n///\n/// * `query` - query is used to extract the terms and their fields which will be loaded from the\n/// inverted_index.\n///\n/// * `term_dict_field_names` - A list of fields, where the whole dictionary needs to be loaded.\n/// This is e.g. required for term aggregation, since we don't know in advance which terms are going\n/// to be hit.\n#[instrument(skip_all)]\npub(crate) async fn warmup(searcher: &Searcher, warmup_info: &WarmupInfo) -> anyhow::Result<()> {\n    debug!(warmup_info=?warmup_info);\n    let warm_up_terms_future = warm_up_terms(searcher, &warmup_info.terms_grouped_by_field)\n        .instrument(debug_span!(\"warm_up_terms\"));\n    let warm_up_term_ranges_future =\n        warm_up_term_ranges(searcher, &warmup_info.term_ranges_grouped_by_field)\n            .instrument(debug_span!(\"warm_up_term_ranges\"));\n    let warm_up_term_dict_future =\n        warm_up_term_dict_fields(searcher, &warmup_info.term_dict_fields)\n            .instrument(debug_span!(\"warm_up_term_dicts\"));\n    let warm_up_fastfields_future = warm_up_fastfields(searcher, &warmup_info.fast_field_names)\n        .instrument(debug_span!(\"warm_up_fastfields\"));\n    let warm_up_fieldnorms_future = warm_up_fieldnorms(searcher, warmup_info.field_norms)\n        .instrument(debug_span!(\"warm_up_fieldnorms\"));\n    // TODO merge warm_up_postings into warm_up_term_dict_fields\n    let warm_up_postings_future = warm_up_postings(searcher, &warmup_info.term_dict_fields)\n        .instrument(debug_span!(\"warm_up_postings\"));\n\n    tokio::try_join!(\n        warm_up_terms_future,\n        warm_up_term_ranges_future,\n        warm_up_fastfields_future,\n        warm_up_term_dict_future,\n        warm_up_fieldnorms_future,\n        warm_up_postings_future,\n    )?;\n\n    Ok(())\n}\n\nasync fn warm_up_term_dict_fields(\n    searcher: &Searcher,\n    term_dict_fields: &HashSet<Field>,\n) -> anyhow::Result<()> {\n    let mut warm_up_futures = Vec::new();\n    for field in term_dict_fields {\n        for segment_reader in searcher.segment_readers() {\n            let inverted_index = segment_reader.inverted_index(*field)?.clone();\n            warm_up_futures.push(async move {\n                let dict = inverted_index.terms();\n                dict.warm_up_dictionary().await\n            });\n        }\n    }\n    try_join_all(warm_up_futures).await?;\n    Ok(())\n}\n\nasync fn warm_up_postings(searcher: &Searcher, fields: &HashSet<Field>) -> anyhow::Result<()> {\n    let mut warm_up_futures = Vec::new();\n    for field in fields {\n        for segment_reader in searcher.segment_readers() {\n            let inverted_index = segment_reader.inverted_index(*field)?.clone();\n            warm_up_futures.push(async move { inverted_index.warm_postings_full(false).await });\n        }\n    }\n    try_join_all(warm_up_futures).await?;\n    Ok(())\n}\n\nasync fn warm_up_fastfield(\n    fast_field_reader: &FastFieldReaders,\n    fast_field_name: &str,\n) -> anyhow::Result<()> {\n    let columns = fast_field_reader\n        .list_dynamic_column_handles(fast_field_name)\n        .await?;\n    futures::future::try_join_all(\n        columns\n            .into_iter()\n            .map(|col| async move { col.file_slice().read_bytes_async().await }),\n    )\n    .await?;\n    Ok(())\n}\n\n/// Populates the short-lived cache with the data for\n/// all of the fast fields passed as argument.\nasync fn warm_up_fastfields(\n    searcher: &Searcher,\n    fast_field_names: &HashSet<String>,\n) -> anyhow::Result<()> {\n    let mut warm_up_futures = Vec::new();\n    for segment_reader in searcher.segment_readers() {\n        let fast_field_reader = segment_reader.fast_fields();\n        for fast_field_name in fast_field_names {\n            let warm_up_fut = warm_up_fastfield(fast_field_reader, fast_field_name);\n            warm_up_futures.push(Box::pin(warm_up_fut));\n        }\n    }\n    futures::future::try_join_all(warm_up_futures).await?;\n    Ok(())\n}\n\nasync fn warm_up_terms(\n    searcher: &Searcher,\n    terms_grouped_by_field: &HashMap<Field, HashMap<Term, bool>>,\n) -> anyhow::Result<()> {\n    let mut warm_up_futures = Vec::new();\n    for (field, terms) in terms_grouped_by_field {\n        for segment_reader in searcher.segment_readers() {\n            let inv_idx = segment_reader.inverted_index(*field)?;\n            for (term, position_needed) in terms.iter() {\n                let inv_idx_clone = inv_idx.clone();\n                warm_up_futures\n                    .push(async move { inv_idx_clone.warm_postings(term, *position_needed).await });\n            }\n        }\n    }\n    try_join_all(warm_up_futures).await?;\n    Ok(())\n}\n\nasync fn warm_up_term_ranges(\n    searcher: &Searcher,\n    terms_grouped_by_field: &HashMap<Field, HashMap<TermRange, bool>>,\n) -> anyhow::Result<()> {\n    let mut warm_up_futures = Vec::new();\n    for (field, terms) in terms_grouped_by_field {\n        for segment_reader in searcher.segment_readers() {\n            let inv_idx = segment_reader.inverted_index(*field)?;\n            for (term_range, position_needed) in terms.iter() {\n                let inv_idx_clone = inv_idx.clone();\n                let range = (term_range.start.as_ref(), term_range.end.as_ref());\n                warm_up_futures.push(async move {\n                    inv_idx_clone\n                        .warm_postings_range(range, term_range.limit, *position_needed)\n                        .await\n                });\n            }\n        }\n    }\n    try_join_all(warm_up_futures).await?;\n    Ok(())\n}\n\nasync fn warm_up_fieldnorms(searcher: &Searcher, requires_scoring: bool) -> anyhow::Result<()> {\n    if !requires_scoring {\n        return Ok(());\n    }\n    let mut warm_up_futures = Vec::new();\n    for field in searcher.schema().fields() {\n        for segment_reader in searcher.segment_readers() {\n            let fieldnorm_readers = segment_reader.fieldnorms_readers();\n            let file_handle_opt = fieldnorm_readers.get_inner_file().open_read(field.0);\n            if let Some(file_handle) = file_handle_opt {\n                warm_up_futures.push(async move { file_handle.read_bytes_async().await })\n            }\n        }\n    }\n    try_join_all(warm_up_futures).await?;\n    Ok(())\n}\n\nfn get_leaf_resp_from_count(count: u64) -> LeafSearchResponse {\n    LeafSearchResponse {\n        num_hits: count,\n        partial_hits: Vec::new(),\n        failed_splits: Vec::new(),\n        num_attempted_splits: 1,\n        intermediate_aggregation_result: None,\n    }\n}\n\n/// Apply a leaf search on a single split.\nasync fn leaf_search_single_split(\n    searcher_context: &SearcherContext,\n    mut search_request: SearchRequest,\n    storage: Arc<dyn Storage>,\n    split: SplitIdAndFooterOffsets,\n    doc_mapper: Arc<dyn DocMapper>,\n    split_filter: Arc<RwLock<CanSplitDoBetter>>,\n    aggregations_limits: AggregationLimits,\n) -> crate::Result<LeafSearchResponse> {\n    rewrite_request(\n        &mut search_request,\n        &split,\n        doc_mapper.timestamp_field_name(),\n    );\n    // Check cache\n    // This cache takes in account the split id and the search request\n    //\n    if let Some(cached_answer) = searcher_context\n        .leaf_search_cache\n        .get(split.clone(), search_request.clone())\n    {\n        return Ok(cached_answer);\n    }\n\n    let query_ast: QueryAst = serde_json::from_str(search_request.query_ast.as_str())\n        .map_err(|err| SearchError::InvalidQuery(err.to_string()))?;\n\n    // CanSplitDoBetter or rewrite_request may have changed the request to be a count only request\n    // This may be the case for AllQuery with a sort by date and time filter, where the current\n    // split can't have better results.\n    //\n    if is_metadata_count_request_with_ast(&query_ast, &search_request) {\n        return Ok(get_leaf_resp_from_count(split.num_docs));\n    }\n\n    let split_id = split.split_id.to_string();\n    // this will return index with hotcache if available\n    let index = open_index_with_caches(\n        searcher_context,\n        storage,\n        &split,\n        Some(doc_mapper.tokenizer_manager()),\n        true,\n    )\n    .await?;\n    let split_schema = index.schema();\n\n    let reader = index\n        .reader_builder()\n        .reload_policy(ReloadPolicy::Manual)\n        .try_into()?;\n    let searcher = reader.searcher();\n\n    // collector is needed to collect the search results\n    let mut collector =\n        make_collector_for_split(split_id.clone(), &search_request, aggregations_limits)?;\n\n    let (query, mut warmup_info) = doc_mapper.query(split_schema.clone(), &query_ast, false)?;\n\n    let collector_warmup_info = collector.warmup_info();\n    warmup_info.merge(collector_warmup_info);\n    warmup_info.simplify();\n\n    // all of the FST lookup happens here. This is the most expensive part of the search\n    // and we want to do it only once per split\n    warmup(&searcher, &warmup_info).await?;\n    let span = info_span!(\"tantivy_search\");\n\n    let (search_request, leaf_search_response) = {\n        let split = split.clone();\n\n        crate::search_thread_pool()\n            // actual serach happens in a rayon thread pool\n            // where tantivy calls in the\n            .run_cpu_intensive(move || {\n                let _span_guard = span.enter();\n                // Our search execution has been scheduled, let's check if we can improve the\n                // request based on the results of the preceding searches\n                check_optimize_search_request(&mut search_request, &split, &split_filter);\n                collector.update_search_param(&search_request);\n                if is_metadata_count_request_with_ast(&query_ast, &search_request) {\n                    return Ok((\n                        search_request,\n                        get_leaf_resp_from_count(searcher.num_docs() as u64),\n                    ));\n                }\n                if collector.is_count_only() {\n                    let count = query.count(&searcher)? as u64;\n                    Ok((search_request, get_leaf_resp_from_count(count)))\n                } else {\n                    searcher\n                        .search(&query, &collector)\n                        .map(|resp| (search_request, resp))\n                }\n            })\n            .await\n            .map_err(|_| {\n                crate::SearchError::Internal(format!(\"leaf search panicked. split={split_id}\"))\n            })??\n    };\n\n    // update cache\n    searcher_context\n        .leaf_search_cache\n        .put(split, search_request, leaf_search_response.clone());\n    Ok(leaf_search_response)\n}\n\n/// Rewrite a request removing parts which incur additional download or computation with no\n/// effect.\n///\n/// This include things such as sorting result by a field or _score when no document is requested,\n/// or applying date range when the range covers the entire split.\nfn rewrite_request(\n    search_request: &mut SearchRequest,\n    split: &SplitIdAndFooterOffsets,\n    timestamp_field: Option<&str>,\n) {\n    if search_request.max_hits == 0 {\n        search_request.sort_fields = Vec::new();\n    }\n    if let Some(timestamp_field) = timestamp_field {\n        remove_redundant_timestamp_range(search_request, split, timestamp_field);\n    }\n    rewrite_aggregation(search_request);\n}\n\n/// Rewrite aggregation to make them easier to cache\n///\n/// This is only valid for options which are handled while merging results, which is\n/// mostly `extended_bounds`.\nfn rewrite_aggregation(search_request: &mut SearchRequest) {\n    if let Some(aggregation) = &search_request.aggregation_request {\n        let Ok(QuickwitAggregations::TantivyAggregations(mut aggregations)) =\n            serde_json::from_str(aggregation)\n        else {\n            return;\n        };\n        let modified_something = visit_aggregation_mut(&mut aggregations, &|aggregation_variant| {\n            match aggregation_variant {\n                // we take() away the extended bounds, and record we did something\n                AggregationVariants::Histogram(histogram) => {\n                    histogram.extended_bounds.take().is_some()\n                }\n                AggregationVariants::DateHistogram(histogram) => {\n                    histogram.extended_bounds.take().is_some()\n                }\n                _ => false,\n            }\n        });\n        if modified_something {\n            // it's fine to put a (Tantivy)Aggregations and not a QuickwitAggregations because\n            // the former is an serde-untagged variant of the later\n            search_request.aggregation_request =\n                Some(serde_json::to_string(&aggregations).expect(\"serializing should never fail\"));\n        }\n    }\n}\n\n// this is a rather limited visitor, but enough to do the job\nfn visit_aggregation_mut(\n    aggregations: &mut Aggregations,\n    callback: &impl Fn(&mut AggregationVariants) -> bool,\n) -> bool {\n    let mut modified_something = false;\n    for aggregation in aggregations.values_mut() {\n        modified_something |= callback(&mut aggregation.agg);\n        modified_something |= visit_aggregation_mut(&mut aggregation.sub_aggregation, callback);\n    }\n    modified_something\n}\n\n// equivalent to Bound::map, which is unstable\npub fn map_bound<T, U>(bound: Bound<T>, f: impl FnOnce(T) -> U) -> Bound<U> {\n    use Bound::*;\n    match bound {\n        Unbounded => Unbounded,\n        Included(x) => Included(f(x)),\n        Excluded(x) => Excluded(f(x)),\n    }\n}\n\n// returns the max of left and right, that isn't unbounded. Useful for making\n// the intersection of lower bound of ranges\nfn max_bound<T: Ord + Copy>(left: Bound<T>, right: Bound<T>) -> Bound<T> {\n    use Bound::*;\n    match (left, right) {\n        (Unbounded, right) => right,\n        (left, Unbounded) => left,\n        (Included(left), Included(right)) => Included(left.max(right)),\n        (Excluded(left), Excluded(right)) => Excluded(left.max(right)),\n        (excluded_total @ Excluded(excluded), included_total @ Included(included)) => {\n            if included > excluded {\n                included_total\n            } else {\n                excluded_total\n            }\n        }\n        (included_total @ Included(included), excluded_total @ Excluded(excluded)) => {\n            if included > excluded {\n                included_total\n            } else {\n                excluded_total\n            }\n        }\n    }\n}\n\n// returns the min of left and right, that isn't unbounded. Useful for making\n// the intersection of upper bound of ranges\nfn min_bound<T: Ord + Copy>(left: Bound<T>, right: Bound<T>) -> Bound<T> {\n    use Bound::*;\n    match (left, right) {\n        (Unbounded, right) => right,\n        (left, Unbounded) => left,\n        (Included(left), Included(right)) => Included(left.min(right)),\n        (Excluded(left), Excluded(right)) => Excluded(left.min(right)),\n        (excluded_total @ Excluded(excluded), included_total @ Included(included)) => {\n            if included < excluded {\n                included_total\n            } else {\n                excluded_total\n            }\n        }\n        (included_total @ Included(included), excluded_total @ Excluded(excluded)) => {\n            if included < excluded {\n                included_total\n            } else {\n                excluded_total\n            }\n        }\n    }\n}\n\n/// remove timestamp range that would be present both in QueryAst and SearchRequest\n///\n/// this can save us from doing double the work in some cases, and help with the partial request\n/// cache.\nfn remove_redundant_timestamp_range(\n    search_request: &mut SearchRequest,\n    split: &SplitIdAndFooterOffsets,\n    timestamp_field: &str,\n) {\n    let Ok(query_ast) = serde_json::from_str(search_request.query_ast.as_str()) else {\n        // an error will get raised a bit after anyway\n        return;\n    };\n\n    let start_timestamp = search_request\n        .start_timestamp\n        .map(DateTime::from_timestamp_secs)\n        .map(Bound::Included)\n        .unwrap_or(Bound::Unbounded);\n    let end_timestamp = search_request\n        .end_timestamp\n        .map(DateTime::from_timestamp_secs)\n        .map(Bound::Excluded)\n        .unwrap_or(Bound::Unbounded);\n\n    let mut visitor = RemoveTimestampRange {\n        timestamp_field,\n        start_timestamp,\n        end_timestamp,\n    };\n    let mut new_ast = visitor\n        .transform(query_ast)\n        .expect(\"can't fail unwrapping Infallible\")\n        .unwrap_or(QueryAst::MatchAll);\n\n    let final_start_timestamp = match (\n        visitor.start_timestamp,\n        split.timestamp_start.map(DateTime::from_timestamp_secs),\n    ) {\n        (Bound::Included(query_ts), Some(split_ts)) => {\n            if query_ts > split_ts {\n                Bound::Included(query_ts)\n            } else {\n                Bound::Unbounded\n            }\n        }\n        (Bound::Excluded(query_ts), Some(split_ts)) => {\n            if query_ts >= split_ts {\n                Bound::Excluded(query_ts)\n            } else {\n                Bound::Unbounded\n            }\n        }\n        (Bound::Unbounded, Some(_)) => Bound::Unbounded,\n        (timestamp, None) => timestamp,\n    };\n    let final_end_timestamp = match (\n        visitor.end_timestamp,\n        split.timestamp_end.map(DateTime::from_timestamp_secs),\n    ) {\n        (Bound::Included(query_ts), Some(split_ts)) => {\n            if query_ts < split_ts {\n                Bound::Included(query_ts)\n            } else {\n                Bound::Unbounded\n            }\n        }\n        (Bound::Excluded(query_ts), Some(split_ts)) => {\n            if query_ts <= split_ts {\n                Bound::Excluded(query_ts)\n            } else {\n                Bound::Unbounded\n            }\n        }\n        (Bound::Unbounded, Some(_)) => Bound::Unbounded,\n        (timestamp, None) => timestamp,\n    };\n    if final_start_timestamp != Bound::Unbounded || final_end_timestamp != Bound::Unbounded {\n        let range = RangeQuery {\n            field: timestamp_field.to_string(),\n            lower_bound: map_bound(final_start_timestamp, |bound| {\n                bound.into_timestamp_nanos().into()\n            }),\n            upper_bound: map_bound(final_end_timestamp, |bound| {\n                bound.into_timestamp_nanos().into()\n            }),\n        };\n        new_ast = if let QueryAst::Bool(mut bool_query) = new_ast {\n            if bool_query.must.is_empty()\n                && bool_query.filter.is_empty()\n                && !bool_query.should.is_empty()\n            {\n                // we can't simply add a filter if we have some should but no must/filter. We must\n                // add a new layer of bool query\n                BoolQuery {\n                    must: vec![bool_query.into()],\n                    filter: vec![range.into()],\n                    ..Default::default()\n                }\n                .into()\n            } else {\n                bool_query.filter.push(range.into());\n                QueryAst::Bool(bool_query)\n            }\n        } else {\n            BoolQuery {\n                must: vec![new_ast],\n                filter: vec![range.into()],\n                ..Default::default()\n            }\n            .into()\n        }\n    }\n\n    search_request.query_ast = serde_json::to_string(&new_ast).unwrap();\n    search_request.start_timestamp = None;\n    search_request.end_timestamp = None;\n}\n\n/// Remove all `must` and `filter timestamp ranges, and summarize them\n#[derive(Debug, Clone)]\nstruct RemoveTimestampRange<'a> {\n    timestamp_field: &'a str,\n    start_timestamp: Bound<DateTime>,\n    end_timestamp: Bound<DateTime>,\n}\n\nimpl<'a> RemoveTimestampRange<'a> {\n    fn update_start_timestamp(\n        &mut self,\n        lower_bound: &quickwit_query::JsonLiteral,\n        included: bool,\n    ) {\n        use quickwit_query::InterpretUserInput;\n        let Some(lower_bound) = DateTime::interpret_json(lower_bound) else {\n            // we shouldn't be able to get here, we would have errored much earlier in root search\n            warn!(\"unparsable time bound in leaf search: {lower_bound:?}\");\n            return;\n        };\n        let bound = if included {\n            Bound::Included(lower_bound)\n        } else {\n            Bound::Excluded(lower_bound)\n        };\n\n        self.start_timestamp = max_bound(self.start_timestamp, bound);\n    }\n\n    fn update_end_timestamp(&mut self, upper_bound: &quickwit_query::JsonLiteral, included: bool) {\n        use quickwit_query::InterpretUserInput;\n        let Some(upper_bound) = DateTime::interpret_json(upper_bound) else {\n            // we shouldn't be able to get here, we would have errored much earlier in root search\n            warn!(\"unparsable time bound in leaf search: {upper_bound:?}\");\n            return;\n        };\n        let bound = if included {\n            Bound::Included(upper_bound)\n        } else {\n            Bound::Excluded(upper_bound)\n        };\n\n        self.end_timestamp = min_bound(self.end_timestamp, bound);\n    }\n}\n\nimpl<'a> QueryAstTransformer for RemoveTimestampRange<'a> {\n    type Err = std::convert::Infallible;\n\n    fn transform_bool(&mut self, mut bool_query: BoolQuery) -> Result<Option<QueryAst>, Self::Err> {\n        // we only want to visit sub-queries which are strict (positive) requirements\n        bool_query.must = bool_query\n            .must\n            .into_iter()\n            .filter_map(|query_ast| self.transform(query_ast).transpose())\n            .collect::<Result<Vec<_>, _>>()?;\n        bool_query.filter = bool_query\n            .filter\n            .into_iter()\n            .filter_map(|query_ast| self.transform(query_ast).transpose())\n            .collect::<Result<Vec<_>, _>>()?;\n\n        Ok(Some(QueryAst::Bool(bool_query)))\n    }\n\n    fn transform_range(&mut self, range_query: RangeQuery) -> Result<Option<QueryAst>, Self::Err> {\n        if range_query.field == self.timestamp_field {\n            match range_query.lower_bound {\n                Bound::Included(lower_bound) => {\n                    self.update_start_timestamp(&lower_bound, true);\n                }\n                Bound::Excluded(lower_bound) => {\n                    self.update_start_timestamp(&lower_bound, false);\n                }\n                Bound::Unbounded => (),\n            };\n\n            match range_query.upper_bound {\n                Bound::Included(upper_bound) => {\n                    self.update_end_timestamp(&upper_bound, true);\n                }\n                Bound::Excluded(upper_bound) => {\n                    self.update_end_timestamp(&upper_bound, false);\n                }\n                Bound::Unbounded => (),\n            };\n\n            Ok(Some(QueryAst::MatchAll))\n        } else {\n            Ok(Some(range_query.into()))\n        }\n    }\n\n    fn transform_term(&mut self, term_query: TermQuery) -> Result<Option<QueryAst>, Self::Err> {\n        // TODO we could remove query bounds, this point query surely is more precise, and it\n        // doesn't require loading a fastfield\n        Ok(Some(QueryAst::Term(term_query)))\n    }\n}\n\npub(crate) fn rewrite_start_end_time_bounds(\n    start_timestamp_opt: &mut Option<i64>,\n    end_timestamp_opt: &mut Option<i64>,\n    split: &SplitIdAndFooterOffsets,\n) {\n    if let (Some(split_start), Some(split_end)) = (split.timestamp_start, split.timestamp_end) {\n        if let Some(start_timestamp) = start_timestamp_opt {\n            // both starts are inclusive\n            if *start_timestamp <= split_start {\n                *start_timestamp_opt = None;\n            }\n        }\n        if let Some(end_timestamp) = end_timestamp_opt {\n            // search end is exclusive, split end is inclusive\n            if *end_timestamp > split_end {\n                *end_timestamp_opt = None;\n            }\n        }\n    }\n}\n\n/// Checks if request is a simple all query.\n/// Simple in this case would still including sorting\nfn is_simple_all_query(search_request: &SearchRequest) -> bool {\n    if search_request.aggregation_request.is_some() {\n        return false;\n    }\n\n    if search_request.search_after.is_some() {\n        return false;\n    }\n\n    // TODO: Update the logic to handle start_timestamp end_timestamp ranges\n    if search_request.start_timestamp.is_some() || search_request.end_timestamp.is_some() {\n        return false;\n    }\n\n    let Ok(query_ast) = serde_json::from_str(&search_request.query_ast) else {\n        return false;\n    };\n\n    matches!(query_ast, QueryAst::MatchAll)\n}\n\n#[derive(Debug, Clone)]\nenum CanSplitDoBetter {\n    Uninformative,\n    SplitIdHigher(Option<String>),\n    SplitTimestampHigher(Option<i64>),\n    SplitTimestampLower(Option<i64>),\n    FindTraceIdsAggregation(Option<i64>),\n}\n\nimpl CanSplitDoBetter {\n    /// Create a CanSplitDoBetter from a SearchRequest\n    fn from_request(request: &SearchRequest, timestamp_field_name: Option<&str>) -> Self {\n        if request.max_hits == 0 {\n            if let Some(aggregation) = &request.aggregation_request {\n                if let Ok(crate::QuickwitAggregations::FindTraceIdsAggregation(\n                    find_trace_aggregation,\n                )) = serde_json::from_str(aggregation)\n                {\n                    if Some(find_trace_aggregation.span_timestamp_field_name.as_str())\n                        == timestamp_field_name\n                    {\n                        return CanSplitDoBetter::FindTraceIdsAggregation(None);\n                    }\n                }\n            }\n        }\n\n        if request.sort_fields.is_empty() {\n            CanSplitDoBetter::SplitIdHigher(None)\n        } else if let Some((sort_by, timestamp_field)) =\n            request.sort_fields.first().zip(timestamp_field_name)\n        {\n            if sort_by.field_name == timestamp_field {\n                if sort_by.sort_order() == SortOrder::Desc {\n                    CanSplitDoBetter::SplitTimestampHigher(None)\n                } else {\n                    CanSplitDoBetter::SplitTimestampLower(None)\n                }\n            } else {\n                CanSplitDoBetter::Uninformative\n            }\n        } else {\n            CanSplitDoBetter::Uninformative\n        }\n    }\n\n    /// Optimize the order in which splits will get processed based on how it can skip the most\n    /// splits.\n    ///\n    /// The leaf search code contains some logic that makes it possible to skip entire splits\n    /// when we are confident they won't make it into top K.\n    /// To make this optimization as potent as possible, we sort the splits so that the first splits\n    /// are the most likely to fill our Top K.\n    /// In the future, as split get more metadata per column, we may be able to do this more than\n    /// just for timestamp and \"unsorted\" request.\n    fn optimize_split_order(&self, splits: &mut [SplitIdAndFooterOffsets]) {\n        match self {\n            CanSplitDoBetter::SplitIdHigher(_) => {\n                splits.sort_unstable_by(|a, b| b.split_id.cmp(&a.split_id))\n            }\n            CanSplitDoBetter::SplitTimestampHigher(_)\n            | CanSplitDoBetter::FindTraceIdsAggregation(_) => {\n                splits.sort_unstable_by_key(|split| std::cmp::Reverse(split.timestamp_end()))\n            }\n            CanSplitDoBetter::SplitTimestampLower(_) => {\n                splits.sort_unstable_by_key(|split| split.timestamp_start())\n            }\n            CanSplitDoBetter::Uninformative => (),\n        }\n    }\n\n    /// This function tries to detect upfront which splits contain the top n hits and convert other\n    /// split searches to count only searches. It also optimizes split order.\n    ///\n    /// Returns the search_requests with their split.\n    fn optimize(\n        &self,\n        request: Arc<SearchRequest>,\n        mut splits: Vec<SplitIdAndFooterOffsets>,\n    ) -> Result<Vec<(SplitIdAndFooterOffsets, SearchRequest)>, SearchError> {\n        self.optimize_split_order(&mut splits);\n\n        if !is_simple_all_query(&request) {\n            // no optimization opportunity here.\n            return Ok(splits\n                .into_iter()\n                .map(|split| (split, (*request).clone()))\n                .collect::<Vec<_>>());\n        }\n\n        let num_requested_docs = request.start_offset + request.max_hits;\n\n        // Calculate the number of splits which are guaranteed to deliver enough documents.\n        let min_required_splits = splits\n            .iter()\n            .map(|split| split.num_docs)\n            // computing the partial sum\n            .scan(0u64, |partial_sum: &mut u64, num_docs_in_split: u64| {\n                *partial_sum += num_docs_in_split;\n                Some(*partial_sum)\n            })\n            .take_while(|partial_sum| *partial_sum < num_requested_docs)\n            .count()\n            + 1;\n\n        // TODO: we maybe want here some deduplication + Cow logic\n        let mut split_with_req = splits\n            .into_iter()\n            .map(|split| (split, (*request).clone()))\n            .collect::<Vec<_>>();\n\n        // reuse the detected sort order in split_filter\n        // we want to detect cases where we can convert some split queries to count only queries\n        match self {\n            CanSplitDoBetter::SplitIdHigher(_) => {\n                // In this case there is no sort order, we order by split id.\n                // If the the first split has enough documents, we can convert the other queries to\n                // count only queries\n                for (_split, ref mut request) in split_with_req.iter_mut().skip(min_required_splits)\n                {\n                    disable_search_request_hits(request);\n                }\n            }\n            CanSplitDoBetter::Uninformative => {}\n            CanSplitDoBetter::SplitTimestampLower(_) => {\n                // We order by timestamp asc. split_with_req is sorted by timestamp_start.\n                //\n                // If we know that some splits will deliver enough documents, we can convert the\n                // others to count only queries.\n                // Since we only have start and end ranges and don't know the distribution we make\n                // sure the splits dont' overlap, since the distribution of two\n                // splits could be like this (dot is a timestamp doc on a x axis), for top 2\n                // queries.\n                // ```\n                // [.          .] Split1 has enough docs, but last doc is not in top 2\n                //           [..         .] Split2 first doc is in top2\n                // ```\n                // Let's get the biggest timestamp_end of the first num_splits splits\n                let biggest_end_timestamp = split_with_req\n                    .iter()\n                    .take(min_required_splits)\n                    .map(|(split, _)| split.timestamp_end())\n                    .max()\n                    // if min_required_splits is 0, we choose a value that disables all splits\n                    .unwrap_or(i64::MIN);\n                for (split, ref mut request) in split_with_req.iter_mut().skip(min_required_splits)\n                {\n                    if split.timestamp_start() > biggest_end_timestamp {\n                        disable_search_request_hits(request);\n                    }\n                }\n            }\n            CanSplitDoBetter::SplitTimestampHigher(_) => {\n                // We order by timestamp desc. split_with_req is sorted by timestamp_end desc.\n                //\n                // We have the number of splits we need to search to get enough docs, now we need to\n                // find the splits that don't overlap.\n                //\n                // Let's get the smallest timestamp_start of the first num_splits splits\n                let smallest_start_timestamp = split_with_req\n                    .iter()\n                    .take(min_required_splits)\n                    .map(|(split, _)| split.timestamp_start())\n                    .min()\n                    // if min_required_splits is 0, we choose a value that disables all splits\n                    .unwrap_or(i64::MAX);\n                for (split, ref mut request) in split_with_req.iter_mut().skip(min_required_splits)\n                {\n                    if split.timestamp_end() < smallest_start_timestamp {\n                        disable_search_request_hits(request);\n                    }\n                }\n            }\n            CanSplitDoBetter::FindTraceIdsAggregation(_) => {}\n        }\n\n        Ok(split_with_req)\n    }\n\n    /// Returns whether the given split can possibly give documents better than the one already\n    /// known to match.\n    fn can_be_better(&self, split: &SplitIdAndFooterOffsets) -> bool {\n        match self {\n            CanSplitDoBetter::SplitIdHigher(Some(split_id)) => split.split_id >= *split_id,\n            CanSplitDoBetter::SplitTimestampHigher(Some(timestamp))\n            | CanSplitDoBetter::FindTraceIdsAggregation(Some(timestamp)) => {\n                split.timestamp_end() >= *timestamp\n            }\n            CanSplitDoBetter::SplitTimestampLower(Some(timestamp)) => {\n                split.timestamp_start() <= *timestamp\n            }\n            _ => true,\n        }\n    }\n\n    /// Record the new worst-of-the-top document, that is, the document which would first be\n    /// evicted from the list of best documents, if a better document was found. Only call this\n    /// function if you have at least max_hits documents already.\n    fn record_new_worst_hit(&mut self, hit: &PartialHit) {\n        match self {\n            CanSplitDoBetter::Uninformative => (),\n            CanSplitDoBetter::SplitIdHigher(split_id) => *split_id = Some(hit.split_id.clone()),\n            CanSplitDoBetter::SplitTimestampHigher(timestamp)\n            | CanSplitDoBetter::FindTraceIdsAggregation(timestamp) => {\n                if let Some(SortValue::I64(timestamp_ns)) = hit.sort_value() {\n                    // if we get a timestamp of, says 1.5s, we need to check up to 2s to make\n                    // sure we don't throw away something like 1.2s, so we should round up while\n                    // dividing.\n                    *timestamp = Some(quickwit_common::div_ceil(timestamp_ns, 1_000_000_000));\n                }\n            }\n            CanSplitDoBetter::SplitTimestampLower(timestamp) => {\n                if let Some(SortValue::I64(timestamp_ns)) = hit.sort_value() {\n                    // if we get a timestamp of, says 1.5s, we need to check down to 1s to make\n                    // sure we don't throw away something like 1.7s, so we should truncate,\n                    // which is the default behavior of division\n                    let timestamp_s = timestamp_ns / 1_000_000_000;\n                    *timestamp = Some(timestamp_s);\n                }\n            }\n        }\n    }\n}\n\n/// `multi_leaf_search` searches multiple indices and multiple splits.\n#[instrument(skip_all, fields(index = ?leaf_search_request.search_request.as_ref().unwrap().index_id_patterns))]\npub async fn multi_leaf_search(\n    searcher_context: Arc<SearcherContext>,\n    leaf_search_request: LeafSearchRequest,\n    storage_resolver: &StorageResolver,\n) -> Result<LeafSearchResponse, SearchError> {\n    let search_request: Arc<SearchRequest> = leaf_search_request\n        .search_request\n        .ok_or_else(|| SearchError::Internal(\"no search request\".to_string()))?\n        .into();\n\n    let doc_mappers: Vec<Arc<dyn DocMapper>> = leaf_search_request\n        .doc_mappers\n        .iter()\n        .map(|doc_mapper| deserialize_doc_mapper(doc_mapper))\n        .collect::<crate::Result<_>>()?;\n    // Creates a collector which merges responses into one\n    let aggregation_limits = searcher_context.get_aggregation_limits();\n    // TODO: to avoid lockstep, we should pull up the future creation over the list of split ids\n    // and have the semaphore on this level.\n    // This will lower resource consumption due to less in-flight futures and avoid contention.\n    // It also allows passing early exit conditions between indices.\n    //\n    // It is a little bit tricky how to handle which is now the incremental_merge_collector, one\n    // per index, e.g. when to merge results and how to avoid lock contention.\n    let mut leaf_request_tasks = Vec::new();\n\n    for leaf_search_request_ref in leaf_search_request.leaf_requests.into_iter() {\n        let index_uri = quickwit_common::uri::Uri::from_str(\n            leaf_search_request\n                .index_uris\n                .get(leaf_search_request_ref.index_uri_ord as usize)\n                .ok_or_else(|| {\n                    SearchError::Internal(format!(\n                        \"Received incorrect request, index_uri_ord out of bounds: {}\",\n                        leaf_search_request_ref.index_uri_ord\n                    ))\n                })?,\n        )?;\n        let doc_mapper = doc_mappers\n            .get(leaf_search_request_ref.doc_mapper_ord as usize)\n            .ok_or_else(|| {\n                SearchError::Internal(format!(\n                    \"Received incorrect request, doc_mapper_ord out of bounds: {}\",\n                    leaf_search_request_ref.doc_mapper_ord\n                ))\n            })?\n            .clone();\n\n        let leaf_request_future = tokio::spawn(\n            resolve_storage_and_leaf_search(\n                searcher_context.clone(),\n                search_request.clone(),\n                index_uri,\n                storage_resolver.clone(),\n                leaf_search_request_ref.split_offsets,\n                doc_mapper,\n                aggregation_limits.clone(),\n            )\n            .in_current_span(),\n        );\n        leaf_request_tasks.push(leaf_request_future);\n    }\n\n    let leaf_responses = try_join_all(leaf_request_tasks).await?;\n    let merge_collector = make_merge_collector(&search_request, &aggregation_limits)?;\n    let mut incremental_merge_collector = IncrementalCollector::new(merge_collector);\n    for result in leaf_responses {\n        match result {\n            Ok(result) => {\n                incremental_merge_collector.add_result(result)?;\n            }\n            Err(err) => {\n                incremental_merge_collector.add_failed_split(SplitSearchError {\n                    split_id: \"unknown\".to_string(),\n                    error: format!(\"{}\", err),\n                    retryable_error: true,\n                });\n            }\n        }\n    }\n\n    crate::search_thread_pool()\n        .run_cpu_intensive(|| incremental_merge_collector.finalize().map_err(Into::into))\n        .instrument(info_span!(\"incremental_merge_finalize\"))\n        .await\n        .context(\"failed to merge split search responses\")?\n}\n\n/// Resolves storage and calls leaf_search\nasync fn resolve_storage_and_leaf_search(\n    searcher_context: Arc<SearcherContext>,\n    search_request: Arc<SearchRequest>,\n    index_uri: quickwit_common::uri::Uri,\n    storage_resolver: StorageResolver,\n    splits: Vec<SplitIdAndFooterOffsets>,\n    doc_mapper: Arc<dyn DocMapper>,\n    aggregations_limits: AggregationLimits,\n) -> crate::Result<LeafSearchResponse> {\n    let storage = storage_resolver.resolve(&index_uri).await?;\n\n    leaf_search(\n        searcher_context.clone(),\n        search_request.clone(),\n        storage.clone(),\n        splits,\n        doc_mapper,\n        aggregations_limits,\n    )\n    .await\n}\n\n/// Optimizes the search_request based on CanSplitDoBetter\n/// Returns true if the split can return better results\nfn check_optimize_search_request(\n    search_request: &mut SearchRequest,\n    split: &SplitIdAndFooterOffsets,\n    split_filter: &Arc<RwLock<CanSplitDoBetter>>,\n) -> bool {\n    let can_be_better = split_filter.read().unwrap().can_be_better(split);\n    if !can_be_better {\n        disable_search_request_hits(search_request);\n    }\n    can_be_better\n}\n\n/// Alter the search request so it does not return any docs.\n///\n/// This is usually done since it cannot provide better hits results than existing fetched results.\nfn disable_search_request_hits(search_request: &mut SearchRequest) {\n    search_request.max_hits = 0;\n    search_request.start_offset = 0;\n    search_request.sort_fields.clear();\n}\n\n/// `leaf` step of search.\n///\n/// The leaf search collects all kind of information, and returns a set of\n/// [PartialHit](quickwit_proto::search::PartialHit) candidates. The root will be in\n/// charge to consolidate, identify the actual final top hits to display, and\n/// fetch the actual documents to convert the partial hits into actual Hits.\n#[instrument(skip_all, fields(index = ?request.index_id_patterns))]\npub async fn leaf_search(\n    searcher_context: Arc<SearcherContext>,\n    request: Arc<SearchRequest>,\n    index_storage: Arc<dyn Storage>,\n    splits: Vec<SplitIdAndFooterOffsets>,\n    doc_mapper: Arc<dyn DocMapper>,\n    aggregations_limits: AggregationLimits,\n) -> Result<LeafSearchResponse, SearchError> {\n    info!(splits_num = splits.len(), split_offsets = ?PrettySample::new(&splits, 5));\n\n    let split_filter = CanSplitDoBetter::from_request(&request, doc_mapper.timestamp_field_name());\n    let split_with_req = split_filter.optimize(request.clone(), splits)?;\n\n    // if client wants full count, or we are doing an aggregation, we want to run every splits.\n    // However if the aggregation is the tracing aggregation, we don't actually need all splits.\n    let run_all_splits = request.count_hits() == CountHits::CountAll\n        || (request.aggregation_request.is_some()\n            && !matches!(split_filter, CanSplitDoBetter::FindTraceIdsAggregation(_)));\n\n    let split_filter = Arc::new(RwLock::new(split_filter));\n\n    let mut leaf_search_single_split_join_handles: Vec<(String, tokio::task::JoinHandle<()>)> =\n        Vec::with_capacity(split_with_req.len());\n\n    let merge_collector = make_merge_collector(&request, &aggregations_limits)?;\n    let incremental_merge_collector = IncrementalCollector::new(merge_collector);\n    let incremental_merge_collector = Arc::new(Mutex::new(incremental_merge_collector));\n\n    for (split, mut request) in split_with_req {\n        let leaf_split_search_permit = searcher_context.leaf_search_split_semaphore\n            .clone()\n            .acquire_owned()\n            .instrument(info_span!(\"waiting_for_leaf_search_split_semaphore\"))\n            .await\n            .expect(\"Failed to acquire permit. This should never happen! Please, report on https://github.com/quickwit-oss/quickwit/issues.\");\n\n        let can_be_better = check_optimize_search_request(&mut request, &split, &split_filter);\n        if !can_be_better && !run_all_splits {\n            continue;\n        }\n\n        leaf_search_single_split_join_handles.push((\n            split.split_id.clone(),\n            tokio::spawn(\n                leaf_search_single_split_wrapper(\n                    request,\n                    searcher_context.clone(),\n                    index_storage.clone(),\n                    doc_mapper.clone(),\n                    split,\n                    split_filter.clone(),\n                    incremental_merge_collector.clone(),\n                    leaf_split_search_permit,\n                    aggregations_limits.clone(),\n                )\n                .in_current_span(),\n            ),\n        ));\n    }\n\n    // TODO we could cancel running splits when !run_all_splits and the running split can no\n    // longer give better results after some other split answered.\n    let mut split_search_join_errors: Vec<(String, JoinError)> = Vec::new();\n\n    // There is no need to use `join_all`, as these are spawned tasks.\n    for (split, leaf_search_join_handle) in leaf_search_single_split_join_handles {\n        // splits that did not panic were already added to the collector\n        if let Err(join_error) = leaf_search_join_handle.await {\n            if join_error.is_cancelled() {\n                // An explicit task cancellation is not an error.\n                continue;\n            }\n            if join_error.is_panic() {\n                error!(split=%split, \"leaf search task panicked\");\n            } else {\n                error!(split=%split, \"please report: leaf search was not cancelled, and could not extract panic. this should never happen\");\n            }\n            split_search_join_errors.push((split, join_error));\n        }\n    }\n\n    // we can't use unwrap_or_clone because mutexes aren't Clone\n    let mut incremental_merge_collector = match Arc::try_unwrap(incremental_merge_collector) {\n        Ok(filter_merger) => filter_merger.into_inner().unwrap(),\n        Err(filter_merger) => filter_merger.lock().unwrap().clone(),\n    };\n\n    for (split_id, split_search_join_error) in split_search_join_errors {\n        incremental_merge_collector.add_failed_split(SplitSearchError {\n            split_id,\n            error: SearchError::from(split_search_join_error).to_string(),\n            retryable_error: true,\n        });\n    }\n\n    let result = crate::search_thread_pool()\n        .run_cpu_intensive(|| incremental_merge_collector.finalize())\n        .instrument(info_span!(\"incremental_merge_intermediate\"))\n        .await\n        .context(\"failed to merge split search responses\")??;\n\n    Ok(result)\n}\n\n#[allow(clippy::too_many_arguments)]\n#[instrument(skip_all, fields(split_id = split.split_id))]\n/// Searching through a single split for a given search request.\nasync fn leaf_search_single_split_wrapper(\n    request: SearchRequest,\n    /// Searcher context will contain information needed\n    searcher_context: Arc<SearcherContext>,\n    /// Index storage to read the data from\n    index_storage: Arc<dyn Storage>,\n    /// doc mapper for finding the actual hits\n    doc_mapper: Arc<dyn DocMapper>,\n    /// footer offset\n    split: SplitIdAndFooterOffsets,\n    /// There are filters that can allow us to skip some splits\n    split_filter: Arc<RwLock<CanSplitDoBetter>>,\n    /// collector for the search results\n    /// this is used to collect the search results from the split\n    /// and merge them together\n    incremental_merge_collector: Arc<Mutex<IncrementalCollector>>,\n    /// permit to release the semaphore\n    leaf_split_search_permit: tokio::sync::OwnedSemaphorePermit,\n    /// this is used to limit the number of aggregations\n    /// that can be computed in a single search\n    /// this is useful to prevent a single search from consuming too much memory\n    /// and to prevent a single search from taking too long\n    aggregations_limits: AggregationLimits,\n) {\n    crate::SEARCH_METRICS.leaf_searches_splits_total.inc();\n    let timer = crate::SEARCH_METRICS\n        .leaf_search_split_duration_secs\n        .start_timer();\n    // After searching throught the split we drop the permit\n    let leaf_search_single_split_res = leaf_search_single_split(\n        &searcher_context,\n        request,\n        index_storage,\n        split.clone(),\n        doc_mapper,\n        split_filter.clone(),\n        aggregations_limits,\n    )\n    .await;\n\n    // We explicitly drop it, to highlight it to the reader\n    std::mem::drop(leaf_split_search_permit);\n\n    if leaf_search_single_split_res.is_ok() {\n        timer.observe_duration();\n    }\n\n    let mut locked_incremental_merge_collector = incremental_merge_collector.lock().unwrap();\n    match leaf_search_single_split_res {\n        Ok(split_search_res) => {\n            if let Err(err) = locked_incremental_merge_collector.add_result(split_search_res) {\n                locked_incremental_merge_collector.add_failed_split(SplitSearchError {\n                    split_id: split.split_id.clone(),\n                    error: format!(\"Error parsing aggregation result: {err}\"),\n                    retryable_error: true,\n                });\n            }\n        }\n        Err(err) => locked_incremental_merge_collector.add_failed_split(SplitSearchError {\n            split_id: split.split_id.clone(),\n            error: format!(\"{err}\"),\n            retryable_error: true,\n        }),\n    }\n    if let Some(last_hit) = locked_incremental_merge_collector.peek_worst_hit() {\n        // TODO: we could use the RWLock instead and read the value instead of updating it\n        // unconditionally.\n        split_filter\n            .write()\n            .unwrap()\n            .record_new_worst_hit(last_hit.as_ref());\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use std::ops::Bound;\n\n    use super::*;\n\n    fn bool_filter(ast: impl Into<QueryAst>) -> QueryAst {\n        BoolQuery {\n            must: vec![QueryAst::MatchAll],\n            filter: vec![ast.into()],\n            ..Default::default()\n        }\n        .into()\n    }\n\n    #[track_caller]\n    fn assert_ast_eq(got: &SearchRequest, expected: &QueryAst) {\n        let got_ast: QueryAst = serde_json::from_str(&got.query_ast).unwrap();\n        assert_eq!(&got_ast, expected);\n        assert!(got.start_timestamp.is_none());\n        assert!(got.end_timestamp.is_none());\n    }\n\n    #[track_caller]\n    fn remove_timestamp_test_case(\n        request: &SearchRequest,\n        split: &SplitIdAndFooterOffsets,\n        expected: Option<RangeQuery>,\n    ) {\n        let timestamp_field = \"timestamp\";\n\n        // test the query directly\n        let mut request_direct = request.clone();\n        remove_redundant_timestamp_range(&mut request_direct, split, timestamp_field);\n        let expected_direct = expected\n            .clone()\n            .map(bool_filter)\n            .unwrap_or(QueryAst::MatchAll);\n        assert_ast_eq(&request_direct, &expected_direct);\n    }\n\n    #[test]\n    fn test_remove_timestamp_range() {\n        const S_TO_NS: i64 = 1_000_000_000;\n        let time1 = 1700001000;\n        let time2 = 1700002000;\n        let time3 = 1700003000;\n        let time4 = 1700004000;\n\n        let timestamp_field = \"timestamp\".to_string();\n\n        // cases where the bounds are larger than the split: no bound is emitted\n        let split = SplitIdAndFooterOffsets {\n            timestamp_start: Some(time2),\n            timestamp_end: Some(time3),\n            ..SplitIdAndFooterOffsets::default()\n        };\n\n        let search_request = SearchRequest {\n            query_ast: serde_json::to_string(&QueryAst::Range(RangeQuery {\n                field: timestamp_field.to_string(),\n                lower_bound: Bound::Included(time1.into()),\n                // *1000 has no impact, we detect timestamp in ms instead of s\n                upper_bound: Bound::Included((time4 * 1000).into()),\n            }))\n            .unwrap(),\n            ..SearchRequest::default()\n        };\n        remove_timestamp_test_case(&search_request, &split, None);\n\n        let search_request = SearchRequest {\n            query_ast: serde_json::to_string(&QueryAst::Range(RangeQuery {\n                field: timestamp_field.to_string(),\n                lower_bound: Bound::Included(time1.into()),\n                upper_bound: Bound::Included(time3.into()),\n            }))\n            .unwrap(),\n            ..SearchRequest::default()\n        };\n        remove_timestamp_test_case(&search_request, &split, None);\n\n        let search_request = SearchRequest {\n            query_ast: serde_json::to_string(&QueryAst::MatchAll).unwrap(),\n            start_timestamp: Some(time1),\n            end_timestamp: Some(time4),\n            ..SearchRequest::default()\n        };\n        remove_timestamp_test_case(&search_request, &split, None);\n\n        // request bound that are exclusive are treated properly\n        let expected_upper_exclusive = RangeQuery {\n            field: timestamp_field.to_string(),\n            lower_bound: Bound::Unbounded,\n            upper_bound: Bound::Excluded((time3 * S_TO_NS).into()),\n        };\n        let search_request = SearchRequest {\n            query_ast: serde_json::to_string(&QueryAst::Range(RangeQuery {\n                field: timestamp_field.to_string(),\n                lower_bound: Bound::Included(time1.into()),\n                upper_bound: Bound::Excluded(time3.into()),\n            }))\n            .unwrap(),\n            ..SearchRequest::default()\n        };\n        remove_timestamp_test_case(\n            &search_request,\n            &split,\n            Some(expected_upper_exclusive.clone()),\n        );\n\n        let search_request = SearchRequest {\n            query_ast: serde_json::to_string(&QueryAst::MatchAll).unwrap(),\n            start_timestamp: Some(time1),\n            end_timestamp: Some(time3),\n            ..SearchRequest::default()\n        };\n        remove_timestamp_test_case(\n            &search_request,\n            &split,\n            Some(expected_upper_exclusive.clone()),\n        );\n\n        let expected_lower_exclusive = RangeQuery {\n            field: timestamp_field.to_string(),\n            lower_bound: Bound::Excluded((time2 * S_TO_NS).into()),\n            upper_bound: Bound::Unbounded,\n        };\n        let search_request = SearchRequest {\n            query_ast: serde_json::to_string(&QueryAst::Range(RangeQuery {\n                field: timestamp_field.to_string(),\n                lower_bound: Bound::Excluded(time2.into()),\n                upper_bound: Bound::Included(time3.into()),\n            }))\n            .unwrap(),\n            ..SearchRequest::default()\n        };\n        remove_timestamp_test_case(\n            &search_request,\n            &split,\n            Some(expected_lower_exclusive.clone()),\n        );\n\n        // we take the most restrictive bounds\n        let split = SplitIdAndFooterOffsets {\n            timestamp_start: Some(time1),\n            timestamp_end: Some(time4),\n            ..SplitIdAndFooterOffsets::default()\n        };\n\n        let expected_upper_2_ex = RangeQuery {\n            field: timestamp_field.to_string(),\n            lower_bound: Bound::Unbounded,\n            upper_bound: Bound::Excluded((time2 * S_TO_NS).into()),\n        };\n        let search_request = SearchRequest {\n            query_ast: serde_json::to_string(&QueryAst::Range(RangeQuery {\n                field: timestamp_field.to_string(),\n                lower_bound: Bound::Included(time1.into()),\n                upper_bound: Bound::Included(time3.into()),\n            }))\n            .unwrap(),\n            start_timestamp: Some(time1),\n            end_timestamp: Some(time2),\n            ..SearchRequest::default()\n        };\n        remove_timestamp_test_case(&search_request, &split, Some(expected_upper_2_ex));\n\n        let expected_upper_2_inc = RangeQuery {\n            field: timestamp_field.to_string(),\n            lower_bound: Bound::Unbounded,\n            upper_bound: Bound::Included((time2 * S_TO_NS).into()),\n        };\n        let search_request = SearchRequest {\n            query_ast: serde_json::to_string(&QueryAst::Range(RangeQuery {\n                field: timestamp_field.to_string(),\n                lower_bound: Bound::Included(time1.into()),\n                upper_bound: Bound::Included(time2.into()),\n            }))\n            .unwrap(),\n            start_timestamp: Some(time1),\n            end_timestamp: Some(time3),\n            ..SearchRequest::default()\n        };\n        remove_timestamp_test_case(&search_request, &split, Some(expected_upper_2_inc));\n\n        let expected_lower_3 = RangeQuery {\n            field: timestamp_field.to_string(),\n            lower_bound: Bound::Included((time3 * S_TO_NS).into()),\n            upper_bound: Bound::Unbounded,\n        };\n\n        let search_request = SearchRequest {\n            query_ast: serde_json::to_string(&QueryAst::Range(RangeQuery {\n                field: timestamp_field.to_string(),\n                lower_bound: Bound::Included(time2.into()),\n                upper_bound: Bound::Included(time4.into()),\n            }))\n            .unwrap(),\n            start_timestamp: Some(time3),\n            end_timestamp: Some(time4 + 1),\n            ..SearchRequest::default()\n        };\n        remove_timestamp_test_case(&search_request, &split, Some(expected_lower_3.clone()));\n\n        let search_request = SearchRequest {\n            query_ast: serde_json::to_string(&QueryAst::Range(RangeQuery {\n                field: timestamp_field.to_string(),\n                lower_bound: Bound::Included(time3.into()),\n                upper_bound: Bound::Included(time4.into()),\n            }))\n            .unwrap(),\n            start_timestamp: Some(time2),\n            end_timestamp: Some(time4 + 1),\n            ..SearchRequest::default()\n        };\n        remove_timestamp_test_case(&search_request, &split, Some(expected_lower_3));\n\n        let mut search_request = SearchRequest {\n            query_ast: serde_json::to_string(&QueryAst::MatchAll).unwrap(),\n            start_timestamp: Some(time1),\n            end_timestamp: Some(time4),\n            ..SearchRequest::default()\n        };\n        let split = SplitIdAndFooterOffsets {\n            timestamp_start: Some(time2),\n            timestamp_end: Some(time3),\n            ..SplitIdAndFooterOffsets::default()\n        };\n        remove_redundant_timestamp_range(&mut search_request, &split, &timestamp_field);\n        assert_ast_eq(&search_request, &QueryAst::MatchAll);\n    }\n\n    // regression test for #4935\n    #[test]\n    fn test_remove_timestamp_range_keep_should() {\n        let time1 = 1700001000;\n        let time2 = 1700002000;\n        let time3 = 1700003000;\n\n        let timestamp_field = \"timestamp\".to_string();\n\n        // cases where the bounds are larger than the split: no bound is emitted\n        let split = SplitIdAndFooterOffsets {\n            timestamp_start: Some(time1),\n            timestamp_end: Some(time3),\n            ..SplitIdAndFooterOffsets::default()\n        };\n\n        let mut search_request = SearchRequest {\n            query_ast: serde_json::to_string(&QueryAst::Bool(BoolQuery {\n                should: vec![QueryAst::MatchAll],\n                ..BoolQuery::default()\n            }))\n            .unwrap(),\n            start_timestamp: Some(time2),\n            end_timestamp: None,\n            ..SearchRequest::default()\n        };\n        remove_redundant_timestamp_range(&mut search_request, &split, &timestamp_field);\n        assert_ast_eq(\n            &search_request,\n            &QueryAst::Bool(BoolQuery {\n                // original request\n                must: vec![QueryAst::Bool(BoolQuery {\n                    should: vec![QueryAst::MatchAll],\n                    ..BoolQuery::default()\n                })],\n                // time bound\n                filter: vec![RangeQuery {\n                    field: \"timestamp\".to_string(),\n                    lower_bound: Bound::Included(1_700_002_000_000_000_000u64.into()),\n                    upper_bound: Bound::Unbounded,\n                }\n                .into()],\n                ..BoolQuery::default()\n            }),\n        );\n    }\n\n    #[test]\n    fn test_remove_extended_bounds_from_histogram() {\n        let histo_at_root = r#\"\n{\n  \"date_histo\": {\n    \"date_histogram\": {\n      \"extended_bounds\": {\n        \"max\": 1425254400000,\n        \"min\": 1420070400000\n      },\n      \"field\": \"date\",\n      \"fixed_interval\": \"30d\",\n      \"offset\": \"-4d\"\n    }\n  }\n}\n\"#;\n\n        let histo_at_root_no_bounds = r#\"\n{\n  \"date_histo\": {\n    \"date_histogram\": {\n      \"field\": \"date\",\n      \"fixed_interval\": \"30d\",\n      \"offset\": \"-4d\"\n    }\n  }\n}\n\"#;\n\n        let histo_at_root_with_sibling = r#\"\n{\n  \"metrics\": {\n    \"aggs\": {\n      \"response\": {\n        \"percentiles\": {\n          \"field\": \"response\",\n          \"keyed\": false,\n          \"percents\": [\n            85\n          ]\n        }\n      }\n    },\n    \"date_histogram\": {\n      \"extended_bounds\": {\n        \"max\": 1425254400000,\n        \"min\": 1420070400000\n      },\n      \"field\": \"date\",\n      \"fixed_interval\": \"30d\",\n      \"offset\": \"-4d\"\n    }\n  }\n}\n\"#;\n\n        let histo_at_root_with_sibling_no_bounds = r#\"\n{\n  \"metrics\": {\n    \"aggs\": {\n      \"response\": {\n        \"percentiles\": {\n          \"field\": \"response\",\n          \"keyed\": false,\n          \"percents\": [\n            85\n          ]\n        }\n      }\n    },\n    \"date_histogram\": {\n      \"field\": \"date\",\n      \"fixed_interval\": \"30d\",\n      \"offset\": \"-4d\"\n    }\n  }\n}\n\"#;\n        let histo_at_leaf = r#\"\n{\n  \"metrics\": {\n    \"aggs\": {\n      \"response\": {\n        \"date_histogram\": {\n          \"extended_bounds\": {\n            \"max\": 1425254400000,\n            \"min\": 1420070400000\n          },\n          \"field\": \"date\",\n          \"fixed_interval\": \"30d\",\n          \"offset\": \"-4d\"\n        }\n      }\n    },\n    \"percentiles\": {\n      \"field\": \"response\",\n      \"keyed\": false,\n      \"percents\": [\n        85\n      ]\n    }\n  }\n}\n\"#;\n\n        let histo_at_leaf_no_bounds = r#\"\n{\n  \"metrics\": {\n    \"aggs\": {\n      \"response\": {\n        \"date_histogram\": {\n          \"field\": \"date\",\n          \"fixed_interval\": \"30d\",\n          \"offset\": \"-4d\"\n        }\n      }\n    },\n    \"percentiles\": {\n      \"field\": \"response\",\n      \"keyed\": false,\n      \"percents\": [\n        85\n      ]\n    }\n  }\n}\n\"#;\n        for (bounds, no_bounds) in [\n            (histo_at_root, histo_at_root_no_bounds),\n            (\n                histo_at_root_with_sibling,\n                histo_at_root_with_sibling_no_bounds,\n            ),\n            (histo_at_leaf, histo_at_leaf_no_bounds),\n        ] {\n            // first assert we do nothing when there are no bounds\n            let request_no_bounds = SearchRequest {\n                aggregation_request: Some(no_bounds.to_string()),\n                ..SearchRequest::default()\n            };\n            let mut request_no_bounds_clone = request_no_bounds.clone();\n            rewrite_aggregation(&mut request_no_bounds_clone);\n            assert_eq!(request_no_bounds, request_no_bounds_clone);\n\n            let mut request_bounds = SearchRequest {\n                aggregation_request: Some(bounds.to_string()),\n                ..SearchRequest::default()\n            };\n            rewrite_aggregation(&mut request_bounds);\n            // we can't just compare bounds and no_bounds, they must be structuraly equal, but not\n            // necessarily identical (field order, null vs absent...). So we parse both and verify\n            // the results are equal instead\n            let no_bounds_agg: QuickwitAggregations =\n                serde_json::from_str(&request_no_bounds.aggregation_request.unwrap()).unwrap();\n            let rewrote_bounds_agg: QuickwitAggregations =\n                serde_json::from_str(&request_bounds.aggregation_request.unwrap()).unwrap();\n            assert_eq!(rewrote_bounds_agg, no_bounds_agg);\n        }\n    }\n}\n```\ndiagnostics: quickwit/quickwit/quickwit-search/src/leaf.rs\n```rust\nasync fn leaf_search_single_split_wrapper(\n    request: SearchRequest,\n    /// Searcher context will contain information needed\n// error: allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters\n    searcher_context: Arc<SearcherContext>,\n    /// Index storage to read the data from\n```\n```rust\n    /// Searcher context will contain information needed\n    searcher_context: Arc<SearcherContext>,\n    /// Index storage to read the data from\n// error: allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters\n    index_storage: Arc<dyn Storage>,\n    /// doc mapper for finding the actual hits\n```\n```rust\n    /// Index storage to read the data from\n    index_storage: Arc<dyn Storage>,\n    /// doc mapper for finding the actual hits\n// error: allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters\n    doc_mapper: Arc<dyn DocMapper>,\n    /// footer offset\n```\n```rust\n    /// doc mapper for finding the actual hits\n    doc_mapper: Arc<dyn DocMapper>,\n    /// footer offset\n// error: allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters\n    split: SplitIdAndFooterOffsets,\n    /// There are filters that can allow us to skip some splits\n```\n```rust\n    /// footer offset\n    split: SplitIdAndFooterOffsets,\n    /// There are filters that can allow us to skip some splits\n// error: allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters\n    split_filter: Arc<RwLock<CanSplitDoBetter>>,\n    /// collector for the search results\n```\n```rust\n    /// There are filters that can allow us to skip some splits\n    split_filter: Arc<RwLock<CanSplitDoBetter>>,\n    /// collector for the search results\n// error: allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters\n    /// this is used to collect the search results from the split\n    /// and merge them together\n```\n```rust\n    split_filter: Arc<RwLock<CanSplitDoBetter>>,\n    /// collector for the search results\n    /// this is used to collect the search results from the split\n// error: allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters\n    /// and merge them together\n    incremental_merge_collector: Arc<Mutex<IncrementalCollector>>,\n```\n```rust\n    /// collector for the search results\n    /// this is used to collect the search results from the split\n    /// and merge them together\n// error: allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters\n    incremental_merge_collector: Arc<Mutex<IncrementalCollector>>,\n    /// permit to release the semaphore\n```\n```rust\n    /// and merge them together\n    incremental_merge_collector: Arc<Mutex<IncrementalCollector>>,\n    /// permit to release the semaphore\n// error: allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters\n    leaf_split_search_permit: tokio::sync::OwnedSemaphorePermit,\n    /// this is used to limit the number of aggregations\n```\n```rust\n    /// permit to release the semaphore\n    leaf_split_search_permit: tokio::sync::OwnedSemaphorePermit,\n    /// this is used to limit the number of aggregations\n// error: allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters\n    /// that can be computed in a single search\n    /// this is useful to prevent a single search from consuming too much memory\n```\n```rust\n    leaf_split_search_permit: tokio::sync::OwnedSemaphorePermit,\n    /// this is used to limit the number of aggregations\n    /// that can be computed in a single search\n// error: allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters\n    /// this is useful to prevent a single search from consuming too much memory\n    /// and to prevent a single search from taking too long\n```\n```rust\n    /// this is used to limit the number of aggregations\n    /// that can be computed in a single search\n    /// this is useful to prevent a single search from consuming too much memory\n// error: allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters\n    /// and to prevent a single search from taking too long\n    aggregations_limits: AggregationLimits,\n```\n```rust\n    /// that can be computed in a single search\n    /// this is useful to prevent a single search from consuming too much memory\n    /// and to prevent a single search from taking too long\n// error: allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters\n    aggregations_limits: AggregationLimits,\n) {\n```\n\nif all the files needed for quickwit to open an index is in the hotcache, why even bother with the index itself? just use the hotcache\nThe hotcache in Quickwit is designed to optimize the performance of search operations by caching frequently accessed data, such as term dictionaries, document stores, and other small files that are critical for search operations. However, the hotcache alone is not sufficient to perform all the necessary operations for a full-text search engine like Quickwit. Here are some reasons why the index itself is still necessary:\n\n1. **Complete Data Storage**: The hotcache only contains a subset of the data that is frequently accessed or small enough to be cached efficiently. The full index contains all the data, including large files and less frequently accessed data, which are necessary for comprehensive search operations.\n\n2. **Data Integrity and Completeness**: The index ensures that all data is stored and can be retrieved when needed. The hotcache is a performance optimization layer and does not guarantee the completeness of the data. Relying solely on the hotcache could lead to incomplete search results.\n\n3. **Updates and Consistency**: The index is the source of truth for all the data. When updates or changes occur, they are applied to the index. The hotcache may need to be invalidated or updated to reflect these changes, but it cannot be the primary storage for updates.\n\n4. **Scalability**: The index is designed to handle large volumes of data that may not fit into memory or a cache. The hotcache is limited by the available memory and is intended to speed up access to the most frequently used data, not to store the entire dataset.\n\n5. **Advanced Search Features**: Some advanced search features and operations may require access to the full index. For example, complex queries, aggregations, and sorting operations might need data that is not present in the hotcache.\n\n6. **Fault Tolerance**: The index provides a durable and fault-tolerant storage mechanism. If the hotcache is lost or corrupted, the index can be used to rebuild the cache. Relying solely on the hotcache would compromise the fault tolerance of the system.\n\nIn summary, the hotcache is an important optimization layer that enhances the performance of search operations by caching frequently accessed data. However, the full index is still necessary to ensure data integrity, completeness, scalability, and support for advanced search features. The hotcache and the index work together to provide a fast and reliable search experience.\nbut then how is all other data stored? after all quickwit is using tantivy's index files\nQuickwit leverages Tantivy, a full-text search engine library, to manage its indexing and search functionalities. Tantivy stores its index data in a structured format across multiple files, which include segment files, term dictionaries, postings lists, fast fields, and more. Here's a breakdown of how data is stored and managed in Quickwit using Tantivy's index files:\n\n### Tantivy Index Structure\n\n1. **Segment Files**: Tantivy divides the index into segments, each of which is a self-contained index. Segments are immutable once created, which allows for efficient merging and querying.\n\n2. **Term Dictionaries**: These files store the terms in the index along with their metadata. They are often stored in a compressed format to save space and improve lookup performance.\n\n3. **Postings Lists**: These files contain the list of document IDs where each term appears, along with additional information like term frequency and positions (for phrase queries).\n\n4. **Fast Fields**: These are columnar storage files optimized for fast retrieval of field values, often used for sorting and faceting.\n\n5. **Stored Fields**: These files contain the original document fields that need to be retrieved when a document is matched by a query.\n\n6. **Field Norms**: These files store normalization factors for fields, which are used in scoring.\n\n### Quickwit Enhancements\n\nQuickwit enhances Tantivy's capabilities by adding additional layers and optimizations:\n\n1. **Hotcache**: Quickwit uses a hotcache to store frequently accessed data, such as term dictionaries and small files. This cache helps speed up search operations by reducing the need to repeatedly read these files from disk or remote storage.\n\n2. **Bundle Storage**: Quickwit can bundle multiple index files into a single file for efficient storage and retrieval, especially when dealing with remote storage systems like S3.\n\n3. **Caching Layers**: Quickwit adds multiple caching layers, including in-memory caches and ephemeral caches, to further optimize access to index data.\n\n4. **Split Management**: Quickwit divides the index into splits, which are logical partitions of the index. Each split can be independently searched and managed, allowing for better scalability and parallelism.\n\n### Data Storage and Retrieval\n\nWhen Quickwit performs a search, it follows these steps:\n\n1. **Cache Lookup**: Quickwit first checks the hotcache and other caches to see if the required data is already available in memory.\n\n2. **Bundle Storage**: If the data is not in the cache, Quickwit retrieves it from the bundled storage. This might involve reading from a local disk or a remote storage system.\n\n3. **Index Access**: Quickwit uses Tantivy to access the index files, leveraging Tantivy's efficient data structures and algorithms for querying.\n\n4. **Warmup**: Quickwit preloads necessary data into memory (warmup) based on the query requirements to ensure efficient search execution.\n\n### Example Code\n\nHere's an example of how Quickwit opens an index with caching layers:\n\n```rust\npub(crate) async fn open_index_with_caches(\n    searcher_context: &SearcherContext,\n    index_storage: Arc<dyn Storage>,\n    split_and_footer_offsets: &SplitIdAndFooterOffsets,\n    tokenizer_manager: Option<&TokenizerManager>,\n    ephemeral_unbounded_cache: bool,\n) -> anyhow::Result<Index> {\n    // Retrieve hotcache bytes and bundle storage\n    let (hotcache_bytes, bundle_storage) =\n        open_split_bundle(searcher_context, index_storage, split_and_footer_offsets).await?;\n\n    // Wrap the bundle storage with the fast fields cache\n    let bundle_storage_with_cache = wrap_storage_with_cache(\n        searcher_context.fast_fields_cache.clone(),\n        Arc::new(bundle_storage),\n    );\n    let directory = StorageDirectory::new(bundle_storage_with_cache);\n\n    // Create a hot directory with the hotcache bytes\n    let hot_directory = if ephemeral_unbounded_cache {\n        let caching_directory = CachingDirectory::new_unbounded(Arc::new(directory));\n        HotDirectory::open(caching_directory, hotcache_bytes.read_bytes()?)?\n    } else {\n        HotDirectory::open(directory, hotcache_bytes.read_bytes()?)?\n    };\n\n    // Open the Tantivy index\n    let mut index = Index::open(hot_directory)?;\n    if let Some(tokenizer_manager) = tokenizer_manager {\n        index.set_tokenizers(tokenizer_manager.tantivy_manager().clone());\n    }\n    index.set_fast_field_tokenizers(\n        quickwit_query::get_quickwit_fastfield_normalizer_manager()\n            .tantivy_manager()\n            .clone(),\n    );\n    Ok(index)\n}\n```\n\nIn summary, Quickwit uses Tantivy's index files to store and manage data, while adding its own layers of caching and optimizations to improve performance and scalability. The hotcache is an important part of this system, but it works in conjunction with the full index to provide a complete and efficient search solution.\nhow is the .store file created and stored in quickwit?\nIn Quickwit, the `.store` file is a crucial component of the index, as it contains the stored fields for documents. These fields are the original document fields that need to be retrieved when a document is matched by a query. The `.store` file is created and managed by Tantivy, the underlying search engine library used by Quickwit. Here's an overview of how the `.store` file is created and stored in Quickwit:\n\n### Creation of the `.store` File\n\n1. **Indexing Documents**: When documents are indexed in Quickwit, they are processed and added to the Tantivy index. During this process, the fields specified as \"stored\" in the schema are written to the `.store` file.\n\n2. **Segment Creation**: Tantivy divides the index into segments, and each segment has its own `.store` file. When a segment is created, Tantivy writes the stored fields of the documents in that segment to the `.store` file.\n\n3. **Serialization**: The stored fields are serialized and compressed to optimize storage space and retrieval speed. Tantivy handles the serialization and compression of the stored fields.\n\n### Storage of the `.store` File\n\n1. **Local Storage**: By default, the `.store` file is stored on the local filesystem as part of the segment files. Each segment directory contains a `.store` file along with other index files such as term dictionaries, postings lists, and fast fields.\n\n2. **Remote Storage**: Quickwit supports storing index files in remote storage systems such as Amazon S3. When using remote storage, Quickwit bundles the segment files, including the `.store` file, into a single file for efficient storage and retrieval. This bundled file is then uploaded to the remote storage.\n\n3. **Caching**: Quickwit employs various caching mechanisms to optimize access to the `.store` file. Frequently accessed data from the `.store` file can be cached in memory (hotcache) to reduce the need for repeated disk or network I/O.\n\n### Example Code\n\nHere is an example of how Quickwit handles the opening of a split bundle, which includes accessing the `.store` file:\n\n```rust\n/// Returns hotcache_bytes and the split directory (`BundleStorage`) with cache layer:\n/// - A split footer cache given by `SearcherContext.split_footer_cache`.\n#[instrument(skip_all, fields(split_footer_start=split_and_footer_offsets.split_footer_start, split_footer_end=split_and_footer_offsets.split_footer_end))]\npub(crate) async fn open_split_bundle(\n    searcher_context: &SearcherContext,\n    index_storage: Arc<dyn Storage>,\n    split_and_footer_offsets: &SplitIdAndFooterOffsets,\n) -> anyhow::Result<(FileSlice, BundleStorage)> {\n    let split_file = PathBuf::from(format!(\"{}.split\", split_and_footer_offsets.split_id));\n    let footer_data = get_split_footer_from_cache_or_fetch(\n        index_storage.clone(),\n        split_and_footer_offsets,\n        &searcher_context.split_footer_cache,\n    )\n    .await?;\n\n    // We wrap the top-level storage with the split cache.\n    // This is before the bundle storage: at this point, this storage is reading `.split` files.\n    let index_storage_with_split_cache =\n        if let Some(split_cache) = searcher_context.split_cache_opt.as_ref() {\n            SplitCache::wrap_storage(split_cache.clone(), index_storage.clone())\n        } else {\n            index_storage.clone()\n        };\n\n    let (hotcache_bytes, bundle_storage) = BundleStorage::open_from_split_data(\n        index_storage_with_split_cache,\n        split_file,\n        FileSlice::new(Arc::new(footer_data)),\n    )?;\n\n    Ok((hotcache_bytes, bundle_storage))\n}\n```\n\n### Summary\n\n- **Creation**: The `.store` file is created during the indexing process by Tantivy. It stores the serialized and compressed stored fields of documents.\n- **Storage**: The `.store` file is stored as part of the segment files on the local filesystem or in remote storage systems like Amazon S3.\n- **Caching**: Quickwit uses caching mechanisms to optimize access to the `.store` file, reducing the need for repeated disk or network I/O.\n\nBy leveraging Tantivy's efficient indexing and storage mechanisms, Quickwit ensures that the `.store` file is created, stored, and accessed in a performant and scalable manner.\n","messages":[{"id":{"replica_id":0,"value":0},"start":0,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":324}},"image_offsets":[]},{"id":{"replica_id":0,"value":22},"start":74967,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":325}},"image_offsets":[]},{"id":{"replica_id":0,"value":23},"start":77394,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":326}},"image_offsets":[]},{"id":{"replica_id":0,"value":117},"start":77483,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":327}},"image_offsets":[]},{"id":{"replica_id":0,"value":118},"start":82365,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":328}},"image_offsets":[]},{"id":{"replica_id":0,"value":160},"start":82420,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":329}},"image_offsets":[]},{"id":{"replica_id":0,"value":161},"start":86603,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":330}},"image_offsets":[]}],"summary":"Importance of Index in Quickwit Despite Hotcache Optimization","slash_command_output_sections":[{"range":{"start":0,"end":1},"icon":"Library","label":"Default"},{"range":{"start":3,"end":74831},"icon":"File","label":"quickwit/quickwit/quickwit-search/src/leaf.rs"},{"range":{"start":69774,"end":74831},"icon":"ExclamationTriangle","label":"Diagnostics (quickwit/quickwit/quickwit-search/src/leaf.rs): 13 errors"},{"range":{"start":69833,"end":70187},"icon":"XCircle","label":"allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters"},{"range":{"start":70188,"end":70555},"icon":"XCircle","label":"allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters"},{"range":{"start":70556,"end":70880},"icon":"XCircle","label":"allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters"},{"range":{"start":70881,"end":71224},"icon":"XCircle","label":"allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters"},{"range":{"start":71225,"end":71575},"icon":"XCircle","label":"allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters"},{"range":{"start":71576,"end":71966},"icon":"XCircle","label":"allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters"},{"range":{"start":71967,"end":72360},"icon":"XCircle","label":"allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters"},{"range":{"start":72361,"end":72745},"icon":"XCircle","label":"allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters"},{"range":{"start":72746,"end":73145},"icon":"XCircle","label":"allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters"},{"range":{"start":73146,"end":73575},"icon":"XCircle","label":"allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters"},{"range":{"start":73576,"end":74025},"icon":"XCircle","label":"allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters"},{"range":{"start":74026,"end":74454},"icon":"XCircle","label":"allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters"},{"range":{"start":74455,"end":74830},"icon":"XCircle","label":"allow, cfg, cfg_attr, deny, expect, forbid, and warn are the only allowed built-in attributes in function parameters"}]}